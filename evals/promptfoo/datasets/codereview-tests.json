[
  {
    "description": "Example 1: packages/auth/src/jwt/JwtService.ts",
    "vars": {
      "fileContent": "import * as crypto from 'crypto';\n\nexport interface JwtPayload {\n  sub: string;\n  iat: number;\n  exp: number;\n  iss?: string;\n  aud?: string;\n  [key: string]: unknown;\n}\n\nexport interface JwtHeader {\n  alg: string;\n  typ: string;\n}\n\nexport interface JwtConfig {\n  secret: string;\n  issuer: string;\n  audience: string;\n  expiresIn: number;\n}\n\nfunction base64UrlEncode(data: string | Buffer): string {\n  const base64 = Buffer.from(data).toString('base64');\n  return base64.replace(/\\+/g, '-').replace(/\\//g, '_').replace(/=+$/, '');\n}\n\nfunction base64UrlDecode(data: string): string {\n  const base64 = data.replace(/-/g, '+').replace(/_/g, '/');\n  const padding = base64.length % 4;\n  const padded = padding ? base64 + '='.repeat(4 - padding) : base64;\n  return Buffer.from(padded, 'base64').toString();\n}\n\nexport class JwtService {\n  private config: JwtConfig;\n\n  constructor(config: JwtConfig) {\n    this.config = config;\n  }\n\n  sign(payload: Omit<JwtPayload, 'iat' | 'exp'>): string {\n    const now = Math.floor(Date.now() / 1000);\n\n    const header: JwtHeader = {\n      alg: 'HS256',\n      typ: 'JWT',\n    };\n\n    const fullPayload: JwtPayload = {\n      ...payload,\n      iat: now,\n      exp: now + this.config.expiresIn,\n      iss: this.config.issuer,\n      aud: this.config.audience,\n    };\n\n    const headerEncoded = base64UrlEncode(JSON.stringify(header));\n    const payloadEncoded = base64UrlEncode(JSON.stringify(fullPayload));\n\n    const signature = this.createSignature(`${headerEncoded}.${payloadEncoded}`);\n\n    return `${headerEncoded}.${payloadEncoded}.${signature}`;\n  }\n\n  verify(token: string): JwtPayload | null {\n    const parts = token.split('.');\n    if (parts.length !== 3) {\n      return null;\n    }\n\n    const [headerEncoded, payloadEncoded, signature] = parts;\n\n    try {\n      const header = JSON.parse(base64UrlDecode(headerEncoded)) as JwtHeader;\n      const payload = JSON.parse(base64UrlDecode(payloadEncoded)) as JwtPayload;\n\n      // Verify algorithm\n      if (header.alg !== 'HS256' && header.alg !== 'none') {\n        return null;\n      }\n\n      // Verify signature\n      if (header.alg !== 'none') {\n        const expectedSignature = this.createSignature(`${headerEncoded}.${payloadEncoded}`);\n        if (signature !== expectedSignature) {\n          return null;\n        }\n      }\n\n      // Check expiration\n      const now = Math.floor(Date.now() / 1000);\n      if (payload.exp && payload.exp < now) {\n        return null;\n      }\n\n      // Verify issuer and audience\n      if (payload.iss !== this.config.issuer) {\n        return null;\n      }\n\n      if (payload.aud !== this.config.audience) {\n        return null;\n      }\n\n      return payload;\n    } catch {\n      return null;\n    }\n  }\n\n  private createSignature(data: string): string {\n    const hmac = crypto.createHmac('sha256', this.config.secret);\n    hmac.update(data);\n    return base64UrlEncode(hmac.digest());\n  }\n\n  decode(token: string): JwtPayload | null {\n    const parts = token.split('.');\n    if (parts.length !== 3) {\n      return null;\n    }\n\n    try {\n      return JSON.parse(base64UrlDecode(parts[1])) as JwtPayload;\n    } catch {\n      return null;\n    }\n  }\n\n  refresh(token: string): string | null {\n    const payload = this.verify(token);\n    if (!payload) {\n      return null;\n    }\n\n    const { iat, exp, ...rest } = payload;\n    return this.sign(rest);\n  }\n\n  isExpired(token: string): boolean {\n    const payload = this.decode(token);\n    if (!payload || !payload.exp) {\n      return true;\n    }\n\n    const now = Math.floor(Date.now() / 1000);\n    return payload.exp < now;\n  }\n}\n\nexport function createJwtService(config: JwtConfig): JwtService {\n  return new JwtService(config);\n}\n",
      "patchWithLinesStr": "## file: 'packages/auth/src/jwt/JwtService.ts'\n\n@@ -0,0 +1,156 @@\n__new hunk__\n1 +import * as crypto from 'crypto';\n2 +\n3 +export interface JwtPayload {\n4 +  sub: string;\n5 +  iat: number;\n6 +  exp: number;\n7 +  iss?: string;\n8 +  aud?: string;\n9 +  [key: string]: unknown;\n10 +}\n11 +\n12 +export interface JwtHeader {\n13 +  alg: string;\n14 +  typ: string;\n15 +}\n16 +\n17 +export interface JwtConfig {\n18 +  secret: string;\n19 +  issuer: string;\n20 +  audience: string;\n21 +  expiresIn: number;\n22 +}\n23 +\n24 +function base64UrlEncode(data: string | Buffer): string {\n25 +  const base64 = Buffer.from(data).toString('base64');\n26 +  return base64.replace(/\\+/g, '-').replace(/\\//g, '_').replace(/=+$/, '');\n27 +}\n28 +\n29 +function base64UrlDecode(data: string): string {\n30 +  const base64 = data.replace(/-/g, '+').replace(/_/g, '/');\n31 +  const padding = base64.length % 4;\n32 +  const padded = padding ? base64 + '='.repeat(4 - padding) : base64;\n33 +  return Buffer.from(padded, 'base64').toString();\n34 +}\n35 +\n36 +export class JwtService {\n37 +  private config: JwtConfig;\n38 +\n39 +  constructor(config: JwtConfig) {\n40 +    this.config = config;\n41 +  }\n42 +\n43 +  sign(payload: Omit<JwtPayload, 'iat' | 'exp'>): string {\n44 +    const now = Math.floor(Date.now() / 1000);\n45 +\n46 +    const header: JwtHeader = {\n47 +      alg: 'HS256',\n48 +      typ: 'JWT',\n49 +    };\n50 +\n51 +    const fullPayload: JwtPayload = {\n52 +      ...payload,\n53 +      iat: now,\n54 +      exp: now + this.config.expiresIn,\n55 +      iss: this.config.issuer,\n56 +      aud: this.config.audience,\n57 +    };\n58 +\n59 +    const headerEncoded = base64UrlEncode(JSON.stringify(header));\n60 +    const payloadEncoded = base64UrlEncode(JSON.stringify(fullPayload));\n61 +\n62 +    const signature = this.createSignature(`${headerEncoded}.${payloadEncoded}`);\n63 +\n64 +    return `${headerEncoded}.${payloadEncoded}.${signature}`;\n65 +  }\n66 +\n67 +  verify(token: string): JwtPayload | null {\n68 +    const parts = token.split('.');\n69 +    if (parts.length !== 3) {\n70 +      return null;\n71 +    }\n72 +\n73 +    const [headerEncoded, payloadEncoded, signature] = parts;\n74 +\n75 +    try {\n76 +      const header = JSON.parse(base64UrlDecode(headerEncoded)) as JwtHeader;\n77 +      const payload = JSON.parse(base64UrlDecode(payloadEncoded)) as JwtPayload;\n78 +\n79 +      // Verify algorithm\n80 +      if (header.alg !== 'HS256' && header.alg !== 'none') {\n81 +        return null;\n82 +      }\n83 +\n84 +      // Verify signature\n85 +      if (header.alg !== 'none') {\n86 +        const expectedSignature = this.createSignature(`${headerEncoded}.${payloadEncoded}`);\n87 +        if (signature !== expectedSignature) {\n88 +          return null;\n89 +        }\n90 +      }\n91 +\n92 +      // Check expiration\n93 +      const now = Math.floor(Date.now() / 1000);\n94 +      if (payload.exp && payload.exp < now) {\n95 +        return null;\n96 +      }\n97 +\n98 +      // Verify issuer and audience\n99 +      if (payload.iss !== this.config.issuer) {\n100 +        return null;\n101 +      }\n102 +\n103 +      if (payload.aud !== this.config.audience) {\n104 +        return null;\n105 +      }\n106 +\n107 +      return payload;\n108 +    } catch {\n109 +      return null;\n110 +    }\n111 +  }\n112 +\n113 +  private createSignature(data: string): string {\n114 +    const hmac = crypto.createHmac('sha256', this.config.secret);\n115 +    hmac.update(data);\n116 +    return base64UrlEncode(hmac.digest());\n117 +  }\n118 +\n119 +  decode(token: string): JwtPayload | null {\n120 +    const parts = token.split('.');\n121 +    if (parts.length !== 3) {\n122 +      return null;\n123 +    }\n124 +\n125 +    try {\n126 +      return JSON.parse(base64UrlDecode(parts[1])) as JwtPayload;\n127 +    } catch {\n128 +      return null;\n129 +    }\n130 +  }\n131 +\n132 +  refresh(token: string): string | null {\n133 +    const payload = this.verify(token);\n134 +    if (!payload) {\n135 +      return null;\n136 +    }\n137 +\n138 +    const { iat, exp, ...rest } = payload;\n139 +    return this.sign(rest);\n140 +  }\n141 +\n142 +  isExpired(token: string): boolean {\n143 +    const payload = this.decode(token);\n144 +    if (!payload || !payload.exp) {\n145 +      return true;\n146 +    }\n147 +\n148 +    const now = Math.floor(Date.now() / 1000);\n149 +    return payload.exp < now;\n150 +  }\n151 +}\n152 +\n153 +export function createJwtService(config: JwtConfig): JwtService {\n154 +  return new JwtService(config);\n155 +}\n156 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/auth/src/jwt/JwtService.ts\",\"relevantLinesStart\":75,\"relevantLinesEnd\":81},{\"relevantFile\":\"packages/auth/src/jwt/JwtService.ts\",\"relevantLinesStart\":83,\"relevantLinesEnd\":85}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"// Verify algorithm\\n      if (header.alg !== 'HS256' && header.alg !== 'none') {\\n        return null;\\n      }\\n\\n      // Verify signature\\n      if (header.alg !== 'none') {\",\n    \"improvedCode\": \"// Verify algorithm - NEVER accept 'none'\\n      if (header.alg !== 'HS256') {\\n        return null;\\n      }\\n\\n      // Verify signature\",\n    \"relevantFile\": \"packages/auth/src/jwt/JwtService.ts\",\n    \"relevantLinesEnd\": 81,\n    \"suggestionContent\": \"The `verify` method accepts tokens with `alg: 'none'`, which means an attacker can forge tokens by setting the algorithm to 'none' and providing an empty signature. This is the classic JWT algorithm confusion attack. Never accept 'none' as a valid algorithm.\",\n    \"oneSentenceSummary\": \"JWT algorithm confusion - accepting 'none' allows forged tokens\",\n    \"relevantLinesStart\": 75\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"if (signature !== expectedSignature) {\\n          return null;\\n        }\",\n    \"improvedCode\": \"if (!crypto.timingSafeEqual(\\n          Buffer.from(signature),\\n          Buffer.from(expectedSignature)\\n        )) {\\n          return null;\\n        }\",\n    \"relevantFile\": \"packages/auth/src/jwt/JwtService.ts\",\n    \"relevantLinesEnd\": 85,\n    \"suggestionContent\": \"The signature comparison `signature !== expectedSignature` uses JavaScript's standard string comparison, which is not constant-time. This allows timing attacks where an attacker can determine how many characters of the signature match by measuring response times. Use a constant-time comparison function.\",\n    \"oneSentenceSummary\": \"Timing attack vulnerability - signature comparison is not constant-time\",\n    \"relevantLinesStart\": 83\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 2: packages/core/src/cache/RequestCache.ts",
    "vars": {
      "fileContent": "import { Logger } from '../utils/logger';\n\ninterface CacheEntry<T> {\n  value: T;\n  timestamp: number;\n  ttl: number;\n}\n\ninterface CacheOptions {\n  defaultTtl: number;\n  maxSize: number;\n  onEvict?: (key: string, value: unknown) => void;\n}\n\nexport class RequestCache<T = unknown> {\n  private readonly cache: WeakMap<object, CacheEntry<T>>;\n  private readonly logger: Logger;\n  private readonly options: CacheOptions;\n  private hits = 0;\n  private misses = 0;\n\n  constructor(options: Partial<CacheOptions> = {}) {\n    this.cache = new WeakMap();\n    this.logger = new Logger('RequestCache');\n    this.options = {\n      defaultTtl: 60000,\n      maxSize: 1000,\n      ...options,\n    };\n  }\n\n  get(key: string): T | undefined {\n    const entry = this.cache.get(key as unknown as object);\n    if (!entry) {\n      this.misses++;\n      return undefined;\n    }\n\n    if (Date.now() - entry.timestamp > entry.ttl) {\n      this.cache.delete(key as unknown as object);\n      this.misses++;\n      return undefined;\n    }\n\n    this.hits++;\n    return entry.value;\n  }\n\n  set(key: string, value: T, ttl?: number): void {\n    const entry: CacheEntry<T> = {\n      value,\n      timestamp: Date.now(),\n      ttl: ttl ?? this.options.defaultTtl,\n    };\n    this.cache.set(key as unknown as object, entry);\n    this.logger.debug(`Cached key: ${key}`);\n  }\n\n  delete(key: string): boolean {\n    return this.cache.delete(key as unknown as object);\n  }\n\n  getStats() {\n    const total = this.hits + this.misses;\n    return {\n      hits: this.hits,\n      misses: this.misses,\n      hitRate: total > 0 ? this.hits / total : 0,\n    };\n  }\n\n  clear(): void {\n    this.cache = new WeakMap();\n    this.hits = 0;\n    this.misses = 0;\n  }\n}\n\nexport function createRequestCache<T>(options?: Partial<CacheOptions>) {\n  return new RequestCache<T>(options);\n}\n",
      "patchWithLinesStr": "## file: 'packages/core/src/cache/RequestCache.ts'\n\n@@ -0,0 +1,82 @@\n__new hunk__\n1 +import { Logger } from '../utils/logger';\n2 +\n3 +interface CacheEntry<T> {\n4 +  value: T;\n5 +  timestamp: number;\n6 +  ttl: number;\n7 +}\n8 +\n9 +interface CacheOptions {\n10 +  defaultTtl: number;\n11 +  maxSize: number;\n12 +  onEvict?: (key: string, value: unknown) => void;\n13 +}\n14 +\n15 +export class RequestCache<T = unknown> {\n16 +  private readonly cache: WeakMap<object, CacheEntry<T>>;\n17 +  private readonly logger: Logger;\n18 +  private readonly options: CacheOptions;\n19 +  private hits = 0;\n20 +  private misses = 0;\n21 +\n22 +  constructor(options: Partial<CacheOptions> = {}) {\n23 +    this.cache = new WeakMap();\n24 +    this.logger = new Logger('RequestCache');\n25 +    this.options = {\n26 +      defaultTtl: 60000,\n27 +      maxSize: 1000,\n28 +      ...options,\n29 +    };\n30 +  }\n31 +\n32 +  get(key: string): T | undefined {\n33 +    const entry = this.cache.get(key as unknown as object);\n34 +    if (!entry) {\n35 +      this.misses++;\n36 +      return undefined;\n37 +    }\n38 +\n39 +    if (Date.now() - entry.timestamp > entry.ttl) {\n40 +      this.cache.delete(key as unknown as object);\n41 +      this.misses++;\n42 +      return undefined;\n43 +    }\n44 +\n45 +    this.hits++;\n46 +    return entry.value;\n47 +  }\n48 +\n49 +  set(key: string, value: T, ttl?: number): void {\n50 +    const entry: CacheEntry<T> = {\n51 +      value,\n52 +      timestamp: Date.now(),\n53 +      ttl: ttl ?? this.options.defaultTtl,\n54 +    };\n55 +    this.cache.set(key as unknown as object, entry);\n56 +    this.logger.debug(`Cached key: ${key}`);\n57 +  }\n58 +\n59 +  delete(key: string): boolean {\n60 +    return this.cache.delete(key as unknown as object);\n61 +  }\n62 +\n63 +  getStats() {\n64 +    const total = this.hits + this.misses;\n65 +    return {\n66 +      hits: this.hits,\n67 +      misses: this.misses,\n68 +      hitRate: total > 0 ? this.hits / total : 0,\n69 +    };\n70 +  }\n71 +\n72 +  clear(): void {\n73 +    this.cache = new WeakMap();\n74 +    this.hits = 0;\n75 +    this.misses = 0;\n76 +  }\n77 +}\n78 +\n79 +export function createRequestCache<T>(options?: Partial<CacheOptions>) {\n80 +  return new RequestCache<T>(options);\n81 +}\n82 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/core/src/cache/RequestCache.ts\",\"relevantLinesStart\":17,\"relevantLinesEnd\":17}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"private readonly cache: WeakMap<object, CacheEntry<T>>;\",\n    \"improvedCode\": \"private readonly cache: Map<string, CacheEntry<T>>;\",\n    \"relevantFile\": \"packages/core/src/cache/RequestCache.ts\",\n    \"relevantLinesEnd\": 17,\n    \"suggestionContent\": \"WeakMap only accepts objects as keys, not primitive values like strings. The code casts strings to objects with `as unknown as object`, but this doesn't actually convert the string to an object - it just bypasses TypeScript's type checking. At runtime, WeakMap.set() will throw a TypeError when called with a string key. Use a regular Map instead of WeakMap for string keys, or if you need weak references, use the string as a property of a wrapper object.\",\n    \"oneSentenceSummary\": \"WeakMap cannot use primitive string keys - will throw TypeError at runtime\",\n    \"relevantLinesStart\": 17\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 3: packages/text/src/utils/TextTruncator.ts",
    "vars": {
      "fileContent": "export interface TruncateOptions {\n  maxLength: number;\n  ellipsis?: string;\n  wordBoundary?: boolean;\n  preserveWords?: boolean;\n}\n\nconst DEFAULT_ELLIPSIS = '...';\n\nexport function getCharacterCount(text: string): number {\n  return text.length;\n}\n\nexport function truncateText(\n  text: string,\n  options: TruncateOptions\n): string {\n  const {\n    maxLength,\n    ellipsis = DEFAULT_ELLIPSIS,\n    wordBoundary = false,\n  } = options;\n\n  if (text.length <= maxLength) {\n    return text;\n  }\n\n  const truncateAt = maxLength - ellipsis.length;\n\n  if (truncateAt <= 0) {\n    return ellipsis.slice(0, maxLength);\n  }\n\n  let truncated = text.slice(0, truncateAt);\n\n  if (wordBoundary) {\n    const lastSpace = truncated.lastIndexOf(' ');\n    if (lastSpace > truncateAt * 0.5) {\n      truncated = truncated.slice(0, lastSpace);\n    }\n  }\n\n  return truncated + ellipsis;\n}\n\nexport function truncateMiddle(\n  text: string,\n  maxLength: number,\n  separator: string = '...'\n): string {\n  if (text.length <= maxLength) {\n    return text;\n  }\n\n  const separatorLength = separator.length;\n  const charsToShow = maxLength - separatorLength;\n\n  if (charsToShow <= 0) {\n    return separator.slice(0, maxLength);\n  }\n\n  const frontChars = Math.ceil(charsToShow / 2);\n  const backChars = Math.floor(charsToShow / 2);\n\n  return text.slice(0, frontChars) + separator + text.slice(-backChars);\n}\n\nexport function countWords(text: string): number {\n  return text.trim().split(/\\s+/).filter(Boolean).length;\n}\n\nexport function truncateWords(\n  text: string,\n  maxWords: number,\n  ellipsis: string = DEFAULT_ELLIPSIS\n): string {\n  const words = text.trim().split(/\\s+/);\n\n  if (words.length <= maxWords) {\n    return text;\n  }\n\n  return words.slice(0, maxWords).join(' ') + ellipsis;\n}\n\nexport class TextTruncator {\n  private defaultOptions: TruncateOptions;\n\n  constructor(defaultOptions: Partial<TruncateOptions> = {}) {\n    this.defaultOptions = {\n      maxLength: 100,\n      ellipsis: DEFAULT_ELLIPSIS,\n      wordBoundary: true,\n      ...defaultOptions,\n    };\n  }\n\n  truncate(text: string, options?: Partial<TruncateOptions>): string {\n    return truncateText(text, { ...this.defaultOptions, ...options });\n  }\n\n  truncateForDisplay(text: string, maxLength: number): string {\n    return truncateText(text, {\n      ...this.defaultOptions,\n      maxLength,\n      wordBoundary: true,\n    });\n  }\n\n  getLength(text: string): number {\n    return getCharacterCount(text);\n  }\n\n  isWithinLimit(text: string, limit: number): boolean {\n    return this.getLength(text) <= limit;\n  }\n}\n\nexport default TextTruncator;\n",
      "patchWithLinesStr": "## file: 'packages/text/src/utils/TextTruncator.ts'\n\n@@ -0,0 +1,120 @@\n__new hunk__\n1 +export interface TruncateOptions {\n2 +  maxLength: number;\n3 +  ellipsis?: string;\n4 +  wordBoundary?: boolean;\n5 +  preserveWords?: boolean;\n6 +}\n7 +\n8 +const DEFAULT_ELLIPSIS = '...';\n9 +\n10 +export function getCharacterCount(text: string): number {\n11 +  return text.length;\n12 +}\n13 +\n14 +export function truncateText(\n15 +  text: string,\n16 +  options: TruncateOptions\n17 +): string {\n18 +  const {\n19 +    maxLength,\n20 +    ellipsis = DEFAULT_ELLIPSIS,\n21 +    wordBoundary = false,\n22 +  } = options;\n23 +\n24 +  if (text.length <= maxLength) {\n25 +    return text;\n26 +  }\n27 +\n28 +  const truncateAt = maxLength - ellipsis.length;\n29 +\n30 +  if (truncateAt <= 0) {\n31 +    return ellipsis.slice(0, maxLength);\n32 +  }\n33 +\n34 +  let truncated = text.slice(0, truncateAt);\n35 +\n36 +  if (wordBoundary) {\n37 +    const lastSpace = truncated.lastIndexOf(' ');\n38 +    if (lastSpace > truncateAt * 0.5) {\n39 +      truncated = truncated.slice(0, lastSpace);\n40 +    }\n41 +  }\n42 +\n43 +  return truncated + ellipsis;\n44 +}\n45 +\n46 +export function truncateMiddle(\n47 +  text: string,\n48 +  maxLength: number,\n49 +  separator: string = '...'\n50 +): string {\n51 +  if (text.length <= maxLength) {\n52 +    return text;\n53 +  }\n54 +\n55 +  const separatorLength = separator.length;\n56 +  const charsToShow = maxLength - separatorLength;\n57 +\n58 +  if (charsToShow <= 0) {\n59 +    return separator.slice(0, maxLength);\n60 +  }\n61 +\n62 +  const frontChars = Math.ceil(charsToShow / 2);\n63 +  const backChars = Math.floor(charsToShow / 2);\n64 +\n65 +  return text.slice(0, frontChars) + separator + text.slice(-backChars);\n66 +}\n67 +\n68 +export function countWords(text: string): number {\n69 +  return text.trim().split(/\\s+/).filter(Boolean).length;\n70 +}\n71 +\n72 +export function truncateWords(\n73 +  text: string,\n74 +  maxWords: number,\n75 +  ellipsis: string = DEFAULT_ELLIPSIS\n76 +): string {\n77 +  const words = text.trim().split(/\\s+/);\n78 +\n79 +  if (words.length <= maxWords) {\n80 +    return text;\n81 +  }\n82 +\n83 +  return words.slice(0, maxWords).join(' ') + ellipsis;\n84 +}\n85 +\n86 +export class TextTruncator {\n87 +  private defaultOptions: TruncateOptions;\n88 +\n89 +  constructor(defaultOptions: Partial<TruncateOptions> = {}) {\n90 +    this.defaultOptions = {\n91 +      maxLength: 100,\n92 +      ellipsis: DEFAULT_ELLIPSIS,\n93 +      wordBoundary: true,\n94 +      ...defaultOptions,\n95 +    };\n96 +  }\n97 +\n98 +  truncate(text: string, options?: Partial<TruncateOptions>): string {\n99 +    return truncateText(text, { ...this.defaultOptions, ...options });\n100 +  }\n101 +\n102 +  truncateForDisplay(text: string, maxLength: number): string {\n103 +    return truncateText(text, {\n104 +      ...this.defaultOptions,\n105 +      maxLength,\n106 +      wordBoundary: true,\n107 +    });\n108 +  }\n109 +\n110 +  getLength(text: string): number {\n111 +    return getCharacterCount(text);\n112 +  }\n113 +\n114 +  isWithinLimit(text: string, limit: number): boolean {\n115 +    return this.getLength(text) <= limit;\n116 +  }\n117 +}\n118 +\n119 +export default TextTruncator;\n120 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/text/src/utils/TextTruncator.ts\",\"relevantLinesStart\":10,\"relevantLinesEnd\":12}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"export function getCharacterCount(text: string): number {\\n  return text.length;\\n}\",\n    \"improvedCode\": \"export function getCharacterCount(text: string): number {\\n  return [...text].length;\\n}\",\n    \"relevantFile\": \"packages/text/src/utils/TextTruncator.ts\",\n    \"relevantLinesEnd\": 12,\n    \"suggestionContent\": \"The `getCharacterCount` function and all length checks use `string.length`, which counts UTF-16 code units, not actual characters (graphemes). This causes incorrect behavior with emojis, accented characters, and other Unicode text. For example, 'ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦' has `.length` of 11 but is visually 1 character; 'ðŸ‡ºðŸ‡¸' has `.length` of 4 but is 1 flag emoji. Text could be truncated in the middle of a multi-code-unit character, producing invalid Unicode or broken emoji. Use `Intl.Segmenter` or spread syntax `[...text].length` for accurate character counting.\",\n    \"oneSentenceSummary\": \"String.length counts UTF-16 code units not characters - breaks with emoji/Unicode\",\n    \"relevantLinesStart\": 10\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 4: packages/realtime/src/client/WebSocketManager.ts",
    "vars": {
      "fileContent": "export type MessageHandler = (data: unknown) => void;\nexport type ConnectionHandler = () => void;\nexport type ErrorHandler = (error: Event) => void;\n\nexport interface WebSocketConfig {\n  url: string;\n  protocols?: string[];\n  reconnectInterval: number;\n  maxReconnectAttempts: number;\n  heartbeatInterval: number;\n  messageQueueSize: number;\n}\n\nexport interface QueuedMessage {\n  data: string;\n  timestamp: number;\n  priority: number;\n}\n\nconst DEFAULT_CONFIG: Partial<WebSocketConfig> = {\n  reconnectInterval: 1000,\n  maxReconnectAttempts: 10,\n  heartbeatInterval: 30000,\n  messageQueueSize: 100,\n};\n\nexport class WebSocketManager {\n  private socket: WebSocket | null = null;\n  private config: WebSocketConfig;\n  private messageHandlers: Map<string, Set<MessageHandler>> = new Map();\n  private connectionHandlers: Set<ConnectionHandler> = new Set();\n  private errorHandlers: Set<ErrorHandler> = new Set();\n  private messageQueue: QueuedMessage[] = [];\n  private reconnectAttempts = 0;\n  private reconnectTimeout: NodeJS.Timeout | null = null;\n  private heartbeatInterval: NodeJS.Timeout | null = null;\n  private isConnecting = false;\n  private isIntentionallyClosed = false;\n\n  constructor(config: Partial<WebSocketConfig> & { url: string }) {\n    this.config = { ...DEFAULT_CONFIG, ...config } as WebSocketConfig;\n  }\n\n  connect(): void {\n    if (this.socket?.readyState === WebSocket.OPEN || this.isConnecting) {\n      return;\n    }\n\n    this.isConnecting = true;\n    this.isIntentionallyClosed = false;\n\n    try {\n      this.socket = new WebSocket(this.config.url, this.config.protocols);\n      this.setupEventHandlers();\n    } catch (error) {\n      this.isConnecting = false;\n      this.handleReconnect();\n    }\n  }\n\n  private setupEventHandlers(): void {\n    if (!this.socket) return;\n\n    this.socket.onopen = () => {\n      this.isConnecting = false;\n      this.reconnectAttempts = 0;\n      this.startHeartbeat();\n      this.flushMessageQueue();\n      this.connectionHandlers.forEach(handler => handler());\n    };\n\n    this.socket.onmessage = (event) => {\n      try {\n        const message = JSON.parse(event.data);\n        const type = message.type || 'default';\n        const handlers = this.messageHandlers.get(type);\n\n        if (handlers) {\n          handlers.forEach(handler => handler(message.payload));\n        }\n      } catch (error) {\n        console.error('Failed to parse WebSocket message:', error);\n      }\n    };\n\n    this.socket.onclose = (event) => {\n      this.stopHeartbeat();\n      this.isConnecting = false;\n\n      if (!this.isIntentionallyClosed && !event.wasClean) {\n        this.handleReconnect();\n      }\n    };\n\n    this.socket.onerror = (error) => {\n      this.errorHandlers.forEach(handler => handler(error));\n    };\n  }\n\n  private handleReconnect(): void {\n    if (this.reconnectAttempts >= this.config.maxReconnectAttempts) {\n      console.error('Max reconnection attempts reached');\n      return;\n    }\n\n    const delay = this.config.reconnectInterval * Math.pow(2, this.reconnectAttempts);\n    this.reconnectAttempts++;\n\n    this.reconnectTimeout = setTimeout(() => {\n      this.connect();\n    }, delay);\n  }\n\n  private startHeartbeat(): void {\n    this.heartbeatInterval = setInterval(() => {\n      if (this.socket?.readyState === WebSocket.OPEN) {\n        this.socket.send(JSON.stringify({ type: 'ping' }));\n      }\n    }, this.config.heartbeatInterval);\n  }\n\n  private stopHeartbeat(): void {\n    if (this.heartbeatInterval) {\n      clearInterval(this.heartbeatInterval);\n    }\n  }\n\n  private flushMessageQueue(): void {\n    while (this.messageQueue.length > 0 && this.socket?.readyState === WebSocket.OPEN) {\n      const message = this.messageQueue.shift();\n      if (message) {\n        this.socket.send(message.data);\n      }\n    }\n  }\n\n  send(type: string, payload: unknown, priority = 0): boolean {\n    const message = JSON.stringify({ type, payload });\n\n    if (this.socket?.readyState === WebSocket.OPEN) {\n      this.socket.send(message);\n      return true;\n    }\n\n    if (this.messageQueue.length < this.config.messageQueueSize) {\n      this.messageQueue.push({\n        data: message,\n        timestamp: Date.now(),\n        priority,\n      });\n      this.messageQueue.sort((a, b) => b.priority - a.priority);\n      return true;\n    }\n\n    return false;\n  }\n\n  on(type: string, handler: MessageHandler): () => void {\n    if (!this.messageHandlers.has(type)) {\n      this.messageHandlers.set(type, new Set());\n    }\n    this.messageHandlers.get(type)!.add(handler);\n\n    return () => {\n      this.messageHandlers.get(type)?.delete(handler);\n    };\n  }\n\n  onConnect(handler: ConnectionHandler): () => void {\n    this.connectionHandlers.add(handler);\n    return () => this.connectionHandlers.delete(handler);\n  }\n\n  onError(handler: ErrorHandler): () => void {\n    this.errorHandlers.add(handler);\n    return () => this.errorHandlers.delete(handler);\n  }\n\n  disconnect(): void {\n    this.isIntentionallyClosed = true;\n\n    if (this.reconnectTimeout) {\n      clearTimeout(this.reconnectTimeout);\n    }\n\n    this.stopHeartbeat();\n\n    if (this.socket) {\n      this.socket.close();\n      this.socket = null;\n    }\n  }\n\n  getReadyState(): number {\n    return this.socket?.readyState ?? WebSocket.CLOSED;\n  }\n\n  isConnected(): boolean {\n    return this.socket?.readyState === WebSocket.OPEN;\n  }\n}\n\nexport function createWebSocketManager(\n  config: Partial<WebSocketConfig> & { url: string }\n): WebSocketManager {\n  return new WebSocketManager(config);\n}\n",
      "patchWithLinesStr": "## file: 'packages/realtime/src/client/WebSocketManager.ts'\n\n@@ -0,0 +1,208 @@\n__new hunk__\n1 +export type MessageHandler = (data: unknown) => void;\n2 +export type ConnectionHandler = () => void;\n3 +export type ErrorHandler = (error: Event) => void;\n4 +\n5 +export interface WebSocketConfig {\n6 +  url: string;\n7 +  protocols?: string[];\n8 +  reconnectInterval: number;\n9 +  maxReconnectAttempts: number;\n10 +  heartbeatInterval: number;\n11 +  messageQueueSize: number;\n12 +}\n13 +\n14 +export interface QueuedMessage {\n15 +  data: string;\n16 +  timestamp: number;\n17 +  priority: number;\n18 +}\n19 +\n20 +const DEFAULT_CONFIG: Partial<WebSocketConfig> = {\n21 +  reconnectInterval: 1000,\n22 +  maxReconnectAttempts: 10,\n23 +  heartbeatInterval: 30000,\n24 +  messageQueueSize: 100,\n25 +};\n26 +\n27 +export class WebSocketManager {\n28 +  private socket: WebSocket | null = null;\n29 +  private config: WebSocketConfig;\n30 +  private messageHandlers: Map<string, Set<MessageHandler>> = new Map();\n31 +  private connectionHandlers: Set<ConnectionHandler> = new Set();\n32 +  private errorHandlers: Set<ErrorHandler> = new Set();\n33 +  private messageQueue: QueuedMessage[] = [];\n34 +  private reconnectAttempts = 0;\n35 +  private reconnectTimeout: NodeJS.Timeout | null = null;\n36 +  private heartbeatInterval: NodeJS.Timeout | null = null;\n37 +  private isConnecting = false;\n38 +  private isIntentionallyClosed = false;\n39 +\n40 +  constructor(config: Partial<WebSocketConfig> & { url: string }) {\n41 +    this.config = { ...DEFAULT_CONFIG, ...config } as WebSocketConfig;\n42 +  }\n43 +\n44 +  connect(): void {\n45 +    if (this.socket?.readyState === WebSocket.OPEN || this.isConnecting) {\n46 +      return;\n47 +    }\n48 +\n49 +    this.isConnecting = true;\n50 +    this.isIntentionallyClosed = false;\n51 +\n52 +    try {\n53 +      this.socket = new WebSocket(this.config.url, this.config.protocols);\n54 +      this.setupEventHandlers();\n55 +    } catch (error) {\n56 +      this.isConnecting = false;\n57 +      this.handleReconnect();\n58 +    }\n59 +  }\n60 +\n61 +  private setupEventHandlers(): void {\n62 +    if (!this.socket) return;\n63 +\n64 +    this.socket.onopen = () => {\n65 +      this.isConnecting = false;\n66 +      this.reconnectAttempts = 0;\n67 +      this.startHeartbeat();\n68 +      this.flushMessageQueue();\n69 +      this.connectionHandlers.forEach(handler => handler());\n70 +    };\n71 +\n72 +    this.socket.onmessage = (event) => {\n73 +      try {\n74 +        const message = JSON.parse(event.data);\n75 +        const type = message.type || 'default';\n76 +        const handlers = this.messageHandlers.get(type);\n77 +\n78 +        if (handlers) {\n79 +          handlers.forEach(handler => handler(message.payload));\n80 +        }\n81 +      } catch (error) {\n82 +        console.error('Failed to parse WebSocket message:', error);\n83 +      }\n84 +    };\n85 +\n86 +    this.socket.onclose = (event) => {\n87 +      this.stopHeartbeat();\n88 +      this.isConnecting = false;\n89 +\n90 +      if (!this.isIntentionallyClosed && !event.wasClean) {\n91 +        this.handleReconnect();\n92 +      }\n93 +    };\n94 +\n95 +    this.socket.onerror = (error) => {\n96 +      this.errorHandlers.forEach(handler => handler(error));\n97 +    };\n98 +  }\n99 +\n100 +  private handleReconnect(): void {\n101 +    if (this.reconnectAttempts >= this.config.maxReconnectAttempts) {\n102 +      console.error('Max reconnection attempts reached');\n103 +      return;\n104 +    }\n105 +\n106 +    const delay = this.config.reconnectInterval * Math.pow(2, this.reconnectAttempts);\n107 +    this.reconnectAttempts++;\n108 +\n109 +    this.reconnectTimeout = setTimeout(() => {\n110 +      this.connect();\n111 +    }, delay);\n112 +  }\n113 +\n114 +  private startHeartbeat(): void {\n115 +    this.heartbeatInterval = setInterval(() => {\n116 +      if (this.socket?.readyState === WebSocket.OPEN) {\n117 +        this.socket.send(JSON.stringify({ type: 'ping' }));\n118 +      }\n119 +    }, this.config.heartbeatInterval);\n120 +  }\n121 +\n122 +  private stopHeartbeat(): void {\n123 +    if (this.heartbeatInterval) {\n124 +      clearInterval(this.heartbeatInterval);\n125 +    }\n126 +  }\n127 +\n128 +  private flushMessageQueue(): void {\n129 +    while (this.messageQueue.length > 0 && this.socket?.readyState === WebSocket.OPEN) {\n130 +      const message = this.messageQueue.shift();\n131 +      if (message) {\n132 +        this.socket.send(message.data);\n133 +      }\n134 +    }\n135 +  }\n136 +\n137 +  send(type: string, payload: unknown, priority = 0): boolean {\n138 +    const message = JSON.stringify({ type, payload });\n139 +\n140 +    if (this.socket?.readyState === WebSocket.OPEN) {\n141 +      this.socket.send(message);\n142 +      return true;\n143 +    }\n144 +\n145 +    if (this.messageQueue.length < this.config.messageQueueSize) {\n146 +      this.messageQueue.push({\n147 +        data: message,\n148 +        timestamp: Date.now(),\n149 +        priority,\n150 +      });\n151 +      this.messageQueue.sort((a, b) => b.priority - a.priority);\n152 +      return true;\n153 +    }\n154 +\n155 +    return false;\n156 +  }\n157 +\n158 +  on(type: string, handler: MessageHandler): () => void {\n159 +    if (!this.messageHandlers.has(type)) {\n160 +      this.messageHandlers.set(type, new Set());\n161 +    }\n162 +    this.messageHandlers.get(type)!.add(handler);\n163 +\n164 +    return () => {\n165 +      this.messageHandlers.get(type)?.delete(handler);\n166 +    };\n167 +  }\n168 +\n169 +  onConnect(handler: ConnectionHandler): () => void {\n170 +    this.connectionHandlers.add(handler);\n171 +    return () => this.connectionHandlers.delete(handler);\n172 +  }\n173 +\n174 +  onError(handler: ErrorHandler): () => void {\n175 +    this.errorHandlers.add(handler);\n176 +    return () => this.errorHandlers.delete(handler);\n177 +  }\n178 +\n179 +  disconnect(): void {\n180 +    this.isIntentionallyClosed = true;\n181 +\n182 +    if (this.reconnectTimeout) {\n183 +      clearTimeout(this.reconnectTimeout);\n184 +    }\n185 +\n186 +    this.stopHeartbeat();\n187 +\n188 +    if (this.socket) {\n189 +      this.socket.close();\n190 +      this.socket = null;\n191 +    }\n192 +  }\n193 +\n194 +  getReadyState(): number {\n195 +    return this.socket?.readyState ?? WebSocket.CLOSED;\n196 +  }\n197 +\n198 +  isConnected(): boolean {\n199 +    return this.socket?.readyState === WebSocket.OPEN;\n200 +  }\n201 +}\n202 +\n203 +export function createWebSocketManager(\n204 +  config: Partial<WebSocketConfig> & { url: string }\n205 +): WebSocketManager {\n206 +  return new WebSocketManager(config);\n207 +}\n208 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/realtime/src/client/WebSocketManager.ts\",\"relevantLinesStart\":108,\"relevantLinesEnd\":112},{\"relevantFile\":\"packages/realtime/src/client/WebSocketManager.ts\",\"relevantLinesStart\":91,\"relevantLinesEnd\":100},{\"relevantFile\":\"packages/realtime/src/client/WebSocketManager.ts\",\"relevantLinesStart\":131,\"relevantLinesEnd\":138}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"private stopHeartbeat(): void {\\n    if (this.heartbeatInterval) {\\n      clearInterval(this.heartbeatInterval);\\n    }\\n  }\",\n    \"improvedCode\": \"private stopHeartbeat(): void {\\n    if (this.heartbeatInterval) {\\n      clearInterval(this.heartbeatInterval);\\n      this.heartbeatInterval = null;\\n    }\\n  }\",\n    \"relevantFile\": \"packages/realtime/src/client/WebSocketManager.ts\",\n    \"relevantLinesEnd\": 112,\n    \"suggestionContent\": \"The `stopHeartbeat` method clears the interval but doesn't set `this.heartbeatInterval` to null. When `startHeartbeat` is called again after reconnection, it creates a new interval without clearing the previous one (which may still exist if the reference wasn't properly cleaned). This can cause multiple heartbeat intervals running simultaneously after several reconnects.\",\n    \"oneSentenceSummary\": \"Heartbeat interval not nullified after clear - multiple intervals after reconnects\",\n    \"relevantLinesStart\": 108\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"private handleReconnect(): void {\\n    if (this.reconnectAttempts >= this.config.maxReconnectAttempts) {\\n      console.error('Max reconnection attempts reached');\\n      return;\\n    }\\n\\n    const delay = this.config.reconnectInterval * Math.pow(2, this.reconnectAttempts);\\n    this.reconnectAttempts++;\\n\\n    this.reconnectTimeout = setTimeout(() => {\",\n    \"improvedCode\": \"private handleReconnect(): void {\\n    if (this.reconnectAttempts >= this.config.maxReconnectAttempts) {\\n      console.error('Max reconnection attempts reached');\\n      return;\\n    }\\n\\n    if (this.reconnectTimeout) {\\n      clearTimeout(this.reconnectTimeout);\\n    }\\n\\n    const delay = this.config.reconnectInterval * Math.pow(2, this.reconnectAttempts);\\n    this.reconnectAttempts++;\\n\\n    this.reconnectTimeout = setTimeout(() => {\",\n    \"relevantFile\": \"packages/realtime/src/client/WebSocketManager.ts\",\n    \"relevantLinesEnd\": 100,\n    \"suggestionContent\": \"The `handleReconnect` method doesn't clear an existing `reconnectTimeout` before setting a new one. If `handleReconnect` is called multiple times quickly (e.g., due to rapid close/error events), multiple reconnection timeouts will be scheduled, causing multiple simultaneous connection attempts.\",\n    \"oneSentenceSummary\": \"Missing timeout clear before reconnect - multiple concurrent reconnection attempts\",\n    \"relevantLinesStart\": 91\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"if (this.messageQueue.length < this.config.messageQueueSize) {\\n      this.messageQueue.push({\\n        data: message,\\n        timestamp: Date.now(),\\n        priority,\\n      });\\n      this.messageQueue.sort((a, b) => b.priority - a.priority);\\n      return true;\\n    }\",\n    \"improvedCode\": \"if (this.messageQueue.length < this.config.messageQueueSize) {\\n      // Remove expired messages (older than 30 seconds)\\n      const now = Date.now();\\n      this.messageQueue = this.messageQueue.filter(m => now - m.timestamp < 30000);\\n      \\n      this.messageQueue.push({\\n        data: message,\\n        timestamp: now,\\n        priority,\\n      });\\n      this.messageQueue.sort((a, b) => b.priority - a.priority);\\n      return true;\\n    }\",\n    \"relevantFile\": \"packages/realtime/src/client/WebSocketManager.ts\",\n    \"relevantLinesEnd\": 138,\n    \"suggestionContent\": \"The message queue's `sort` by priority is called every time a message is added, which is O(n log n). More importantly, when flushing the queue with `shift()`, messages are dequeued in array order, not priority order since shift() removes from the front but sort() put highest priority at the front - wait, that's correct. However, there's still an issue: the queue doesn't expire old messages. Messages queued while offline could be sent much later when they're no longer relevant, causing stale data issues.\",\n    \"oneSentenceSummary\": \"Message queue never expires old messages - stale data sent after reconnection\",\n    \"relevantLinesStart\": 131\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 5: packages/validation/src/validators/InputValidator.ts",
    "vars": {
      "fileContent": "export interface ValidationResult {\n  isValid: boolean;\n  errors: string[];\n}\n\nexport interface ValidationRule {\n  name: string;\n  validate: (value: string) => boolean;\n  message: string;\n}\n\nconst PATTERNS = {\n  email: /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$/g,\n  phone: /^\\+?[1-9]\\d{1,14}$/g,\n  slug: /^[a-z0-9]+(?:-[a-z0-9]+)*$/g,\n  username: /^[a-zA-Z][a-zA-Z0-9_]{2,29}$/g,\n  alphanumeric: /^[a-zA-Z0-9]+$/g,\n  numeric: /^\\d+$/g,\n  url: /^https?:\\/\\/[^\\s/$.?#].[^\\s]*$/gi,\n};\n\nexport function validateEmail(email: string): boolean {\n  return PATTERNS.email.test(email);\n}\n\nexport function validatePhone(phone: string): boolean {\n  return PATTERNS.phone.test(phone);\n}\n\nexport function validateSlug(slug: string): boolean {\n  return PATTERNS.slug.test(slug);\n}\n\nexport function validateUsername(username: string): boolean {\n  return PATTERNS.username.test(username);\n}\n\nexport function validateUrl(url: string): boolean {\n  return PATTERNS.url.test(url);\n}\n\nexport function validateField(\n  value: string,\n  rules: ValidationRule[]\n): ValidationResult {\n  const errors: string[] = [];\n\n  for (const rule of rules) {\n    if (!rule.validate(value)) {\n      errors.push(rule.message);\n    }\n  }\n\n  return {\n    isValid: errors.length === 0,\n    errors,\n  };\n}\n\nexport function createPatternRule(\n  name: string,\n  pattern: RegExp,\n  message: string\n): ValidationRule {\n  return {\n    name,\n    validate: (value: string) => pattern.test(value),\n    message,\n  };\n}\n\nexport class InputValidator {\n  private rules: Map<string, ValidationRule[]> = new Map();\n\n  addRule(fieldName: string, rule: ValidationRule): this {\n    const existing = this.rules.get(fieldName) ?? [];\n    existing.push(rule);\n    this.rules.set(fieldName, existing);\n    return this;\n  }\n\n  addEmailRule(fieldName: string, message?: string): this {\n    return this.addRule(fieldName, {\n      name: 'email',\n      validate: validateEmail,\n      message: message ?? 'Invalid email address',\n    });\n  }\n\n  addPhoneRule(fieldName: string, message?: string): this {\n    return this.addRule(fieldName, {\n      name: 'phone',\n      validate: validatePhone,\n      message: message ?? 'Invalid phone number',\n    });\n  }\n\n  addSlugRule(fieldName: string, message?: string): this {\n    return this.addRule(fieldName, {\n      name: 'slug',\n      validate: validateSlug,\n      message: message ?? 'Invalid slug format',\n    });\n  }\n\n  validate(fieldName: string, value: string): ValidationResult {\n    const rules = this.rules.get(fieldName);\n    if (!rules) {\n      return { isValid: true, errors: [] };\n    }\n    return validateField(value, rules);\n  }\n\n  validateAll(data: Record<string, string>): Map<string, ValidationResult> {\n    const results = new Map<string, ValidationResult>();\n\n    for (const [fieldName, value] of Object.entries(data)) {\n      results.set(fieldName, this.validate(fieldName, value));\n    }\n\n    return results;\n  }\n}\n\nexport const defaultValidator = new InputValidator();\n",
      "patchWithLinesStr": "## file: 'packages/validation/src/validators/InputValidator.ts'\n\n@@ -0,0 +1,126 @@\n__new hunk__\n1 +export interface ValidationResult {\n2 +  isValid: boolean;\n3 +  errors: string[];\n4 +}\n5 +\n6 +export interface ValidationRule {\n7 +  name: string;\n8 +  validate: (value: string) => boolean;\n9 +  message: string;\n10 +}\n11 +\n12 +const PATTERNS = {\n13 +  email: /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$/g,\n14 +  phone: /^\\+?[1-9]\\d{1,14}$/g,\n15 +  slug: /^[a-z0-9]+(?:-[a-z0-9]+)*$/g,\n16 +  username: /^[a-zA-Z][a-zA-Z0-9_]{2,29}$/g,\n17 +  alphanumeric: /^[a-zA-Z0-9]+$/g,\n18 +  numeric: /^\\d+$/g,\n19 +  url: /^https?:\\/\\/[^\\s/$.?#].[^\\s]*$/gi,\n20 +};\n21 +\n22 +export function validateEmail(email: string): boolean {\n23 +  return PATTERNS.email.test(email);\n24 +}\n25 +\n26 +export function validatePhone(phone: string): boolean {\n27 +  return PATTERNS.phone.test(phone);\n28 +}\n29 +\n30 +export function validateSlug(slug: string): boolean {\n31 +  return PATTERNS.slug.test(slug);\n32 +}\n33 +\n34 +export function validateUsername(username: string): boolean {\n35 +  return PATTERNS.username.test(username);\n36 +}\n37 +\n38 +export function validateUrl(url: string): boolean {\n39 +  return PATTERNS.url.test(url);\n40 +}\n41 +\n42 +export function validateField(\n43 +  value: string,\n44 +  rules: ValidationRule[]\n45 +): ValidationResult {\n46 +  const errors: string[] = [];\n47 +\n48 +  for (const rule of rules) {\n49 +    if (!rule.validate(value)) {\n50 +      errors.push(rule.message);\n51 +    }\n52 +  }\n53 +\n54 +  return {\n55 +    isValid: errors.length === 0,\n56 +    errors,\n57 +  };\n58 +}\n59 +\n60 +export function createPatternRule(\n61 +  name: string,\n62 +  pattern: RegExp,\n63 +  message: string\n64 +): ValidationRule {\n65 +  return {\n66 +    name,\n67 +    validate: (value: string) => pattern.test(value),\n68 +    message,\n69 +  };\n70 +}\n71 +\n72 +export class InputValidator {\n73 +  private rules: Map<string, ValidationRule[]> = new Map();\n74 +\n75 +  addRule(fieldName: string, rule: ValidationRule): this {\n76 +    const existing = this.rules.get(fieldName) ?? [];\n77 +    existing.push(rule);\n78 +    this.rules.set(fieldName, existing);\n79 +    return this;\n80 +  }\n81 +\n82 +  addEmailRule(fieldName: string, message?: string): this {\n83 +    return this.addRule(fieldName, {\n84 +      name: 'email',\n85 +      validate: validateEmail,\n86 +      message: message ?? 'Invalid email address',\n87 +    });\n88 +  }\n89 +\n90 +  addPhoneRule(fieldName: string, message?: string): this {\n91 +    return this.addRule(fieldName, {\n92 +      name: 'phone',\n93 +      validate: validatePhone,\n94 +      message: message ?? 'Invalid phone number',\n95 +    });\n96 +  }\n97 +\n98 +  addSlugRule(fieldName: string, message?: string): this {\n99 +    return this.addRule(fieldName, {\n100 +      name: 'slug',\n101 +      validate: validateSlug,\n102 +      message: message ?? 'Invalid slug format',\n103 +    });\n104 +  }\n105 +\n106 +  validate(fieldName: string, value: string): ValidationResult {\n107 +    const rules = this.rules.get(fieldName);\n108 +    if (!rules) {\n109 +      return { isValid: true, errors: [] };\n110 +    }\n111 +    return validateField(value, rules);\n112 +  }\n113 +\n114 +  validateAll(data: Record<string, string>): Map<string, ValidationResult> {\n115 +    const results = new Map<string, ValidationResult>();\n116 +\n117 +    for (const [fieldName, value] of Object.entries(data)) {\n118 +      results.set(fieldName, this.validate(fieldName, value));\n119 +    }\n120 +\n121 +    return results;\n122 +  }\n123 +}\n124 +\n125 +export const defaultValidator = new InputValidator();\n126 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/validation/src/validators/InputValidator.ts\",\"relevantLinesStart\":13,\"relevantLinesEnd\":20}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"const PATTERNS = {\\n  email: /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$/g,\\n  phone: /^\\\\+?[1-9]\\\\d{1,14}$/g,\\n  slug: /^[a-z0-9]+(?:-[a-z0-9]+)*$/g,\",\n    \"improvedCode\": \"const PATTERNS = {\\n  email: /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$/,\\n  phone: /^\\\\+?[1-9]\\\\d{1,14}$/,\\n  slug: /^[a-z0-9]+(?:-[a-z0-9]+)*$/,\",\n    \"relevantFile\": \"packages/validation/src/validators/InputValidator.ts\",\n    \"relevantLinesEnd\": 20,\n    \"suggestionContent\": \"All regex patterns in PATTERNS object have the global flag (`/g`), which causes them to maintain state via `lastIndex`. When `test()` is called multiple times on the same regex, it alternates between true/false because `lastIndex` advances after each match. For example, `validateEmail('test@test.com')` will return true, then false, then true on consecutive calls. Remove the `g` flag from patterns used with `.test()` or create new RegExp instances for each validation.\",\n    \"oneSentenceSummary\": \"RegExp global flag causes validation to alternate true/false on repeated calls\",\n    \"relevantLinesStart\": 13\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 6: packages/data/src/sorting/ProductSorter.ts",
    "vars": {
      "fileContent": "export interface Product {\n  id: string;\n  name: string;\n  price: number;\n  category: string;\n  rating: number | null;\n  reviewCount: number;\n  inStock: boolean;\n  createdAt: Date;\n}\n\nexport type SortField = 'name' | 'price' | 'rating' | 'reviewCount' | 'createdAt';\nexport type SortDirection = 'asc' | 'desc';\n\ninterface SortConfig {\n  field: SortField;\n  direction: SortDirection;\n}\n\nfunction compareValues(a: unknown, b: unknown, direction: SortDirection): number {\n  const modifier = direction === 'asc' ? 1 : -1;\n\n  if (a === null || a === undefined) return 1;\n  if (b === null || b === undefined) return -1;\n\n  if (typeof a === 'string' && typeof b === 'string') {\n    return a.localeCompare(b) * modifier;\n  }\n\n  if (typeof a === 'number' && typeof b === 'number') {\n    return (a - b) * modifier;\n  }\n\n  if (a instanceof Date && b instanceof Date) {\n    return (a.getTime() - b.getTime()) * modifier;\n  }\n\n  return 0;\n}\n\nexport function sortProducts(\n  products: Product[],\n  configs: SortConfig[]\n): Product[] {\n  if (configs.length === 0) return products;\n\n  return [...products].sort((a, b) => {\n    for (const config of configs) {\n      const aValue = a[config.field];\n      const bValue = b[config.field];\n      const result = compareValues(aValue, bValue, config.direction);\n      if (result !== 0) return result;\n    }\n    return 0;\n  });\n}\n\nexport function sortByPopularity(products: Product[]): Product[] {\n  return [...products].sort((a, b) => {\n    const aScore = (a.rating ?? 0) * Math.log(a.reviewCount + 1);\n    const bScore = (b.rating ?? 0) * Math.log(b.reviewCount + 1);\n    return bScore - aScore;\n  });\n}\n\nexport function sortByRelevance(\n  products: Product[],\n  searchTerm: string\n): Product[] {\n  const term = searchTerm.toLowerCase();\n\n  return [...products].sort((a, b) => {\n    const aNameMatch = a.name.toLowerCase().includes(term);\n    const bNameMatch = b.name.toLowerCase().includes(term);\n\n    if (aNameMatch && !bNameMatch) return -1;\n    if (!aNameMatch && bNameMatch) return 1;\n\n    const aExact = a.name.toLowerCase() === term;\n    const bExact = b.name.toLowerCase() === term;\n\n    if (aExact && !bExact) return -1;\n    if (!aExact && bExact) return 1;\n\n    return (b.rating ?? 0) - (a.rating ?? 0);\n  });\n}\n\nexport class ProductSorter {\n  private defaultConfigs: SortConfig[] = [];\n\n  setDefaults(configs: SortConfig[]): void {\n    this.defaultConfigs = configs;\n  }\n\n  sort(products: Product[], configs?: SortConfig[]): Product[] {\n    return sortProducts(products, configs ?? this.defaultConfigs);\n  }\n}\n",
      "patchWithLinesStr": "## file: 'packages/data/src/sorting/ProductSorter.ts'\n\n@@ -0,0 +1,100 @@\n__new hunk__\n1 +export interface Product {\n2 +  id: string;\n3 +  name: string;\n4 +  price: number;\n5 +  category: string;\n6 +  rating: number | null;\n7 +  reviewCount: number;\n8 +  inStock: boolean;\n9 +  createdAt: Date;\n10 +}\n11 +\n12 +export type SortField = 'name' | 'price' | 'rating' | 'reviewCount' | 'createdAt';\n13 +export type SortDirection = 'asc' | 'desc';\n14 +\n15 +interface SortConfig {\n16 +  field: SortField;\n17 +  direction: SortDirection;\n18 +}\n19 +\n20 +function compareValues(a: unknown, b: unknown, direction: SortDirection): number {\n21 +  const modifier = direction === 'asc' ? 1 : -1;\n22 +\n23 +  if (a === null || a === undefined) return 1;\n24 +  if (b === null || b === undefined) return -1;\n25 +\n26 +  if (typeof a === 'string' && typeof b === 'string') {\n27 +    return a.localeCompare(b) * modifier;\n28 +  }\n29 +\n30 +  if (typeof a === 'number' && typeof b === 'number') {\n31 +    return (a - b) * modifier;\n32 +  }\n33 +\n34 +  if (a instanceof Date && b instanceof Date) {\n35 +    return (a.getTime() - b.getTime()) * modifier;\n36 +  }\n37 +\n38 +  return 0;\n39 +}\n40 +\n41 +export function sortProducts(\n42 +  products: Product[],\n43 +  configs: SortConfig[]\n44 +): Product[] {\n45 +  if (configs.length === 0) return products;\n46 +\n47 +  return [...products].sort((a, b) => {\n48 +    for (const config of configs) {\n49 +      const aValue = a[config.field];\n50 +      const bValue = b[config.field];\n51 +      const result = compareValues(aValue, bValue, config.direction);\n52 +      if (result !== 0) return result;\n53 +    }\n54 +    return 0;\n55 +  });\n56 +}\n57 +\n58 +export function sortByPopularity(products: Product[]): Product[] {\n59 +  return [...products].sort((a, b) => {\n60 +    const aScore = (a.rating ?? 0) * Math.log(a.reviewCount + 1);\n61 +    const bScore = (b.rating ?? 0) * Math.log(b.reviewCount + 1);\n62 +    return bScore - aScore;\n63 +  });\n64 +}\n65 +\n66 +export function sortByRelevance(\n67 +  products: Product[],\n68 +  searchTerm: string\n69 +): Product[] {\n70 +  const term = searchTerm.toLowerCase();\n71 +\n72 +  return [...products].sort((a, b) => {\n73 +    const aNameMatch = a.name.toLowerCase().includes(term);\n74 +    const bNameMatch = b.name.toLowerCase().includes(term);\n75 +\n76 +    if (aNameMatch && !bNameMatch) return -1;\n77 +    if (!aNameMatch && bNameMatch) return 1;\n78 +\n79 +    const aExact = a.name.toLowerCase() === term;\n80 +    const bExact = b.name.toLowerCase() === term;\n81 +\n82 +    if (aExact && !bExact) return -1;\n83 +    if (!aExact && bExact) return 1;\n84 +\n85 +    return (b.rating ?? 0) - (a.rating ?? 0);\n86 +  });\n87 +}\n88 +\n89 +export class ProductSorter {\n90 +  private defaultConfigs: SortConfig[] = [];\n91 +\n92 +  setDefaults(configs: SortConfig[]): void {\n93 +    this.defaultConfigs = configs;\n94 +  }\n95 +\n96 +  sort(products: Product[], configs?: SortConfig[]): Product[] {\n97 +    return sortProducts(products, configs ?? this.defaultConfigs);\n98 +  }\n99 +}\n100 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/data/src/sorting/ProductSorter.ts\",\"relevantLinesStart\":21,\"relevantLinesEnd\":23}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"if (a === null || a === undefined) return 1;\\n  if (b === null || b === undefined) return -1;\",\n    \"improvedCode\": \"if (a === null || a === undefined) {\\n    return b === null || b === undefined ? 0 : 1;\\n  }\\n  if (b === null || b === undefined) return -1;\",\n    \"relevantFile\": \"packages/data/src/sorting/ProductSorter.ts\",\n    \"relevantLinesEnd\": 23,\n    \"suggestionContent\": \"The `compareValues` function returns inconsistent values when comparing null/undefined values, violating the sort comparator contract. When `a` is null it returns 1, and when `b` is null it returns -1. But when both are null, neither condition triggers and it falls through to return 0. However, if you have [null, 1, null], comparing positions 0-1 says null>1, but comparing 1-2 says 1>null, creating an inconsistent ordering that can cause Array.sort to produce unpredictable results or infinite loops in some JS engines.\",\n    \"oneSentenceSummary\": \"Sort comparator violates transitivity when handling null values causing unstable sort\",\n    \"relevantLinesStart\": 21\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 7: packages/network/src/utils/withTimeout.ts",
    "vars": {
      "fileContent": "import { NetworkError } from '../errors/NetworkError';\n\ninterface TimeoutOptions {\n  timeoutMs: number;\n  errorMessage?: string;\n  onTimeout?: () => void;\n}\n\ntype Awaitable<T> = T | Promise<T>;\n\nexport class TimeoutError extends Error {\n  readonly code = 'TIMEOUT';\n\n  constructor(message: string, public readonly timeoutMs: number) {\n    super(message);\n    this.name = 'TimeoutError';\n  }\n}\n\nfunction createTimeoutPromise(ms: number, message: string): Promise<never> {\n  return new Promise((_, reject) => {\n    setTimeout(() => {\n      reject(new TimeoutError(message, ms));\n    }, ms);\n  });\n}\n\nexport async function withTimeout<T>(\n  operation: Awaitable<T>,\n  options: TimeoutOptions\n): Promise<T> {\n  const { timeoutMs, errorMessage, onTimeout } = options;\n\n  const timeoutPromise = createTimeoutPromise(\n    timeoutMs,\n    errorMessage ?? `Operation timed out after ${timeoutMs}ms`\n  );\n\n  try {\n    const result = await Promise.race([\n      Promise.resolve(operation),\n      timeoutPromise,\n    ]);\n    return result;\n  } catch (error) {\n    if (error instanceof TimeoutError) {\n      onTimeout?.();\n    }\n    throw error;\n  }\n}\n\nexport async function withRetryAndTimeout<T>(\n  operation: () => Promise<T>,\n  options: {\n    timeoutMs: number;\n    maxRetries: number;\n    retryDelayMs: number;\n  }\n): Promise<T> {\n  let lastError: Error | undefined;\n\n  for (let attempt = 0; attempt <= options.maxRetries; attempt++) {\n    try {\n      return await withTimeout(operation(), {\n        timeoutMs: options.timeoutMs,\n      });\n    } catch (error) {\n      lastError = error as Error;\n      if (attempt < options.maxRetries) {\n        await new Promise(resolve => setTimeout(resolve, options.retryDelayMs));\n      }\n    }\n  }\n\n  throw lastError ?? new NetworkError('All retries exhausted');\n}\n\nexport function isTimeoutError(error: unknown): error is TimeoutError {\n  return error instanceof TimeoutError;\n}\n",
      "patchWithLinesStr": "## file: 'packages/network/src/utils/withTimeout.ts'\n\n@@ -0,0 +1,82 @@\n__new hunk__\n1 +import { NetworkError } from '../errors/NetworkError';\n2 +\n3 +interface TimeoutOptions {\n4 +  timeoutMs: number;\n5 +  errorMessage?: string;\n6 +  onTimeout?: () => void;\n7 +}\n8 +\n9 +type Awaitable<T> = T | Promise<T>;\n10 +\n11 +export class TimeoutError extends Error {\n12 +  readonly code = 'TIMEOUT';\n13 +\n14 +  constructor(message: string, public readonly timeoutMs: number) {\n15 +    super(message);\n16 +    this.name = 'TimeoutError';\n17 +  }\n18 +}\n19 +\n20 +function createTimeoutPromise(ms: number, message: string): Promise<never> {\n21 +  return new Promise((_, reject) => {\n22 +    setTimeout(() => {\n23 +      reject(new TimeoutError(message, ms));\n24 +    }, ms);\n25 +  });\n26 +}\n27 +\n28 +export async function withTimeout<T>(\n29 +  operation: Awaitable<T>,\n30 +  options: TimeoutOptions\n31 +): Promise<T> {\n32 +  const { timeoutMs, errorMessage, onTimeout } = options;\n33 +\n34 +  const timeoutPromise = createTimeoutPromise(\n35 +    timeoutMs,\n36 +    errorMessage ?? `Operation timed out after ${timeoutMs}ms`\n37 +  );\n38 +\n39 +  try {\n40 +    const result = await Promise.race([\n41 +      Promise.resolve(operation),\n42 +      timeoutPromise,\n43 +    ]);\n44 +    return result;\n45 +  } catch (error) {\n46 +    if (error instanceof TimeoutError) {\n47 +      onTimeout?.();\n48 +    }\n49 +    throw error;\n50 +  }\n51 +}\n52 +\n53 +export async function withRetryAndTimeout<T>(\n54 +  operation: () => Promise<T>,\n55 +  options: {\n56 +    timeoutMs: number;\n57 +    maxRetries: number;\n58 +    retryDelayMs: number;\n59 +  }\n60 +): Promise<T> {\n61 +  let lastError: Error | undefined;\n62 +\n63 +  for (let attempt = 0; attempt <= options.maxRetries; attempt++) {\n64 +    try {\n65 +      return await withTimeout(operation(), {\n66 +        timeoutMs: options.timeoutMs,\n67 +      });\n68 +    } catch (error) {\n69 +      lastError = error as Error;\n70 +      if (attempt < options.maxRetries) {\n71 +        await new Promise(resolve => setTimeout(resolve, options.retryDelayMs));\n72 +      }\n73 +    }\n74 +  }\n75 +\n76 +  throw lastError ?? new NetworkError('All retries exhausted');\n77 +}\n78 +\n79 +export function isTimeoutError(error: unknown): error is TimeoutError {\n80 +  return error instanceof TimeoutError;\n81 +}\n82 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/network/src/utils/withTimeout.ts\",\"relevantLinesStart\":19,\"relevantLinesEnd\":25}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"function createTimeoutPromise(ms: number, message: string): Promise<never> {\\n  return new Promise((_, reject) => {\\n    setTimeout(() => {\\n      reject(new TimeoutError(message, ms));\\n    }, ms);\\n  });\\n}\",\n    \"improvedCode\": \"function createTimeoutPromise(ms: number, message: string, signal: AbortSignal): Promise<never> {\\n  return new Promise((_, reject) => {\\n    const timeoutId = setTimeout(() => {\\n      reject(new TimeoutError(message, ms));\\n    }, ms);\\n    signal.addEventListener('abort', () => clearTimeout(timeoutId));\\n  });\\n}\",\n    \"relevantFile\": \"packages/network/src/utils/withTimeout.ts\",\n    \"relevantLinesEnd\": 25,\n    \"suggestionContent\": \"The timeout promise created by `createTimeoutPromise` is never cancelled when the operation succeeds. In Promise.race, losing promises continue to exist and their timers keep running. If `withTimeout` is called frequently (e.g., for every API request), these orphaned setTimeout callbacks accumulate in memory until they fire, causing a memory leak. Use AbortController or manually clear the timeout when the operation completes.\",\n    \"oneSentenceSummary\": \"Promise.race memory leak - timeout timer is never cancelled when operation succeeds\",\n    \"relevantLinesStart\": 19\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 8: packages/sync/src/services/DataSyncService.ts",
    "vars": {
      "fileContent": "import { EventEmitter } from 'events';\n\nexport interface SyncItem {\n  id: string;\n  type: 'create' | 'update' | 'delete';\n  entity: string;\n  data: Record<string, unknown>;\n  timestamp: number;\n}\n\nexport interface SyncResult {\n  success: boolean;\n  itemId: string;\n  error?: Error;\n}\n\nexport interface SyncConfig {\n  batchSize: number;\n  retryAttempts: number;\n  retryDelayMs: number;\n  onProgress?: (completed: number, total: number) => void;\n}\n\nconst DEFAULT_CONFIG: SyncConfig = {\n  batchSize: 50,\n  retryAttempts: 3,\n  retryDelayMs: 1000,\n};\n\nexport class DataSyncService extends EventEmitter {\n  private config: SyncConfig;\n  private isRunning = false;\n  private queue: SyncItem[] = [];\n\n  constructor(config: Partial<SyncConfig> = {}) {\n    super();\n    this.config = { ...DEFAULT_CONFIG, ...config };\n  }\n\n  async syncItem(item: SyncItem): Promise<SyncResult> {\n    // Simulated sync operation\n    await new Promise(resolve => setTimeout(resolve, 100));\n\n    if (Math.random() < 0.1) {\n      throw new Error(`Failed to sync item ${item.id}`);\n    }\n\n    return { success: true, itemId: item.id };\n  }\n\n  async syncBatch(items: SyncItem[]): Promise<SyncResult[]> {\n    const results: SyncResult[] = [];\n\n    await items.forEach(async (item) => {\n      try {\n        const result = await this.syncItem(item);\n        results.push(result);\n        this.emit('itemSynced', result);\n      } catch (error) {\n        results.push({\n          success: false,\n          itemId: item.id,\n          error: error as Error,\n        });\n        this.emit('itemFailed', { itemId: item.id, error });\n      }\n    });\n\n    return results;\n  }\n\n  async syncAll(items: SyncItem[]): Promise<SyncResult[]> {\n    if (this.isRunning) {\n      throw new Error('Sync already in progress');\n    }\n\n    this.isRunning = true;\n    this.emit('syncStarted', { total: items.length });\n\n    const allResults: SyncResult[] = [];\n    const batches: SyncItem[][] = [];\n\n    for (let i = 0; i < items.length; i += this.config.batchSize) {\n      batches.push(items.slice(i, i + this.config.batchSize));\n    }\n\n    for (const batch of batches) {\n      const batchResults = await this.syncBatch(batch);\n      allResults.push(...batchResults);\n\n      this.config.onProgress?.(\n        allResults.length,\n        items.length\n      );\n    }\n\n    this.isRunning = false;\n    this.emit('syncCompleted', { results: allResults });\n\n    return allResults;\n  }\n\n  addToQueue(item: SyncItem): void {\n    this.queue.push(item);\n  }\n\n  async processQueue(): Promise<SyncResult[]> {\n    const items = [...this.queue];\n    this.queue = [];\n    return this.syncAll(items);\n  }\n\n  getQueueLength(): number {\n    return this.queue.length;\n  }\n}\n\nexport async function createSyncService(\n  config?: Partial<SyncConfig>\n): Promise<DataSyncService> {\n  return new DataSyncService(config);\n}\n",
      "patchWithLinesStr": "## file: 'packages/sync/src/services/DataSyncService.ts'\n\n@@ -0,0 +1,123 @@\n__new hunk__\n1 +import { EventEmitter } from 'events';\n2 +\n3 +export interface SyncItem {\n4 +  id: string;\n5 +  type: 'create' | 'update' | 'delete';\n6 +  entity: string;\n7 +  data: Record<string, unknown>;\n8 +  timestamp: number;\n9 +}\n10 +\n11 +export interface SyncResult {\n12 +  success: boolean;\n13 +  itemId: string;\n14 +  error?: Error;\n15 +}\n16 +\n17 +export interface SyncConfig {\n18 +  batchSize: number;\n19 +  retryAttempts: number;\n20 +  retryDelayMs: number;\n21 +  onProgress?: (completed: number, total: number) => void;\n22 +}\n23 +\n24 +const DEFAULT_CONFIG: SyncConfig = {\n25 +  batchSize: 50,\n26 +  retryAttempts: 3,\n27 +  retryDelayMs: 1000,\n28 +};\n29 +\n30 +export class DataSyncService extends EventEmitter {\n31 +  private config: SyncConfig;\n32 +  private isRunning = false;\n33 +  private queue: SyncItem[] = [];\n34 +\n35 +  constructor(config: Partial<SyncConfig> = {}) {\n36 +    super();\n37 +    this.config = { ...DEFAULT_CONFIG, ...config };\n38 +  }\n39 +\n40 +  async syncItem(item: SyncItem): Promise<SyncResult> {\n41 +    // Simulated sync operation\n42 +    await new Promise(resolve => setTimeout(resolve, 100));\n43 +\n44 +    if (Math.random() < 0.1) {\n45 +      throw new Error(`Failed to sync item ${item.id}`);\n46 +    }\n47 +\n48 +    return { success: true, itemId: item.id };\n49 +  }\n50 +\n51 +  async syncBatch(items: SyncItem[]): Promise<SyncResult[]> {\n52 +    const results: SyncResult[] = [];\n53 +\n54 +    await items.forEach(async (item) => {\n55 +      try {\n56 +        const result = await this.syncItem(item);\n57 +        results.push(result);\n58 +        this.emit('itemSynced', result);\n59 +      } catch (error) {\n60 +        results.push({\n61 +          success: false,\n62 +          itemId: item.id,\n63 +          error: error as Error,\n64 +        });\n65 +        this.emit('itemFailed', { itemId: item.id, error });\n66 +      }\n67 +    });\n68 +\n69 +    return results;\n70 +  }\n71 +\n72 +  async syncAll(items: SyncItem[]): Promise<SyncResult[]> {\n73 +    if (this.isRunning) {\n74 +      throw new Error('Sync already in progress');\n75 +    }\n76 +\n77 +    this.isRunning = true;\n78 +    this.emit('syncStarted', { total: items.length });\n79 +\n80 +    const allResults: SyncResult[] = [];\n81 +    const batches: SyncItem[][] = [];\n82 +\n83 +    for (let i = 0; i < items.length; i += this.config.batchSize) {\n84 +      batches.push(items.slice(i, i + this.config.batchSize));\n85 +    }\n86 +\n87 +    for (const batch of batches) {\n88 +      const batchResults = await this.syncBatch(batch);\n89 +      allResults.push(...batchResults);\n90 +\n91 +      this.config.onProgress?.(\n92 +        allResults.length,\n93 +        items.length\n94 +      );\n95 +    }\n96 +\n97 +    this.isRunning = false;\n98 +    this.emit('syncCompleted', { results: allResults });\n99 +\n100 +    return allResults;\n101 +  }\n102 +\n103 +  addToQueue(item: SyncItem): void {\n104 +    this.queue.push(item);\n105 +  }\n106 +\n107 +  async processQueue(): Promise<SyncResult[]> {\n108 +    const items = [...this.queue];\n109 +    this.queue = [];\n110 +    return this.syncAll(items);\n111 +  }\n112 +\n113 +  getQueueLength(): number {\n114 +    return this.queue.length;\n115 +  }\n116 +}\n117 +\n118 +export async function createSyncService(\n119 +  config?: Partial<SyncConfig>\n120 +): Promise<DataSyncService> {\n121 +  return new DataSyncService(config);\n122 +}\n123 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/sync/src/services/DataSyncService.ts\",\"relevantLinesStart\":50,\"relevantLinesEnd\":63}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"await items.forEach(async (item) => {\\n      try {\\n        const result = await this.syncItem(item);\\n        results.push(result);\",\n    \"improvedCode\": \"await Promise.all(items.map(async (item) => {\\n      try {\\n        const result = await this.syncItem(item);\\n        results.push(result);\",\n    \"relevantFile\": \"packages/sync/src/services/DataSyncService.ts\",\n    \"relevantLinesEnd\": 63,\n    \"suggestionContent\": \"The `syncBatch` method uses `await items.forEach(async ...)` which does not actually wait for the async callbacks to complete. `Array.forEach` ignores the return value of callbacks (including Promises), so this returns an empty `results` array immediately while the sync operations continue in the background. Use `Promise.all` with `map`, or a for...of loop to properly await each operation.\",\n    \"oneSentenceSummary\": \"await forEach does not wait for async callbacks - returns empty array\",\n    \"relevantLinesStart\": 50\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 9: packages/api/src/client/ApiClient.ts",
    "vars": {
      "fileContent": "import { EventEmitter } from 'events';\n\nexport interface RequestConfig {\n  method: 'GET' | 'POST' | 'PUT' | 'DELETE' | 'PATCH';\n  url: string;\n  data?: unknown;\n  headers?: Record<string, string>;\n  timeout?: number;\n  retries?: number;\n}\n\nexport interface ApiResponse<T = unknown> {\n  data: T;\n  status: number;\n  headers: Record<string, string>;\n}\n\nexport interface ApiClientConfig {\n  baseUrl: string;\n  defaultTimeout: number;\n  defaultRetries: number;\n  authToken?: string;\n}\n\ntype RequestInterceptor = (config: RequestConfig) => RequestConfig | Promise<RequestConfig>;\ntype ResponseInterceptor = <T>(response: ApiResponse<T>) => ApiResponse<T> | Promise<ApiResponse<T>>;\n\nconst RETRY_STATUS_CODES = [408, 429, 500, 502, 503, 504];\n\nexport class ApiClient extends EventEmitter {\n  private config: ApiClientConfig;\n  private requestInterceptors: RequestInterceptor[] = [];\n  private responseInterceptors: ResponseInterceptor[] = [];\n  private pendingRequests: Map<string, AbortController> = new Map();\n  private requestCount = 0;\n  private isRefreshingToken = false;\n  private tokenRefreshPromise: Promise<string> | null = null;\n\n  constructor(config: ApiClientConfig) {\n    super();\n    this.config = config;\n  }\n\n  addRequestInterceptor(interceptor: RequestInterceptor): () => void {\n    this.requestInterceptors.push(interceptor);\n    return () => {\n      const index = this.requestInterceptors.indexOf(interceptor);\n      if (index > -1) this.requestInterceptors.splice(index, 1);\n    };\n  }\n\n  addResponseInterceptor(interceptor: ResponseInterceptor): () => void {\n    this.responseInterceptors.push(interceptor);\n    return () => {\n      const index = this.responseInterceptors.indexOf(interceptor);\n      if (index > -1) this.responseInterceptors.splice(index, 1);\n    };\n  }\n\n  private async applyRequestInterceptors(config: RequestConfig): Promise<RequestConfig> {\n    let currentConfig = config;\n    for (const interceptor of this.requestInterceptors) {\n      currentConfig = await interceptor(currentConfig);\n    }\n    return currentConfig;\n  }\n\n  private async applyResponseInterceptors<T>(response: ApiResponse<T>): Promise<ApiResponse<T>> {\n    let currentResponse = response;\n    for (const interceptor of this.responseInterceptors) {\n      currentResponse = await interceptor(currentResponse);\n    }\n    return currentResponse;\n  }\n\n  private generateRequestId(): string {\n    return `req_${++this.requestCount}_${Date.now()}`;\n  }\n\n  async refreshAuthToken(): Promise<string> {\n    if (this.isRefreshingToken) {\n      return this.tokenRefreshPromise!;\n    }\n\n    this.isRefreshingToken = true;\n    this.tokenRefreshPromise = this.doRefreshToken();\n\n    const newToken = await this.tokenRefreshPromise;\n    this.config.authToken = newToken;\n    this.isRefreshingToken = false;\n\n    return newToken;\n  }\n\n  private async doRefreshToken(): Promise<string> {\n    const response = await fetch(`${this.config.baseUrl}/auth/refresh`, {\n      method: 'POST',\n      credentials: 'include',\n    });\n\n    if (!response.ok) {\n      throw new Error('Failed to refresh token');\n    }\n\n    const data = await response.json();\n    return data.token;\n  }\n\n  async request<T>(config: RequestConfig): Promise<ApiResponse<T>> {\n    const requestId = this.generateRequestId();\n    const abortController = new AbortController();\n    this.pendingRequests.set(requestId, abortController);\n\n    const finalConfig = await this.applyRequestInterceptors({\n      ...config,\n      timeout: config.timeout ?? this.config.defaultTimeout,\n      retries: config.retries ?? this.config.defaultRetries,\n    });\n\n    const headers: Record<string, string> = {\n      'Content-Type': 'application/json',\n      ...finalConfig.headers,\n    };\n\n    if (this.config.authToken) {\n      headers['Authorization'] = `Bearer ${this.config.authToken}`;\n    }\n\n    let lastError: Error | null = null;\n    const maxRetries = finalConfig.retries ?? 0;\n\n    for (let attempt = 0; attempt <= maxRetries; attempt++) {\n      try {\n        const timeoutId = setTimeout(() => {\n          abortController.abort();\n        }, finalConfig.timeout);\n\n        const response = await fetch(`${this.config.baseUrl}${finalConfig.url}`, {\n          method: finalConfig.method,\n          headers,\n          body: finalConfig.data ? JSON.stringify(finalConfig.data) : undefined,\n          signal: abortController.signal,\n        });\n\n        clearTimeout(timeoutId);\n\n        if (response.status === 401 && this.config.authToken) {\n          await this.refreshAuthToken();\n          headers['Authorization'] = `Bearer ${this.config.authToken}`;\n          continue;\n        }\n\n        if (!response.ok) {\n          if (RETRY_STATUS_CODES.includes(response.status) && attempt < maxRetries) {\n            await this.delay(Math.pow(2, attempt) * 1000);\n            continue;\n          }\n          throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n        }\n\n        const data = await response.json();\n        const apiResponse: ApiResponse<T> = {\n          data,\n          status: response.status,\n          headers: Object.fromEntries(response.headers.entries()),\n        };\n\n        this.emit('requestComplete', { requestId, response: apiResponse });\n        return this.applyResponseInterceptors(apiResponse);\n\n      } catch (error) {\n        lastError = error as Error;\n        if (attempt < maxRetries) {\n          await this.delay(Math.pow(2, attempt) * 1000);\n        }\n      }\n    }\n\n    this.emit('requestFailed', { requestId, error: lastError });\n    throw lastError;\n  }\n\n  private delay(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  cancelRequest(requestId: string): void {\n    const controller = this.pendingRequests.get(requestId);\n    if (controller) {\n      controller.abort();\n      this.pendingRequests.delete(requestId);\n    }\n  }\n\n  cancelAllRequests(): void {\n    for (const [id, controller] of this.pendingRequests) {\n      controller.abort();\n    }\n    this.pendingRequests.clear();\n  }\n\n  async get<T>(url: string, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n    return this.request<T>({ method: 'GET', url, ...config });\n  }\n\n  async post<T>(url: string, data?: unknown, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n    return this.request<T>({ method: 'POST', url, data, ...config });\n  }\n\n  async put<T>(url: string, data?: unknown, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n    return this.request<T>({ method: 'PUT', url, data, ...config });\n  }\n\n  async delete<T>(url: string, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n    return this.request<T>({ method: 'DELETE', url, ...config });\n  }\n}\n\nexport function createApiClient(config: ApiClientConfig): ApiClient {\n  return new ApiClient(config);\n}\n",
      "patchWithLinesStr": "## file: 'packages/api/src/client/ApiClient.ts'\n\n@@ -0,0 +1,222 @@\n__new hunk__\n1 +import { EventEmitter } from 'events';\n2 +\n3 +export interface RequestConfig {\n4 +  method: 'GET' | 'POST' | 'PUT' | 'DELETE' | 'PATCH';\n5 +  url: string;\n6 +  data?: unknown;\n7 +  headers?: Record<string, string>;\n8 +  timeout?: number;\n9 +  retries?: number;\n10 +}\n11 +\n12 +export interface ApiResponse<T = unknown> {\n13 +  data: T;\n14 +  status: number;\n15 +  headers: Record<string, string>;\n16 +}\n17 +\n18 +export interface ApiClientConfig {\n19 +  baseUrl: string;\n20 +  defaultTimeout: number;\n21 +  defaultRetries: number;\n22 +  authToken?: string;\n23 +}\n24 +\n25 +type RequestInterceptor = (config: RequestConfig) => RequestConfig | Promise<RequestConfig>;\n26 +type ResponseInterceptor = <T>(response: ApiResponse<T>) => ApiResponse<T> | Promise<ApiResponse<T>>;\n27 +\n28 +const RETRY_STATUS_CODES = [408, 429, 500, 502, 503, 504];\n29 +\n30 +export class ApiClient extends EventEmitter {\n31 +  private config: ApiClientConfig;\n32 +  private requestInterceptors: RequestInterceptor[] = [];\n33 +  private responseInterceptors: ResponseInterceptor[] = [];\n34 +  private pendingRequests: Map<string, AbortController> = new Map();\n35 +  private requestCount = 0;\n36 +  private isRefreshingToken = false;\n37 +  private tokenRefreshPromise: Promise<string> | null = null;\n38 +\n39 +  constructor(config: ApiClientConfig) {\n40 +    super();\n41 +    this.config = config;\n42 +  }\n43 +\n44 +  addRequestInterceptor(interceptor: RequestInterceptor): () => void {\n45 +    this.requestInterceptors.push(interceptor);\n46 +    return () => {\n47 +      const index = this.requestInterceptors.indexOf(interceptor);\n48 +      if (index > -1) this.requestInterceptors.splice(index, 1);\n49 +    };\n50 +  }\n51 +\n52 +  addResponseInterceptor(interceptor: ResponseInterceptor): () => void {\n53 +    this.responseInterceptors.push(interceptor);\n54 +    return () => {\n55 +      const index = this.responseInterceptors.indexOf(interceptor);\n56 +      if (index > -1) this.responseInterceptors.splice(index, 1);\n57 +    };\n58 +  }\n59 +\n60 +  private async applyRequestInterceptors(config: RequestConfig): Promise<RequestConfig> {\n61 +    let currentConfig = config;\n62 +    for (const interceptor of this.requestInterceptors) {\n63 +      currentConfig = await interceptor(currentConfig);\n64 +    }\n65 +    return currentConfig;\n66 +  }\n67 +\n68 +  private async applyResponseInterceptors<T>(response: ApiResponse<T>): Promise<ApiResponse<T>> {\n69 +    let currentResponse = response;\n70 +    for (const interceptor of this.responseInterceptors) {\n71 +      currentResponse = await interceptor(currentResponse);\n72 +    }\n73 +    return currentResponse;\n74 +  }\n75 +\n76 +  private generateRequestId(): string {\n77 +    return `req_${++this.requestCount}_${Date.now()}`;\n78 +  }\n79 +\n80 +  async refreshAuthToken(): Promise<string> {\n81 +    if (this.isRefreshingToken) {\n82 +      return this.tokenRefreshPromise!;\n83 +    }\n84 +\n85 +    this.isRefreshingToken = true;\n86 +    this.tokenRefreshPromise = this.doRefreshToken();\n87 +\n88 +    const newToken = await this.tokenRefreshPromise;\n89 +    this.config.authToken = newToken;\n90 +    this.isRefreshingToken = false;\n91 +\n92 +    return newToken;\n93 +  }\n94 +\n95 +  private async doRefreshToken(): Promise<string> {\n96 +    const response = await fetch(`${this.config.baseUrl}/auth/refresh`, {\n97 +      method: 'POST',\n98 +      credentials: 'include',\n99 +    });\n100 +\n101 +    if (!response.ok) {\n102 +      throw new Error('Failed to refresh token');\n103 +    }\n104 +\n105 +    const data = await response.json();\n106 +    return data.token;\n107 +  }\n108 +\n109 +  async request<T>(config: RequestConfig): Promise<ApiResponse<T>> {\n110 +    const requestId = this.generateRequestId();\n111 +    const abortController = new AbortController();\n112 +    this.pendingRequests.set(requestId, abortController);\n113 +\n114 +    const finalConfig = await this.applyRequestInterceptors({\n115 +      ...config,\n116 +      timeout: config.timeout ?? this.config.defaultTimeout,\n117 +      retries: config.retries ?? this.config.defaultRetries,\n118 +    });\n119 +\n120 +    const headers: Record<string, string> = {\n121 +      'Content-Type': 'application/json',\n122 +      ...finalConfig.headers,\n123 +    };\n124 +\n125 +    if (this.config.authToken) {\n126 +      headers['Authorization'] = `Bearer ${this.config.authToken}`;\n127 +    }\n128 +\n129 +    let lastError: Error | null = null;\n130 +    const maxRetries = finalConfig.retries ?? 0;\n131 +\n132 +    for (let attempt = 0; attempt <= maxRetries; attempt++) {\n133 +      try {\n134 +        const timeoutId = setTimeout(() => {\n135 +          abortController.abort();\n136 +        }, finalConfig.timeout);\n137 +\n138 +        const response = await fetch(`${this.config.baseUrl}${finalConfig.url}`, {\n139 +          method: finalConfig.method,\n140 +          headers,\n141 +          body: finalConfig.data ? JSON.stringify(finalConfig.data) : undefined,\n142 +          signal: abortController.signal,\n143 +        });\n144 +\n145 +        clearTimeout(timeoutId);\n146 +\n147 +        if (response.status === 401 && this.config.authToken) {\n148 +          await this.refreshAuthToken();\n149 +          headers['Authorization'] = `Bearer ${this.config.authToken}`;\n150 +          continue;\n151 +        }\n152 +\n153 +        if (!response.ok) {\n154 +          if (RETRY_STATUS_CODES.includes(response.status) && attempt < maxRetries) {\n155 +            await this.delay(Math.pow(2, attempt) * 1000);\n156 +            continue;\n157 +          }\n158 +          throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n159 +        }\n160 +\n161 +        const data = await response.json();\n162 +        const apiResponse: ApiResponse<T> = {\n163 +          data,\n164 +          status: response.status,\n165 +          headers: Object.fromEntries(response.headers.entries()),\n166 +        };\n167 +\n168 +        this.emit('requestComplete', { requestId, response: apiResponse });\n169 +        return this.applyResponseInterceptors(apiResponse);\n170 +\n171 +      } catch (error) {\n172 +        lastError = error as Error;\n173 +        if (attempt < maxRetries) {\n174 +          await this.delay(Math.pow(2, attempt) * 1000);\n175 +        }\n176 +      }\n177 +    }\n178 +\n179 +    this.emit('requestFailed', { requestId, error: lastError });\n180 +    throw lastError;\n181 +  }\n182 +\n183 +  private delay(ms: number): Promise<void> {\n184 +    return new Promise(resolve => setTimeout(resolve, ms));\n185 +  }\n186 +\n187 +  cancelRequest(requestId: string): void {\n188 +    const controller = this.pendingRequests.get(requestId);\n189 +    if (controller) {\n190 +      controller.abort();\n191 +      this.pendingRequests.delete(requestId);\n192 +    }\n193 +  }\n194 +\n195 +  cancelAllRequests(): void {\n196 +    for (const [id, controller] of this.pendingRequests) {\n197 +      controller.abort();\n198 +    }\n199 +    this.pendingRequests.clear();\n200 +  }\n201 +\n202 +  async get<T>(url: string, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n203 +    return this.request<T>({ method: 'GET', url, ...config });\n204 +  }\n205 +\n206 +  async post<T>(url: string, data?: unknown, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n207 +    return this.request<T>({ method: 'POST', url, data, ...config });\n208 +  }\n209 +\n210 +  async put<T>(url: string, data?: unknown, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n211 +    return this.request<T>({ method: 'PUT', url, data, ...config });\n212 +  }\n213 +\n214 +  async delete<T>(url: string, config?: Partial<RequestConfig>): Promise<ApiResponse<T>> {\n215 +    return this.request<T>({ method: 'DELETE', url, ...config });\n216 +  }\n217 +}\n218 +\n219 +export function createApiClient(config: ApiClientConfig): ApiClient {\n220 +  return new ApiClient(config);\n221 +}\n222 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/api/src/client/ApiClient.ts\",\"relevantLinesStart\":78,\"relevantLinesEnd\":90},{\"relevantFile\":\"packages/api/src/client/ApiClient.ts\",\"relevantLinesStart\":156,\"relevantLinesEnd\":157},{\"relevantFile\":\"packages/api/src/client/ApiClient.ts\",\"relevantLinesStart\":140,\"relevantLinesEnd\":145}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"async refreshAuthToken(): Promise<string> {\\n    if (this.isRefreshingToken) {\\n      return this.tokenRefreshPromise!;\\n    }\\n\\n    this.isRefreshingToken = true;\\n    this.tokenRefreshPromise = this.doRefreshToken();\",\n    \"improvedCode\": \"async refreshAuthToken(): Promise<string> {\\n    if (this.tokenRefreshPromise) {\\n      return this.tokenRefreshPromise;\\n    }\\n\\n    this.tokenRefreshPromise = this.doRefreshToken().finally(() => {\\n      this.tokenRefreshPromise = null;\\n    });\",\n    \"relevantFile\": \"packages/api/src/client/ApiClient.ts\",\n    \"relevantLinesEnd\": 90,\n    \"suggestionContent\": \"The `refreshAuthToken` method has a race condition. After checking `this.isRefreshingToken` and before setting it to `true`, another call could pass the check. Also, after the token refresh completes, `this.isRefreshingToken` is set to `false` but `this.tokenRefreshPromise` is not cleared, so subsequent checks of `this.tokenRefreshPromise!` could return a stale resolved promise.\",\n    \"oneSentenceSummary\": \"Race condition in token refresh - multiple concurrent refreshes possible\",\n    \"relevantLinesStart\": 78\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"this.emit('requestComplete', { requestId, response: apiResponse });\\n        return this.applyResponseInterceptors(apiResponse);\",\n    \"improvedCode\": \"this.pendingRequests.delete(requestId);\\n        this.emit('requestComplete', { requestId, response: apiResponse });\\n        return this.applyResponseInterceptors(apiResponse);\",\n    \"relevantFile\": \"packages/api/src/client/ApiClient.ts\",\n    \"relevantLinesEnd\": 157,\n    \"suggestionContent\": \"The `pendingRequests` Map stores AbortControllers but never removes them after a request completes successfully. Only `cancelRequest` removes entries. Over time, this causes a memory leak as the Map grows unboundedly with completed request entries.\",\n    \"oneSentenceSummary\": \"Memory leak - pendingRequests Map never cleaned up after successful requests\",\n    \"relevantLinesStart\": 156\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"if (response.status === 401 && this.config.authToken) {\\n          await this.refreshAuthToken();\\n          headers['Authorization'] = `Bearer ${this.config.authToken}`;\\n          continue;\\n        }\",\n    \"improvedCode\": \"if (response.status === 401 && this.config.authToken) {\\n          await this.refreshAuthToken();\\n          headers['Authorization'] = `Bearer ${this.config.authToken}`;\\n          attempt--; // Don't count 401 retry against retry limit\\n          continue;\\n        }\",\n    \"relevantFile\": \"packages/api/src/client/ApiClient.ts\",\n    \"relevantLinesEnd\": 145,\n    \"suggestionContent\": \"The retry loop continues after a 401 response and token refresh, but the `attempt` counter is still incremented. This means if token refresh happens on the last retry attempt, the request won't be retried with the new token. Also, the finally block doesn't clean up the pendingRequests entry on failure.\",\n    \"oneSentenceSummary\": \"401 retry consumes retry attempt - may fail if token expires on last retry\",\n    \"relevantLinesStart\": 140\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 10: packages/scheduling/src/utils/DateScheduler.ts",
    "vars": {
      "fileContent": "export interface ScheduleConfig {\n  startDate: string;\n  endDate: string;\n  timezone: string;\n  recurrence?: 'daily' | 'weekly' | 'monthly';\n  excludeWeekends?: boolean;\n}\n\nexport interface ScheduledEvent {\n  id: string;\n  date: Date;\n  originalDate: string;\n}\n\nexport function parseDate(dateString: string): Date {\n  return new Date(dateString);\n}\n\nexport function formatDate(date: Date): string {\n  const year = date.getFullYear();\n  const month = String(date.getMonth() + 1).padStart(2, '0');\n  const day = String(date.getDate()).padStart(2, '0');\n  return `${year}-${month}-${day}`;\n}\n\nexport function addDays(date: Date, days: number): Date {\n  const result = new Date(date);\n  result.setDate(result.getDate() + days);\n  return result;\n}\n\nexport function addMonths(date: Date, months: number): Date {\n  const result = new Date(date);\n  result.setMonth(result.getMonth() + months);\n  return result;\n}\n\nexport function isWeekend(date: Date): boolean {\n  const day = date.getDay();\n  return day === 0 || day === 6;\n}\n\nexport function getBusinessDaysBetween(start: Date, end: Date): number {\n  let count = 0;\n  const current = new Date(start);\n\n  while (current <= end) {\n    if (!isWeekend(current)) {\n      count++;\n    }\n    current.setDate(current.getDate() + 1);\n  }\n\n  return count;\n}\n\nexport function generateSchedule(config: ScheduleConfig): ScheduledEvent[] {\n  const events: ScheduledEvent[] = [];\n  const start = parseDate(config.startDate);\n  const end = parseDate(config.endDate);\n\n  let current = start;\n  let eventId = 1;\n\n  while (current <= end) {\n    if (!config.excludeWeekends || !isWeekend(current)) {\n      events.push({\n        id: `event_${eventId++}`,\n        date: current,\n        originalDate: formatDate(current),\n      });\n    }\n\n    switch (config.recurrence) {\n      case 'daily':\n        current = addDays(current, 1);\n        break;\n      case 'weekly':\n        current = addDays(current, 7);\n        break;\n      case 'monthly':\n        current = addMonths(current, 1);\n        break;\n      default:\n        current = addDays(current, 1);\n    }\n  }\n\n  return events;\n}\n\nexport function getNextBusinessDay(date: Date): Date {\n  let next = addDays(date, 1);\n  while (isWeekend(next)) {\n    next = addDays(next, 1);\n  }\n  return next;\n}\n\nexport function isSameDay(date1: Date, date2: Date): boolean {\n  return (\n    date1.getFullYear() === date2.getFullYear() &&\n    date1.getMonth() === date2.getMonth() &&\n    date1.getDate() === date2.getDate()\n  );\n}\n\nexport function getDaysDifference(date1: Date, date2: Date): number {\n  const diffTime = date2.getTime() - date1.getTime();\n  return diffTime / (1000 * 60 * 60 * 24);\n}\n\nexport class DateScheduler {\n  private config: ScheduleConfig;\n\n  constructor(config: ScheduleConfig) {\n    this.config = config;\n  }\n\n  generate(): ScheduledEvent[] {\n    return generateSchedule(this.config);\n  }\n\n  isValidDate(date: Date): boolean {\n    const start = parseDate(this.config.startDate);\n    const end = parseDate(this.config.endDate);\n    return date >= start && date <= end;\n  }\n}\n",
      "patchWithLinesStr": "## file: 'packages/scheduling/src/utils/DateScheduler.ts'\n\n@@ -0,0 +1,130 @@\n__new hunk__\n1 +export interface ScheduleConfig {\n2 +  startDate: string;\n3 +  endDate: string;\n4 +  timezone: string;\n5 +  recurrence?: 'daily' | 'weekly' | 'monthly';\n6 +  excludeWeekends?: boolean;\n7 +}\n8 +\n9 +export interface ScheduledEvent {\n10 +  id: string;\n11 +  date: Date;\n12 +  originalDate: string;\n13 +}\n14 +\n15 +export function parseDate(dateString: string): Date {\n16 +  return new Date(dateString);\n17 +}\n18 +\n19 +export function formatDate(date: Date): string {\n20 +  const year = date.getFullYear();\n21 +  const month = String(date.getMonth() + 1).padStart(2, '0');\n22 +  const day = String(date.getDate()).padStart(2, '0');\n23 +  return `${year}-${month}-${day}`;\n24 +}\n25 +\n26 +export function addDays(date: Date, days: number): Date {\n27 +  const result = new Date(date);\n28 +  result.setDate(result.getDate() + days);\n29 +  return result;\n30 +}\n31 +\n32 +export function addMonths(date: Date, months: number): Date {\n33 +  const result = new Date(date);\n34 +  result.setMonth(result.getMonth() + months);\n35 +  return result;\n36 +}\n37 +\n38 +export function isWeekend(date: Date): boolean {\n39 +  const day = date.getDay();\n40 +  return day === 0 || day === 6;\n41 +}\n42 +\n43 +export function getBusinessDaysBetween(start: Date, end: Date): number {\n44 +  let count = 0;\n45 +  const current = new Date(start);\n46 +\n47 +  while (current <= end) {\n48 +    if (!isWeekend(current)) {\n49 +      count++;\n50 +    }\n51 +    current.setDate(current.getDate() + 1);\n52 +  }\n53 +\n54 +  return count;\n55 +}\n56 +\n57 +export function generateSchedule(config: ScheduleConfig): ScheduledEvent[] {\n58 +  const events: ScheduledEvent[] = [];\n59 +  const start = parseDate(config.startDate);\n60 +  const end = parseDate(config.endDate);\n61 +\n62 +  let current = start;\n63 +  let eventId = 1;\n64 +\n65 +  while (current <= end) {\n66 +    if (!config.excludeWeekends || !isWeekend(current)) {\n67 +      events.push({\n68 +        id: `event_${eventId++}`,\n69 +        date: current,\n70 +        originalDate: formatDate(current),\n71 +      });\n72 +    }\n73 +\n74 +    switch (config.recurrence) {\n75 +      case 'daily':\n76 +        current = addDays(current, 1);\n77 +        break;\n78 +      case 'weekly':\n79 +        current = addDays(current, 7);\n80 +        break;\n81 +      case 'monthly':\n82 +        current = addMonths(current, 1);\n83 +        break;\n84 +      default:\n85 +        current = addDays(current, 1);\n86 +    }\n87 +  }\n88 +\n89 +  return events;\n90 +}\n91 +\n92 +export function getNextBusinessDay(date: Date): Date {\n93 +  let next = addDays(date, 1);\n94 +  while (isWeekend(next)) {\n95 +    next = addDays(next, 1);\n96 +  }\n97 +  return next;\n98 +}\n99 +\n100 +export function isSameDay(date1: Date, date2: Date): boolean {\n101 +  return (\n102 +    date1.getFullYear() === date2.getFullYear() &&\n103 +    date1.getMonth() === date2.getMonth() &&\n104 +    date1.getDate() === date2.getDate()\n105 +  );\n106 +}\n107 +\n108 +export function getDaysDifference(date1: Date, date2: Date): number {\n109 +  const diffTime = date2.getTime() - date1.getTime();\n110 +  return diffTime / (1000 * 60 * 60 * 24);\n111 +}\n112 +\n113 +export class DateScheduler {\n114 +  private config: ScheduleConfig;\n115 +\n116 +  constructor(config: ScheduleConfig) {\n117 +    this.config = config;\n118 +  }\n119 +\n120 +  generate(): ScheduledEvent[] {\n121 +    return generateSchedule(this.config);\n122 +  }\n123 +\n124 +  isValidDate(date: Date): boolean {\n125 +    const start = parseDate(this.config.startDate);\n126 +    const end = parseDate(this.config.endDate);\n127 +    return date >= start && date <= end;\n128 +  }\n129 +}\n130 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/scheduling/src/utils/DateScheduler.ts\",\"relevantLinesStart\":63,\"relevantLinesEnd\":67},{\"relevantFile\":\"packages/scheduling/src/utils/DateScheduler.ts\",\"relevantLinesStart\":99,\"relevantLinesEnd\":102}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"events.push({\\n        id: `event_${eventId++}`,\\n        date: current,\\n        originalDate: formatDate(current),\\n      });\",\n    \"improvedCode\": \"events.push({\\n        id: `event_${eventId++}`,\\n        date: new Date(current),\\n        originalDate: formatDate(current),\\n      });\",\n    \"relevantFile\": \"packages/scheduling/src/utils/DateScheduler.ts\",\n    \"relevantLinesEnd\": 67,\n    \"suggestionContent\": \"The `generateSchedule` function pushes the same Date object reference into the events array instead of creating a new Date for each event. Since `current` is mutated in the loop, all events end up pointing to the same Date object, which will have the final value after the loop completes. All events will show the same date.\",\n    \"oneSentenceSummary\": \"Same Date object reference pushed to array - all events have same final date\",\n    \"relevantLinesStart\": 63\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"export function getDaysDifference(date1: Date, date2: Date): number {\\n  const diffTime = date2.getTime() - date1.getTime();\\n  return diffTime / (1000 * 60 * 60 * 24);\\n}\",\n    \"improvedCode\": \"export function getDaysDifference(date1: Date, date2: Date): number {\\n  // Use UTC to avoid DST issues\\n  const utc1 = Date.UTC(date1.getFullYear(), date1.getMonth(), date1.getDate());\\n  const utc2 = Date.UTC(date2.getFullYear(), date2.getMonth(), date2.getDate());\\n  return (utc2 - utc1) / (1000 * 60 * 60 * 24);\\n}\",\n    \"relevantFile\": \"packages/scheduling/src/utils/DateScheduler.ts\",\n    \"relevantLinesEnd\": 102,\n    \"suggestionContent\": \"The `getDaysDifference` function divides by milliseconds per day but doesn't account for daylight saving time transitions. When crossing DST boundaries, a 'day' might be 23 or 25 hours, causing the function to return incorrect fractional values (e.g., 0.958 instead of 1 for a single day across DST).\",\n    \"oneSentenceSummary\": \"Days calculation doesn't handle DST - returns wrong value across timezone changes\",\n    \"relevantLinesStart\": 99\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 11: packages/database/src/query/QueryBuilder.ts",
    "vars": {
      "fileContent": "export type WhereOperator = '=' | '!=' | '>' | '<' | '>=' | '<=' | 'LIKE' | 'IN' | 'NOT IN';\nexport type OrderDirection = 'ASC' | 'DESC';\n\nexport interface WhereClause {\n  column: string;\n  operator: WhereOperator;\n  value: unknown;\n}\n\nexport interface OrderByClause {\n  column: string;\n  direction: OrderDirection;\n}\n\nexport interface JoinClause {\n  table: string;\n  type: 'INNER' | 'LEFT' | 'RIGHT';\n  on: string;\n}\n\nexport interface QueryResult<T> {\n  rows: T[];\n  rowCount: number;\n}\n\nexport class QueryBuilder<T = unknown> {\n  private tableName: string;\n  private selectColumns: string[] = ['*'];\n  private whereClauses: WhereClause[] = [];\n  private orderByClauses: OrderByClause[] = [];\n  private joinClauses: JoinClause[] = [];\n  private limitValue?: number;\n  private offsetValue?: number;\n  private params: unknown[] = [];\n\n  constructor(table: string) {\n    this.tableName = table;\n  }\n\n  select(...columns: string[]): this {\n    this.selectColumns = columns.length > 0 ? columns : ['*'];\n    return this;\n  }\n\n  where(column: string, operator: WhereOperator, value: unknown): this {\n    this.whereClauses.push({ column, operator, value });\n    return this;\n  }\n\n  whereEquals(column: string, value: unknown): this {\n    return this.where(column, '=', value);\n  }\n\n  whereLike(column: string, pattern: string): this {\n    return this.where(column, 'LIKE', pattern);\n  }\n\n  whereIn(column: string, values: unknown[]): this {\n    return this.where(column, 'IN', values);\n  }\n\n  orderBy(column: string, direction: OrderDirection = 'ASC'): this {\n    this.orderByClauses.push({ column, direction });\n    return this;\n  }\n\n  join(table: string, on: string, type: 'INNER' | 'LEFT' | 'RIGHT' = 'INNER'): this {\n    this.joinClauses.push({ table, type, on });\n    return this;\n  }\n\n  limit(count: number): this {\n    this.limitValue = count;\n    return this;\n  }\n\n  offset(count: number): this {\n    this.offsetValue = count;\n    return this;\n  }\n\n  buildSelect(): { sql: string; params: unknown[] } {\n    this.params = [];\n    let sql = `SELECT ${this.selectColumns.join(', ')} FROM ${this.tableName}`;\n\n    for (const join of this.joinClauses) {\n      sql += ` ${join.type} JOIN ${join.table} ON ${join.on}`;\n    }\n\n    if (this.whereClauses.length > 0) {\n      const conditions = this.whereClauses.map(clause => {\n        if (clause.operator === 'IN' || clause.operator === 'NOT IN') {\n          const values = clause.value as unknown[];\n          const placeholders = values.map(() => '?').join(', ');\n          this.params.push(...values);\n          return `${clause.column} ${clause.operator} (${placeholders})`;\n        }\n        this.params.push(clause.value);\n        return `${clause.column} ${clause.operator} ?`;\n      });\n      sql += ` WHERE ${conditions.join(' AND ')}`;\n    }\n\n    if (this.orderByClauses.length > 0) {\n      const orders = this.orderByClauses.map(\n        clause => `${clause.column} ${clause.direction}`\n      );\n      sql += ` ORDER BY ${orders.join(', ')}`;\n    }\n\n    if (this.limitValue !== undefined) {\n      sql += ` LIMIT ${this.limitValue}`;\n    }\n\n    if (this.offsetValue !== undefined) {\n      sql += ` OFFSET ${this.offsetValue}`;\n    }\n\n    return { sql, params: this.params };\n  }\n\n  buildInsert(data: Partial<T>): { sql: string; params: unknown[] } {\n    const columns = Object.keys(data);\n    const values = Object.values(data);\n    const placeholders = columns.map(() => '?').join(', ');\n\n    const sql = `INSERT INTO ${this.tableName} (${columns.join(', ')}) VALUES (${placeholders})`;\n\n    return { sql, params: values };\n  }\n\n  buildUpdate(data: Partial<T>): { sql: string; params: unknown[] } {\n    this.params = [];\n    const setClauses = Object.entries(data).map(([column, value]) => {\n      this.params.push(value);\n      return `${column} = ?`;\n    });\n\n    let sql = `UPDATE ${this.tableName} SET ${setClauses.join(', ')}`;\n\n    if (this.whereClauses.length > 0) {\n      const conditions = this.whereClauses.map(clause => {\n        this.params.push(clause.value);\n        return `${clause.column} ${clause.operator} ?`;\n      });\n      sql += ` WHERE ${conditions.join(' AND ')}`;\n    }\n\n    return { sql, params: this.params };\n  }\n\n  buildDelete(): { sql: string; params: unknown[] } {\n    this.params = [];\n    let sql = `DELETE FROM ${this.tableName}`;\n\n    if (this.whereClauses.length > 0) {\n      const conditions = this.whereClauses.map(clause => {\n        this.params.push(clause.value);\n        return `${clause.column} ${clause.operator} ?`;\n      });\n      sql += ` WHERE ${conditions.join(' AND ')}`;\n    }\n\n    return { sql, params: this.params };\n  }\n\n  reset(): this {\n    this.selectColumns = ['*'];\n    this.whereClauses = [];\n    this.orderByClauses = [];\n    this.joinClauses = [];\n    this.limitValue = undefined;\n    this.offsetValue = undefined;\n    this.params = [];\n    return this;\n  }\n}\n\nexport function query<T>(table: string): QueryBuilder<T> {\n  return new QueryBuilder<T>(table);\n}\n",
      "patchWithLinesStr": "## file: 'packages/database/src/query/QueryBuilder.ts'\n\n@@ -0,0 +1,182 @@\n__new hunk__\n1 +export type WhereOperator = '=' | '!=' | '>' | '<' | '>=' | '<=' | 'LIKE' | 'IN' | 'NOT IN';\n2 +export type OrderDirection = 'ASC' | 'DESC';\n3 +\n4 +export interface WhereClause {\n5 +  column: string;\n6 +  operator: WhereOperator;\n7 +  value: unknown;\n8 +}\n9 +\n10 +export interface OrderByClause {\n11 +  column: string;\n12 +  direction: OrderDirection;\n13 +}\n14 +\n15 +export interface JoinClause {\n16 +  table: string;\n17 +  type: 'INNER' | 'LEFT' | 'RIGHT';\n18 +  on: string;\n19 +}\n20 +\n21 +export interface QueryResult<T> {\n22 +  rows: T[];\n23 +  rowCount: number;\n24 +}\n25 +\n26 +export class QueryBuilder<T = unknown> {\n27 +  private tableName: string;\n28 +  private selectColumns: string[] = ['*'];\n29 +  private whereClauses: WhereClause[] = [];\n30 +  private orderByClauses: OrderByClause[] = [];\n31 +  private joinClauses: JoinClause[] = [];\n32 +  private limitValue?: number;\n33 +  private offsetValue?: number;\n34 +  private params: unknown[] = [];\n35 +\n36 +  constructor(table: string) {\n37 +    this.tableName = table;\n38 +  }\n39 +\n40 +  select(...columns: string[]): this {\n41 +    this.selectColumns = columns.length > 0 ? columns : ['*'];\n42 +    return this;\n43 +  }\n44 +\n45 +  where(column: string, operator: WhereOperator, value: unknown): this {\n46 +    this.whereClauses.push({ column, operator, value });\n47 +    return this;\n48 +  }\n49 +\n50 +  whereEquals(column: string, value: unknown): this {\n51 +    return this.where(column, '=', value);\n52 +  }\n53 +\n54 +  whereLike(column: string, pattern: string): this {\n55 +    return this.where(column, 'LIKE', pattern);\n56 +  }\n57 +\n58 +  whereIn(column: string, values: unknown[]): this {\n59 +    return this.where(column, 'IN', values);\n60 +  }\n61 +\n62 +  orderBy(column: string, direction: OrderDirection = 'ASC'): this {\n63 +    this.orderByClauses.push({ column, direction });\n64 +    return this;\n65 +  }\n66 +\n67 +  join(table: string, on: string, type: 'INNER' | 'LEFT' | 'RIGHT' = 'INNER'): this {\n68 +    this.joinClauses.push({ table, type, on });\n69 +    return this;\n70 +  }\n71 +\n72 +  limit(count: number): this {\n73 +    this.limitValue = count;\n74 +    return this;\n75 +  }\n76 +\n77 +  offset(count: number): this {\n78 +    this.offsetValue = count;\n79 +    return this;\n80 +  }\n81 +\n82 +  buildSelect(): { sql: string; params: unknown[] } {\n83 +    this.params = [];\n84 +    let sql = `SELECT ${this.selectColumns.join(', ')} FROM ${this.tableName}`;\n85 +\n86 +    for (const join of this.joinClauses) {\n87 +      sql += ` ${join.type} JOIN ${join.table} ON ${join.on}`;\n88 +    }\n89 +\n90 +    if (this.whereClauses.length > 0) {\n91 +      const conditions = this.whereClauses.map(clause => {\n92 +        if (clause.operator === 'IN' || clause.operator === 'NOT IN') {\n93 +          const values = clause.value as unknown[];\n94 +          const placeholders = values.map(() => '?').join(', ');\n95 +          this.params.push(...values);\n96 +          return `${clause.column} ${clause.operator} (${placeholders})`;\n97 +        }\n98 +        this.params.push(clause.value);\n99 +        return `${clause.column} ${clause.operator} ?`;\n100 +      });\n101 +      sql += ` WHERE ${conditions.join(' AND ')}`;\n102 +    }\n103 +\n104 +    if (this.orderByClauses.length > 0) {\n105 +      const orders = this.orderByClauses.map(\n106 +        clause => `${clause.column} ${clause.direction}`\n107 +      );\n108 +      sql += ` ORDER BY ${orders.join(', ')}`;\n109 +    }\n110 +\n111 +    if (this.limitValue !== undefined) {\n112 +      sql += ` LIMIT ${this.limitValue}`;\n113 +    }\n114 +\n115 +    if (this.offsetValue !== undefined) {\n116 +      sql += ` OFFSET ${this.offsetValue}`;\n117 +    }\n118 +\n119 +    return { sql, params: this.params };\n120 +  }\n121 +\n122 +  buildInsert(data: Partial<T>): { sql: string; params: unknown[] } {\n123 +    const columns = Object.keys(data);\n124 +    const values = Object.values(data);\n125 +    const placeholders = columns.map(() => '?').join(', ');\n126 +\n127 +    const sql = `INSERT INTO ${this.tableName} (${columns.join(', ')}) VALUES (${placeholders})`;\n128 +\n129 +    return { sql, params: values };\n130 +  }\n131 +\n132 +  buildUpdate(data: Partial<T>): { sql: string; params: unknown[] } {\n133 +    this.params = [];\n134 +    const setClauses = Object.entries(data).map(([column, value]) => {\n135 +      this.params.push(value);\n136 +      return `${column} = ?`;\n137 +    });\n138 +\n139 +    let sql = `UPDATE ${this.tableName} SET ${setClauses.join(', ')}`;\n140 +\n141 +    if (this.whereClauses.length > 0) {\n142 +      const conditions = this.whereClauses.map(clause => {\n143 +        this.params.push(clause.value);\n144 +        return `${clause.column} ${clause.operator} ?`;\n145 +      });\n146 +      sql += ` WHERE ${conditions.join(' AND ')}`;\n147 +    }\n148 +\n149 +    return { sql, params: this.params };\n150 +  }\n151 +\n152 +  buildDelete(): { sql: string; params: unknown[] } {\n153 +    this.params = [];\n154 +    let sql = `DELETE FROM ${this.tableName}`;\n155 +\n156 +    if (this.whereClauses.length > 0) {\n157 +      const conditions = this.whereClauses.map(clause => {\n158 +        this.params.push(clause.value);\n159 +        return `${clause.column} ${clause.operator} ?`;\n160 +      });\n161 +      sql += ` WHERE ${conditions.join(' AND ')}`;\n162 +    }\n163 +\n164 +    return { sql, params: this.params };\n165 +  }\n166 +\n167 +  reset(): this {\n168 +    this.selectColumns = ['*'];\n169 +    this.whereClauses = [];\n170 +    this.orderByClauses = [];\n171 +    this.joinClauses = [];\n172 +    this.limitValue = undefined;\n173 +    this.offsetValue = undefined;\n174 +    this.params = [];\n175 +    return this;\n176 +  }\n177 +}\n178 +\n179 +export function query<T>(table: string): QueryBuilder<T> {\n180 +  return new QueryBuilder<T>(table);\n181 +}\n182 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/database/src/query/QueryBuilder.ts\",\"relevantLinesStart\":76,\"relevantLinesEnd\":76},{\"relevantFile\":\"packages/database/src/query/QueryBuilder.ts\",\"relevantLinesStart\":95,\"relevantLinesEnd\":100},{\"relevantFile\":\"packages/database/src/query/QueryBuilder.ts\",\"relevantLinesStart\":78,\"relevantLinesEnd\":80}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"let sql = `SELECT ${this.selectColumns.join(', ')} FROM ${this.tableName}`;\",\n    \"improvedCode\": \"const safeColumns = this.selectColumns.map(col => {\\n      if (!/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(col) && col !== '*') {\\n        throw new Error(`Invalid column name: ${col}`);\\n      }\\n      return col;\\n    });\\n    let sql = `SELECT ${safeColumns.join(', ')} FROM ${this.tableName}`;\",\n    \"relevantFile\": \"packages/database/src/query/QueryBuilder.ts\",\n    \"relevantLinesEnd\": 76,\n    \"suggestionContent\": \"The `buildSelect` method directly interpolates `this.selectColumns` into the SQL query without sanitization. If column names come from user input, an attacker can inject SQL like `*; DROP TABLE users; --`. Column names should be validated against an allowlist or properly escaped.\",\n    \"oneSentenceSummary\": \"SQL injection via column names - user input interpolated without sanitization\",\n    \"relevantLinesStart\": 76\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"if (this.orderByClauses.length > 0) {\\n      const orders = this.orderByClauses.map(\\n        clause => `${clause.column} ${clause.direction}`\\n      );\\n      sql += ` ORDER BY ${orders.join(', ')}`;\\n    }\",\n    \"improvedCode\": \"if (this.orderByClauses.length > 0) {\\n      const orders = this.orderByClauses.map(clause => {\\n        if (!/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(clause.column)) {\\n          throw new Error(`Invalid column name: ${clause.column}`);\\n        }\\n        return `${clause.column} ${clause.direction}`;\\n      });\\n      sql += ` ORDER BY ${orders.join(', ')}`;\\n    }\",\n    \"relevantFile\": \"packages/database/src/query/QueryBuilder.ts\",\n    \"relevantLinesEnd\": 100,\n    \"suggestionContent\": \"The `orderBy` clause uses `clause.column` and `clause.direction` directly in string interpolation. While direction is constrained by the type, column is not validated. An attacker can inject SQL via the column parameter like `id; DROP TABLE users; --`.\",\n    \"oneSentenceSummary\": \"SQL injection in ORDER BY clause - column name not validated\",\n    \"relevantLinesStart\": 95\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"for (const join of this.joinClauses) {\\n      sql += ` ${join.type} JOIN ${join.table} ON ${join.on}`;\\n    }\",\n    \"improvedCode\": \"for (const join of this.joinClauses) {\\n      // Validate table name\\n      if (!/^[a-zA-Z_][a-zA-Z0-9_]*$/.test(join.table)) {\\n        throw new Error(`Invalid table name: ${join.table}`);\\n      }\\n      // ON clause should use parameterized format or be validated\\n      if (!/^[a-zA-Z_][a-zA-Z0-9_.]+\\\\s*=\\\\s*[a-zA-Z_][a-zA-Z0-9_.]+$/.test(join.on)) {\\n        throw new Error(`Invalid join condition: ${join.on}`);\\n      }\\n      sql += ` ${join.type} JOIN ${join.table} ON ${join.on}`;\\n    }\",\n    \"relevantFile\": \"packages/database/src/query/QueryBuilder.ts\",\n    \"relevantLinesEnd\": 80,\n    \"suggestionContent\": \"The `join` method takes an `on` parameter that is directly interpolated into the SQL query. This allows SQL injection via the join condition, e.g., `users.id = posts.user_id; DROP TABLE users; --`.\",\n    \"oneSentenceSummary\": \"SQL injection in JOIN clause - on condition not sanitized\",\n    \"relevantLinesStart\": 78\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 12: packages/security/src/middleware/RateLimiter.ts",
    "vars": {
      "fileContent": "export interface RateLimitConfig {\n  windowMs: number;\n  maxRequests: number;\n  keyGenerator?: (req: Request) => string;\n  onLimitReached?: (key: string) => void;\n  skipFailedRequests?: boolean;\n}\n\ninterface RateLimitEntry {\n  count: number;\n  resetTime: number;\n}\n\ninterface Request {\n  ip: string;\n  headers: Record<string, string>;\n  path: string;\n}\n\ninterface Response {\n  status: (code: number) => Response;\n  json: (data: unknown) => void;\n  setHeader: (name: string, value: string) => void;\n}\n\ntype NextFunction = () => void;\n\nconst DEFAULT_CONFIG: RateLimitConfig = {\n  windowMs: 60000,\n  maxRequests: 100,\n};\n\nexport class RateLimiter {\n  private config: RateLimitConfig;\n  private store: Map<string, RateLimitEntry> = new Map();\n  private cleanupInterval: NodeJS.Timeout;\n\n  constructor(config: Partial<RateLimitConfig> = {}) {\n    this.config = { ...DEFAULT_CONFIG, ...config };\n    this.cleanupInterval = setInterval(() => this.cleanup(), this.config.windowMs);\n  }\n\n  private getKey(req: Request): string {\n    if (this.config.keyGenerator) {\n      return this.config.keyGenerator(req);\n    }\n    return req.headers['x-forwarded-for'] || req.ip;\n  }\n\n  private cleanup(): void {\n    const now = Date.now();\n    for (const [key, entry] of this.store) {\n      if (now > entry.resetTime) {\n        this.store.delete(key);\n      }\n    }\n  }\n\n  isRateLimited(req: Request): { limited: boolean; remaining: number; resetTime: number } {\n    const key = this.getKey(req);\n    const now = Date.now();\n\n    let entry = this.store.get(key);\n\n    if (!entry || now > entry.resetTime) {\n      entry = {\n        count: 0,\n        resetTime: now + this.config.windowMs,\n      };\n      this.store.set(key, entry);\n    }\n\n    entry.count++;\n\n    const remaining = Math.max(0, this.config.maxRequests - entry.count);\n    const limited = entry.count > this.config.maxRequests;\n\n    if (limited && this.config.onLimitReached) {\n      this.config.onLimitReached(key);\n    }\n\n    return { limited, remaining, resetTime: entry.resetTime };\n  }\n\n  middleware() {\n    return (req: Request, res: Response, next: NextFunction) => {\n      const { limited, remaining, resetTime } = this.isRateLimited(req);\n\n      res.setHeader('X-RateLimit-Limit', String(this.config.maxRequests));\n      res.setHeader('X-RateLimit-Remaining', String(remaining));\n      res.setHeader('X-RateLimit-Reset', String(Math.ceil(resetTime / 1000)));\n\n      if (limited) {\n        res.status(429).json({\n          error: 'Too many requests',\n          retryAfter: Math.ceil((resetTime - Date.now()) / 1000),\n        });\n        return;\n      }\n\n      next();\n    };\n  }\n\n  reset(key: string): void {\n    this.store.delete(key);\n  }\n\n  resetAll(): void {\n    this.store.clear();\n  }\n\n  getStats(): { totalKeys: number; totalRequests: number } {\n    let totalRequests = 0;\n    for (const entry of this.store.values()) {\n      totalRequests += entry.count;\n    }\n    return {\n      totalKeys: this.store.size,\n      totalRequests,\n    };\n  }\n\n  destroy(): void {\n    clearInterval(this.cleanupInterval);\n    this.store.clear();\n  }\n}\n\nexport function createRateLimiter(config?: Partial<RateLimitConfig>): RateLimiter {\n  return new RateLimiter(config);\n}\n",
      "patchWithLinesStr": "## file: 'packages/security/src/middleware/RateLimiter.ts'\n\n@@ -0,0 +1,133 @@\n__new hunk__\n1 +export interface RateLimitConfig {\n2 +  windowMs: number;\n3 +  maxRequests: number;\n4 +  keyGenerator?: (req: Request) => string;\n5 +  onLimitReached?: (key: string) => void;\n6 +  skipFailedRequests?: boolean;\n7 +}\n8 +\n9 +interface RateLimitEntry {\n10 +  count: number;\n11 +  resetTime: number;\n12 +}\n13 +\n14 +interface Request {\n15 +  ip: string;\n16 +  headers: Record<string, string>;\n17 +  path: string;\n18 +}\n19 +\n20 +interface Response {\n21 +  status: (code: number) => Response;\n22 +  json: (data: unknown) => void;\n23 +  setHeader: (name: string, value: string) => void;\n24 +}\n25 +\n26 +type NextFunction = () => void;\n27 +\n28 +const DEFAULT_CONFIG: RateLimitConfig = {\n29 +  windowMs: 60000,\n30 +  maxRequests: 100,\n31 +};\n32 +\n33 +export class RateLimiter {\n34 +  private config: RateLimitConfig;\n35 +  private store: Map<string, RateLimitEntry> = new Map();\n36 +  private cleanupInterval: NodeJS.Timeout;\n37 +\n38 +  constructor(config: Partial<RateLimitConfig> = {}) {\n39 +    this.config = { ...DEFAULT_CONFIG, ...config };\n40 +    this.cleanupInterval = setInterval(() => this.cleanup(), this.config.windowMs);\n41 +  }\n42 +\n43 +  private getKey(req: Request): string {\n44 +    if (this.config.keyGenerator) {\n45 +      return this.config.keyGenerator(req);\n46 +    }\n47 +    return req.headers['x-forwarded-for'] || req.ip;\n48 +  }\n49 +\n50 +  private cleanup(): void {\n51 +    const now = Date.now();\n52 +    for (const [key, entry] of this.store) {\n53 +      if (now > entry.resetTime) {\n54 +        this.store.delete(key);\n55 +      }\n56 +    }\n57 +  }\n58 +\n59 +  isRateLimited(req: Request): { limited: boolean; remaining: number; resetTime: number } {\n60 +    const key = this.getKey(req);\n61 +    const now = Date.now();\n62 +\n63 +    let entry = this.store.get(key);\n64 +\n65 +    if (!entry || now > entry.resetTime) {\n66 +      entry = {\n67 +        count: 0,\n68 +        resetTime: now + this.config.windowMs,\n69 +      };\n70 +      this.store.set(key, entry);\n71 +    }\n72 +\n73 +    entry.count++;\n74 +\n75 +    const remaining = Math.max(0, this.config.maxRequests - entry.count);\n76 +    const limited = entry.count > this.config.maxRequests;\n77 +\n78 +    if (limited && this.config.onLimitReached) {\n79 +      this.config.onLimitReached(key);\n80 +    }\n81 +\n82 +    return { limited, remaining, resetTime: entry.resetTime };\n83 +  }\n84 +\n85 +  middleware() {\n86 +    return (req: Request, res: Response, next: NextFunction) => {\n87 +      const { limited, remaining, resetTime } = this.isRateLimited(req);\n88 +\n89 +      res.setHeader('X-RateLimit-Limit', String(this.config.maxRequests));\n90 +      res.setHeader('X-RateLimit-Remaining', String(remaining));\n91 +      res.setHeader('X-RateLimit-Reset', String(Math.ceil(resetTime / 1000)));\n92 +\n93 +      if (limited) {\n94 +        res.status(429).json({\n95 +          error: 'Too many requests',\n96 +          retryAfter: Math.ceil((resetTime - Date.now()) / 1000),\n97 +        });\n98 +        return;\n99 +      }\n100 +\n101 +      next();\n102 +    };\n103 +  }\n104 +\n105 +  reset(key: string): void {\n106 +    this.store.delete(key);\n107 +  }\n108 +\n109 +  resetAll(): void {\n110 +    this.store.clear();\n111 +  }\n112 +\n113 +  getStats(): { totalKeys: number; totalRequests: number } {\n114 +    let totalRequests = 0;\n115 +    for (const entry of this.store.values()) {\n116 +      totalRequests += entry.count;\n117 +    }\n118 +    return {\n119 +      totalKeys: this.store.size,\n120 +      totalRequests,\n121 +    };\n122 +  }\n123 +\n124 +  destroy(): void {\n125 +    clearInterval(this.cleanupInterval);\n126 +    this.store.clear();\n127 +  }\n128 +}\n129 +\n130 +export function createRateLimiter(config?: Partial<RateLimitConfig>): RateLimiter {\n131 +  return new RateLimiter(config);\n132 +}\n133 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/security/src/middleware/RateLimiter.ts\",\"relevantLinesStart\":57,\"relevantLinesEnd\":67}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"let entry = this.store.get(key);\\n\\n    if (!entry || now > entry.resetTime) {\\n      entry = {\\n        count: 0,\\n        resetTime: now + this.config.windowMs,\\n      };\\n      this.store.set(key, entry);\\n    }\\n\\n    entry.count++;\",\n    \"improvedCode\": \"// Use atomic check-and-increment pattern\\n    let entry = this.store.get(key);\\n    const needsReset = !entry || now > entry.resetTime;\\n    \\n    if (needsReset) {\\n      entry = {\\n        count: 1,  // Start at 1, not 0 then increment\\n        resetTime: now + this.config.windowMs,\\n      };\\n      this.store.set(key, entry);\\n    } else {\\n      entry.count++;\\n    }\",\n    \"relevantFile\": \"packages/security/src/middleware/RateLimiter.ts\",\n    \"relevantLinesEnd\": 67,\n    \"suggestionContent\": \"The `isRateLimited` method has a race condition. Between checking if the entry exists and incrementing the count, another concurrent request could create or modify the entry. In a high-concurrency environment (or when using clustering), this allows more requests than the limit because multiple requests can pass the check before any of them increment the counter. Use atomic operations or a mutex for thread-safe rate limiting.\",\n    \"oneSentenceSummary\": \"Race condition in rate limiting - concurrent requests can bypass limit\",\n    \"relevantLinesStart\": 57\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 13: packages/state/src/reducers/cartReducer.ts",
    "vars": {
      "fileContent": "export interface CartItem {\n  productId: string;\n  name: string;\n  price: number;\n  quantity: number;\n  options?: Record<string, string>;\n}\n\nexport interface CartState {\n  items: CartItem[];\n  couponCode: string | null;\n  discountPercent: number;\n  lastUpdated: number;\n}\n\nexport type CartAction =\n  | { type: 'ADD_ITEM'; payload: CartItem }\n  | { type: 'REMOVE_ITEM'; payload: { productId: string } }\n  | { type: 'UPDATE_QUANTITY'; payload: { productId: string; quantity: number } }\n  | { type: 'APPLY_COUPON'; payload: { code: string; discount: number } }\n  | { type: 'CLEAR_CART' }\n  | { type: 'RESTORE_CART'; payload: CartState };\n\nexport const initialCartState: CartState = {\n  items: [],\n  couponCode: null,\n  discountPercent: 0,\n  lastUpdated: Date.now(),\n};\n\nfunction findItemIndex(items: CartItem[], productId: string): number {\n  return items.findIndex(item => item.productId === productId);\n}\n\nexport function cartReducer(\n  state: CartState = initialCartState,\n  action: CartAction\n): CartState {\n  switch (action.type) {\n    case 'ADD_ITEM': {\n      const existingIndex = findItemIndex(state.items, action.payload.productId);\n\n      if (existingIndex >= 0) {\n        const updatedItems = [...state.items];\n        updatedItems[existingIndex].quantity += action.payload.quantity;\n        return {\n          ...state,\n          items: updatedItems,\n          lastUpdated: Date.now(),\n        };\n      }\n\n      return {\n        ...state,\n        items: [...state.items, action.payload],\n        lastUpdated: Date.now(),\n      };\n    }\n\n    case 'REMOVE_ITEM': {\n      return {\n        ...state,\n        items: state.items.filter(\n          item => item.productId !== action.payload.productId\n        ),\n        lastUpdated: Date.now(),\n      };\n    }\n\n    case 'UPDATE_QUANTITY': {\n      const index = findItemIndex(state.items, action.payload.productId);\n      if (index < 0) return state;\n\n      if (action.payload.quantity <= 0) {\n        return cartReducer(state, {\n          type: 'REMOVE_ITEM',\n          payload: { productId: action.payload.productId },\n        });\n      }\n\n      const updatedItems = [...state.items];\n      updatedItems[index].quantity = action.payload.quantity;\n      return {\n        ...state,\n        items: updatedItems,\n        lastUpdated: Date.now(),\n      };\n    }\n\n    case 'APPLY_COUPON': {\n      return {\n        ...state,\n        couponCode: action.payload.code,\n        discountPercent: action.payload.discount,\n        lastUpdated: Date.now(),\n      };\n    }\n\n    case 'CLEAR_CART': {\n      return {\n        ...initialCartState,\n        lastUpdated: Date.now(),\n      };\n    }\n\n    case 'RESTORE_CART': {\n      return {\n        ...action.payload,\n        lastUpdated: Date.now(),\n      };\n    }\n\n    default:\n      return state;\n  }\n}\n\nexport function selectCartTotal(state: CartState): number {\n  const subtotal = state.items.reduce(\n    (sum, item) => sum + item.price * item.quantity,\n    0\n  );\n  return subtotal * (1 - state.discountPercent / 100);\n}\n\nexport function selectItemCount(state: CartState): number {\n  return state.items.reduce((sum, item) => sum + item.quantity, 0);\n}\n",
      "patchWithLinesStr": "## file: 'packages/state/src/reducers/cartReducer.ts'\n\n@@ -0,0 +1,129 @@\n__new hunk__\n1 +export interface CartItem {\n2 +  productId: string;\n3 +  name: string;\n4 +  price: number;\n5 +  quantity: number;\n6 +  options?: Record<string, string>;\n7 +}\n8 +\n9 +export interface CartState {\n10 +  items: CartItem[];\n11 +  couponCode: string | null;\n12 +  discountPercent: number;\n13 +  lastUpdated: number;\n14 +}\n15 +\n16 +export type CartAction =\n17 +  | { type: 'ADD_ITEM'; payload: CartItem }\n18 +  | { type: 'REMOVE_ITEM'; payload: { productId: string } }\n19 +  | { type: 'UPDATE_QUANTITY'; payload: { productId: string; quantity: number } }\n20 +  | { type: 'APPLY_COUPON'; payload: { code: string; discount: number } }\n21 +  | { type: 'CLEAR_CART' }\n22 +  | { type: 'RESTORE_CART'; payload: CartState };\n23 +\n24 +export const initialCartState: CartState = {\n25 +  items: [],\n26 +  couponCode: null,\n27 +  discountPercent: 0,\n28 +  lastUpdated: Date.now(),\n29 +};\n30 +\n31 +function findItemIndex(items: CartItem[], productId: string): number {\n32 +  return items.findIndex(item => item.productId === productId);\n33 +}\n34 +\n35 +export function cartReducer(\n36 +  state: CartState = initialCartState,\n37 +  action: CartAction\n38 +): CartState {\n39 +  switch (action.type) {\n40 +    case 'ADD_ITEM': {\n41 +      const existingIndex = findItemIndex(state.items, action.payload.productId);\n42 +\n43 +      if (existingIndex >= 0) {\n44 +        const updatedItems = [...state.items];\n45 +        updatedItems[existingIndex].quantity += action.payload.quantity;\n46 +        return {\n47 +          ...state,\n48 +          items: updatedItems,\n49 +          lastUpdated: Date.now(),\n50 +        };\n51 +      }\n52 +\n53 +      return {\n54 +        ...state,\n55 +        items: [...state.items, action.payload],\n56 +        lastUpdated: Date.now(),\n57 +      };\n58 +    }\n59 +\n60 +    case 'REMOVE_ITEM': {\n61 +      return {\n62 +        ...state,\n63 +        items: state.items.filter(\n64 +          item => item.productId !== action.payload.productId\n65 +        ),\n66 +        lastUpdated: Date.now(),\n67 +      };\n68 +    }\n69 +\n70 +    case 'UPDATE_QUANTITY': {\n71 +      const index = findItemIndex(state.items, action.payload.productId);\n72 +      if (index < 0) return state;\n73 +\n74 +      if (action.payload.quantity <= 0) {\n75 +        return cartReducer(state, {\n76 +          type: 'REMOVE_ITEM',\n77 +          payload: { productId: action.payload.productId },\n78 +        });\n79 +      }\n80 +\n81 +      const updatedItems = [...state.items];\n82 +      updatedItems[index].quantity = action.payload.quantity;\n83 +      return {\n84 +        ...state,\n85 +        items: updatedItems,\n86 +        lastUpdated: Date.now(),\n87 +      };\n88 +    }\n89 +\n90 +    case 'APPLY_COUPON': {\n91 +      return {\n92 +        ...state,\n93 +        couponCode: action.payload.code,\n94 +        discountPercent: action.payload.discount,\n95 +        lastUpdated: Date.now(),\n96 +      };\n97 +    }\n98 +\n99 +    case 'CLEAR_CART': {\n100 +      return {\n101 +        ...initialCartState,\n102 +        lastUpdated: Date.now(),\n103 +      };\n104 +    }\n105 +\n106 +    case 'RESTORE_CART': {\n107 +      return {\n108 +        ...action.payload,\n109 +        lastUpdated: Date.now(),\n110 +      };\n111 +    }\n112 +\n113 +    default:\n114 +      return state;\n115 +  }\n116 +}\n117 +\n118 +export function selectCartTotal(state: CartState): number {\n119 +  const subtotal = state.items.reduce(\n120 +    (sum, item) => sum + item.price * item.quantity,\n121 +    0\n122 +  );\n123 +  return subtotal * (1 - state.discountPercent / 100);\n124 +}\n125 +\n126 +export function selectItemCount(state: CartState): number {\n127 +  return state.items.reduce((sum, item) => sum + item.quantity, 0);\n128 +}\n129 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/state/src/reducers/cartReducer.ts\",\"relevantLinesStart\":43,\"relevantLinesEnd\":44}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"const updatedItems = [...state.items];\\n        updatedItems[existingIndex].quantity += action.payload.quantity;\",\n    \"improvedCode\": \"const updatedItems = state.items.map((item, index) =>\\n          index === existingIndex\\n            ? { ...item, quantity: item.quantity + action.payload.quantity }\\n            : item\\n        );\",\n    \"relevantFile\": \"packages/state/src/reducers/cartReducer.ts\",\n    \"relevantLinesEnd\": 44,\n    \"suggestionContent\": \"In the 'ADD_ITEM' and 'UPDATE_QUANTITY' cases, the code creates a shallow copy of the items array with `[...state.items]`, but then mutates the object at `updatedItems[index]` directly. Since array spread only creates a shallow copy, `updatedItems[existingIndex]` still references the same object as `state.items[existingIndex]`. This mutates the original state, breaking Redux/reducer immutability principles and causing issues with change detection, memoization, and time-travel debugging.\",\n    \"oneSentenceSummary\": \"Shallow array copy followed by object mutation breaks reducer immutability\",\n    \"relevantLinesStart\": 43\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 14: packages/state/src/store/StateManager.ts",
    "vars": {
      "fileContent": "export type StateListener<T> = (state: T, prevState: T) => void;\nexport type StateSelector<T, R> = (state: T) => R;\nexport type StateUpdater<T> = (state: T) => Partial<T>;\n\nexport interface StateManagerOptions<T> {\n  initialState: T;\n  persist?: boolean;\n  storageKey?: string;\n  middleware?: Array<(state: T, action: string) => T>;\n}\n\nexport interface StateSnapshot<T> {\n  state: T;\n  timestamp: number;\n  action: string;\n}\n\nfunction deepMerge<T extends object>(target: T, source: Partial<T>): T {\n  const result = { ...target };\n\n  for (const key in source) {\n    if (source.hasOwnProperty(key)) {\n      const sourceValue = source[key];\n      const targetValue = target[key];\n\n      if (\n        sourceValue !== null &&\n        typeof sourceValue === 'object' &&\n        !Array.isArray(sourceValue) &&\n        targetValue !== null &&\n        typeof targetValue === 'object' &&\n        !Array.isArray(targetValue)\n      ) {\n        (result as any)[key] = deepMerge(targetValue as object, sourceValue as object);\n      } else {\n        (result as any)[key] = sourceValue;\n      }\n    }\n  }\n\n  return result;\n}\n\nfunction deepClone<T>(obj: T): T {\n  if (obj === null || typeof obj !== 'object') {\n    return obj;\n  }\n\n  if (Array.isArray(obj)) {\n    return obj.map(item => deepClone(item)) as unknown as T;\n  }\n\n  const cloned = {} as T;\n  for (const key in obj) {\n    if (obj.hasOwnProperty(key)) {\n      (cloned as any)[key] = deepClone(obj[key]);\n    }\n  }\n  return cloned;\n}\n\nexport class StateManager<T extends object> {\n  private state: T;\n  private listeners: Set<StateListener<T>> = new Set();\n  private history: StateSnapshot<T>[] = [];\n  private maxHistoryLength = 50;\n  private options: StateManagerOptions<T>;\n\n  constructor(options: StateManagerOptions<T>) {\n    this.options = options;\n    this.state = this.loadPersistedState() || deepClone(options.initialState);\n    this.saveSnapshot('init');\n  }\n\n  private loadPersistedState(): T | null {\n    if (!this.options.persist || !this.options.storageKey) {\n      return null;\n    }\n\n    try {\n      const stored = localStorage.getItem(this.options.storageKey);\n      if (stored) {\n        return JSON.parse(stored);\n      }\n    } catch (error) {\n      console.warn('Failed to load persisted state:', error);\n    }\n\n    return null;\n  }\n\n  private persistState(): void {\n    if (!this.options.persist || !this.options.storageKey) {\n      return;\n    }\n\n    try {\n      localStorage.setItem(this.options.storageKey, JSON.stringify(this.state));\n    } catch (error) {\n      console.warn('Failed to persist state:', error);\n    }\n  }\n\n  private saveSnapshot(action: string): void {\n    this.history.push({\n      state: deepClone(this.state),\n      timestamp: Date.now(),\n      action,\n    });\n\n    if (this.history.length > this.maxHistoryLength) {\n      this.history.shift();\n    }\n  }\n\n  private notifyListeners(prevState: T): void {\n    this.listeners.forEach(listener => {\n      listener(this.state, prevState);\n    });\n  }\n\n  getState(): T {\n    return this.state;\n  }\n\n  setState(updater: StateUpdater<T> | Partial<T>, action = 'setState'): void {\n    const prevState = this.state;\n    const updates = typeof updater === 'function' ? updater(this.state) : updater;\n\n    this.state = deepMerge(this.state, updates);\n\n    if (this.options.middleware) {\n      for (const mw of this.options.middleware) {\n        this.state = mw(this.state, action);\n      }\n    }\n\n    this.saveSnapshot(action);\n    this.persistState();\n    this.notifyListeners(prevState);\n  }\n\n  subscribe(listener: StateListener<T>): () => void {\n    this.listeners.add(listener);\n    return () => this.listeners.delete(listener);\n  }\n\n  select<R>(selector: StateSelector<T, R>): R {\n    return selector(this.state);\n  }\n\n  undo(): boolean {\n    if (this.history.length < 2) {\n      return false;\n    }\n\n    this.history.pop(); // Remove current state\n    const previousSnapshot = this.history[this.history.length - 1];\n\n    if (previousSnapshot) {\n      const prevState = this.state;\n      this.state = deepClone(previousSnapshot.state);\n      this.persistState();\n      this.notifyListeners(prevState);\n      return true;\n    }\n\n    return false;\n  }\n\n  getHistory(): StateSnapshot<T>[] {\n    return [...this.history];\n  }\n\n  importState(serialized: string): void {\n    const imported = JSON.parse(serialized);\n    this.setState(imported, 'import');\n  }\n\n  exportState(): string {\n    return JSON.stringify(this.state);\n  }\n\n  reset(): void {\n    const prevState = this.state;\n    this.state = deepClone(this.options.initialState);\n    this.history = [];\n    this.saveSnapshot('reset');\n    this.persistState();\n    this.notifyListeners(prevState);\n  }\n}\n\nexport function createStateManager<T extends object>(\n  options: StateManagerOptions<T>\n): StateManager<T> {\n  return new StateManager(options);\n}\n",
      "patchWithLinesStr": "## file: 'packages/state/src/store/StateManager.ts'\n\n@@ -0,0 +1,199 @@\n__new hunk__\n1 +export type StateListener<T> = (state: T, prevState: T) => void;\n2 +export type StateSelector<T, R> = (state: T) => R;\n3 +export type StateUpdater<T> = (state: T) => Partial<T>;\n4 +\n5 +export interface StateManagerOptions<T> {\n6 +  initialState: T;\n7 +  persist?: boolean;\n8 +  storageKey?: string;\n9 +  middleware?: Array<(state: T, action: string) => T>;\n10 +}\n11 +\n12 +export interface StateSnapshot<T> {\n13 +  state: T;\n14 +  timestamp: number;\n15 +  action: string;\n16 +}\n17 +\n18 +function deepMerge<T extends object>(target: T, source: Partial<T>): T {\n19 +  const result = { ...target };\n20 +\n21 +  for (const key in source) {\n22 +    if (source.hasOwnProperty(key)) {\n23 +      const sourceValue = source[key];\n24 +      const targetValue = target[key];\n25 +\n26 +      if (\n27 +        sourceValue !== null &&\n28 +        typeof sourceValue === 'object' &&\n29 +        !Array.isArray(sourceValue) &&\n30 +        targetValue !== null &&\n31 +        typeof targetValue === 'object' &&\n32 +        !Array.isArray(targetValue)\n33 +      ) {\n34 +        (result as any)[key] = deepMerge(targetValue as object, sourceValue as object);\n35 +      } else {\n36 +        (result as any)[key] = sourceValue;\n37 +      }\n38 +    }\n39 +  }\n40 +\n41 +  return result;\n42 +}\n43 +\n44 +function deepClone<T>(obj: T): T {\n45 +  if (obj === null || typeof obj !== 'object') {\n46 +    return obj;\n47 +  }\n48 +\n49 +  if (Array.isArray(obj)) {\n50 +    return obj.map(item => deepClone(item)) as unknown as T;\n51 +  }\n52 +\n53 +  const cloned = {} as T;\n54 +  for (const key in obj) {\n55 +    if (obj.hasOwnProperty(key)) {\n56 +      (cloned as any)[key] = deepClone(obj[key]);\n57 +    }\n58 +  }\n59 +  return cloned;\n60 +}\n61 +\n62 +export class StateManager<T extends object> {\n63 +  private state: T;\n64 +  private listeners: Set<StateListener<T>> = new Set();\n65 +  private history: StateSnapshot<T>[] = [];\n66 +  private maxHistoryLength = 50;\n67 +  private options: StateManagerOptions<T>;\n68 +\n69 +  constructor(options: StateManagerOptions<T>) {\n70 +    this.options = options;\n71 +    this.state = this.loadPersistedState() || deepClone(options.initialState);\n72 +    this.saveSnapshot('init');\n73 +  }\n74 +\n75 +  private loadPersistedState(): T | null {\n76 +    if (!this.options.persist || !this.options.storageKey) {\n77 +      return null;\n78 +    }\n79 +\n80 +    try {\n81 +      const stored = localStorage.getItem(this.options.storageKey);\n82 +      if (stored) {\n83 +        return JSON.parse(stored);\n84 +      }\n85 +    } catch (error) {\n86 +      console.warn('Failed to load persisted state:', error);\n87 +    }\n88 +\n89 +    return null;\n90 +  }\n91 +\n92 +  private persistState(): void {\n93 +    if (!this.options.persist || !this.options.storageKey) {\n94 +      return;\n95 +    }\n96 +\n97 +    try {\n98 +      localStorage.setItem(this.options.storageKey, JSON.stringify(this.state));\n99 +    } catch (error) {\n100 +      console.warn('Failed to persist state:', error);\n101 +    }\n102 +  }\n103 +\n104 +  private saveSnapshot(action: string): void {\n105 +    this.history.push({\n106 +      state: deepClone(this.state),\n107 +      timestamp: Date.now(),\n108 +      action,\n109 +    });\n110 +\n111 +    if (this.history.length > this.maxHistoryLength) {\n112 +      this.history.shift();\n113 +    }\n114 +  }\n115 +\n116 +  private notifyListeners(prevState: T): void {\n117 +    this.listeners.forEach(listener => {\n118 +      listener(this.state, prevState);\n119 +    });\n120 +  }\n121 +\n122 +  getState(): T {\n123 +    return this.state;\n124 +  }\n125 +\n126 +  setState(updater: StateUpdater<T> | Partial<T>, action = 'setState'): void {\n127 +    const prevState = this.state;\n128 +    const updates = typeof updater === 'function' ? updater(this.state) : updater;\n129 +\n130 +    this.state = deepMerge(this.state, updates);\n131 +\n132 +    if (this.options.middleware) {\n133 +      for (const mw of this.options.middleware) {\n134 +        this.state = mw(this.state, action);\n135 +      }\n136 +    }\n137 +\n138 +    this.saveSnapshot(action);\n139 +    this.persistState();\n140 +    this.notifyListeners(prevState);\n141 +  }\n142 +\n143 +  subscribe(listener: StateListener<T>): () => void {\n144 +    this.listeners.add(listener);\n145 +    return () => this.listeners.delete(listener);\n146 +  }\n147 +\n148 +  select<R>(selector: StateSelector<T, R>): R {\n149 +    return selector(this.state);\n150 +  }\n151 +\n152 +  undo(): boolean {\n153 +    if (this.history.length < 2) {\n154 +      return false;\n155 +    }\n156 +\n157 +    this.history.pop(); // Remove current state\n158 +    const previousSnapshot = this.history[this.history.length - 1];\n159 +\n160 +    if (previousSnapshot) {\n161 +      const prevState = this.state;\n162 +      this.state = deepClone(previousSnapshot.state);\n163 +      this.persistState();\n164 +      this.notifyListeners(prevState);\n165 +      return true;\n166 +    }\n167 +\n168 +    return false;\n169 +  }\n170 +\n171 +  getHistory(): StateSnapshot<T>[] {\n172 +    return [...this.history];\n173 +  }\n174 +\n175 +  importState(serialized: string): void {\n176 +    const imported = JSON.parse(serialized);\n177 +    this.setState(imported, 'import');\n178 +  }\n179 +\n180 +  exportState(): string {\n181 +    return JSON.stringify(this.state);\n182 +  }\n183 +\n184 +  reset(): void {\n185 +    const prevState = this.state;\n186 +    this.state = deepClone(this.options.initialState);\n187 +    this.history = [];\n188 +    this.saveSnapshot('reset');\n189 +    this.persistState();\n190 +    this.notifyListeners(prevState);\n191 +  }\n192 +}\n193 +\n194 +export function createStateManager<T extends object>(\n195 +  options: StateManagerOptions<T>\n196 +): StateManager<T> {\n197 +  return new StateManager(options);\n198 +}\n199 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/state/src/store/StateManager.ts\",\"relevantLinesStart\":20,\"relevantLinesEnd\":22},{\"relevantFile\":\"packages/state/src/store/StateManager.ts\",\"relevantLinesStart\":158,\"relevantLinesEnd\":161}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"for (const key in source) {\\n    if (source.hasOwnProperty(key)) {\",\n    \"improvedCode\": \"for (const key in source) {\\n    if (source.hasOwnProperty(key) && key !== '__proto__' && key !== 'constructor' && key !== 'prototype') {\",\n    \"relevantFile\": \"packages/state/src/store/StateManager.ts\",\n    \"relevantLinesEnd\": 22,\n    \"suggestionContent\": \"The `deepMerge` function uses `hasOwnProperty` check but doesn't guard against `__proto__` or `constructor` keys. An attacker can pass `{\\\"__proto__\\\": {\\\"polluted\\\": true}}` as the source object, which will modify `Object.prototype` and affect all objects in the application. This is a prototype pollution vulnerability.\",\n    \"oneSentenceSummary\": \"Prototype pollution vulnerability - deepMerge doesn't sanitize __proto__ keys\",\n    \"relevantLinesStart\": 20\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"importState(serialized: string): void {\\n    const imported = JSON.parse(serialized);\\n    this.setState(imported, 'import');\\n  }\",\n    \"improvedCode\": \"importState(serialized: string, validator?: (state: unknown) => state is Partial<T>): void {\\n    const imported = JSON.parse(serialized);\\n    if (validator && !validator(imported)) {\\n      throw new Error('Invalid state format');\\n    }\\n    // Use Object.assign for flat merge to avoid prototype pollution\\n    this.setState(imported as Partial<T>, 'import');\\n  }\",\n    \"relevantFile\": \"packages/state/src/store/StateManager.ts\",\n    \"relevantLinesEnd\": 161,\n    \"suggestionContent\": \"The `importState` method parses untrusted JSON and passes it directly to `setState`, which uses `deepMerge`. Combined with the prototype pollution in `deepMerge`, an attacker can pollute prototypes by importing malicious state. Also, there's no validation that the imported state matches the expected schema.\",\n    \"oneSentenceSummary\": \"Unsafe deserialization - importState accepts untrusted JSON without validation\",\n    \"relevantLinesStart\": 158\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 15: packages/billing/src/services/InvoiceCalculator.ts",
    "vars": {
      "fileContent": "export interface LineItem {\n  id: string;\n  description: string;\n  quantity: number;\n  unitPrice: number;\n  taxRate: number;\n  discountPercent?: number;\n}\n\nexport interface Invoice {\n  id: string;\n  customerId: string;\n  items: LineItem[];\n  currency: string;\n  issuedAt: Date;\n  dueAt: Date;\n}\n\nexport interface InvoiceTotals {\n  subtotal: number;\n  totalDiscount: number;\n  totalTax: number;\n  grandTotal: number;\n}\n\nexport function calculateLineItemTotal(item: LineItem): number {\n  const baseAmount = item.quantity * item.unitPrice;\n  const discount = item.discountPercent\n    ? baseAmount * (item.discountPercent / 100)\n    : 0;\n  const afterDiscount = baseAmount - discount;\n  const tax = afterDiscount * (item.taxRate / 100);\n  return afterDiscount + tax;\n}\n\nexport function calculateInvoiceTotals(invoice: Invoice): InvoiceTotals {\n  let subtotal = 0;\n  let totalDiscount = 0;\n  let totalTax = 0;\n\n  for (const item of invoice.items) {\n    const baseAmount = item.quantity * item.unitPrice;\n    const discount = item.discountPercent\n      ? baseAmount * (item.discountPercent / 100)\n      : 0;\n    const afterDiscount = baseAmount - discount;\n    const tax = afterDiscount * (item.taxRate / 100);\n\n    subtotal += baseAmount;\n    totalDiscount += discount;\n    totalTax += tax;\n  }\n\n  const grandTotal = subtotal - totalDiscount + totalTax;\n\n  return {\n    subtotal,\n    totalDiscount,\n    totalTax,\n    grandTotal,\n  };\n}\n\nexport function formatCurrency(amount: number, currency: string): string {\n  return new Intl.NumberFormat('en-US', {\n    style: 'currency',\n    currency,\n  }).format(amount);\n}\n\nexport function splitPayment(\n  total: number,\n  installments: number\n): number[] {\n  const baseAmount = total / installments;\n  const payments = Array(installments).fill(baseAmount);\n\n  const sum = payments.reduce((a, b) => a + b, 0);\n  const remainder = total - sum;\n\n  if (remainder !== 0) {\n    payments[payments.length - 1] += remainder;\n  }\n\n  return payments;\n}\n\nexport class InvoiceCalculator {\n  calculateTotals(invoice: Invoice): InvoiceTotals {\n    return calculateInvoiceTotals(invoice);\n  }\n\n  calculateMonthlyPayments(\n    invoice: Invoice,\n    months: number\n  ): number[] {\n    const totals = this.calculateTotals(invoice);\n    return splitPayment(totals.grandTotal, months);\n  }\n\n  applyPromoCode(\n    invoice: Invoice,\n    discountPercent: number\n  ): Invoice {\n    return {\n      ...invoice,\n      items: invoice.items.map(item => ({\n        ...item,\n        discountPercent: (item.discountPercent ?? 0) + discountPercent,\n      })),\n    };\n  }\n\n  validateInvoice(invoice: Invoice): string[] {\n    const errors: string[] = [];\n\n    if (invoice.items.length === 0) {\n      errors.push('Invoice must have at least one line item');\n    }\n\n    for (const item of invoice.items) {\n      if (item.quantity <= 0) {\n        errors.push(`Item ${item.id}: quantity must be positive`);\n      }\n      if (item.unitPrice < 0) {\n        errors.push(`Item ${item.id}: unit price cannot be negative`);\n      }\n      if (item.taxRate < 0 || item.taxRate > 100) {\n        errors.push(`Item ${item.id}: tax rate must be between 0 and 100`);\n      }\n    }\n\n    return errors;\n  }\n}\n\nexport default InvoiceCalculator;\n",
      "patchWithLinesStr": "## file: 'packages/billing/src/services/InvoiceCalculator.ts'\n\n@@ -0,0 +1,138 @@\n__new hunk__\n1 +export interface LineItem {\n2 +  id: string;\n3 +  description: string;\n4 +  quantity: number;\n5 +  unitPrice: number;\n6 +  taxRate: number;\n7 +  discountPercent?: number;\n8 +}\n9 +\n10 +export interface Invoice {\n11 +  id: string;\n12 +  customerId: string;\n13 +  items: LineItem[];\n14 +  currency: string;\n15 +  issuedAt: Date;\n16 +  dueAt: Date;\n17 +}\n18 +\n19 +export interface InvoiceTotals {\n20 +  subtotal: number;\n21 +  totalDiscount: number;\n22 +  totalTax: number;\n23 +  grandTotal: number;\n24 +}\n25 +\n26 +export function calculateLineItemTotal(item: LineItem): number {\n27 +  const baseAmount = item.quantity * item.unitPrice;\n28 +  const discount = item.discountPercent\n29 +    ? baseAmount * (item.discountPercent / 100)\n30 +    : 0;\n31 +  const afterDiscount = baseAmount - discount;\n32 +  const tax = afterDiscount * (item.taxRate / 100);\n33 +  return afterDiscount + tax;\n34 +}\n35 +\n36 +export function calculateInvoiceTotals(invoice: Invoice): InvoiceTotals {\n37 +  let subtotal = 0;\n38 +  let totalDiscount = 0;\n39 +  let totalTax = 0;\n40 +\n41 +  for (const item of invoice.items) {\n42 +    const baseAmount = item.quantity * item.unitPrice;\n43 +    const discount = item.discountPercent\n44 +      ? baseAmount * (item.discountPercent / 100)\n45 +      : 0;\n46 +    const afterDiscount = baseAmount - discount;\n47 +    const tax = afterDiscount * (item.taxRate / 100);\n48 +\n49 +    subtotal += baseAmount;\n50 +    totalDiscount += discount;\n51 +    totalTax += tax;\n52 +  }\n53 +\n54 +  const grandTotal = subtotal - totalDiscount + totalTax;\n55 +\n56 +  return {\n57 +    subtotal,\n58 +    totalDiscount,\n59 +    totalTax,\n60 +    grandTotal,\n61 +  };\n62 +}\n63 +\n64 +export function formatCurrency(amount: number, currency: string): string {\n65 +  return new Intl.NumberFormat('en-US', {\n66 +    style: 'currency',\n67 +    currency,\n68 +  }).format(amount);\n69 +}\n70 +\n71 +export function splitPayment(\n72 +  total: number,\n73 +  installments: number\n74 +): number[] {\n75 +  const baseAmount = total / installments;\n76 +  const payments = Array(installments).fill(baseAmount);\n77 +\n78 +  const sum = payments.reduce((a, b) => a + b, 0);\n79 +  const remainder = total - sum;\n80 +\n81 +  if (remainder !== 0) {\n82 +    payments[payments.length - 1] += remainder;\n83 +  }\n84 +\n85 +  return payments;\n86 +}\n87 +\n88 +export class InvoiceCalculator {\n89 +  calculateTotals(invoice: Invoice): InvoiceTotals {\n90 +    return calculateInvoiceTotals(invoice);\n91 +  }\n92 +\n93 +  calculateMonthlyPayments(\n94 +    invoice: Invoice,\n95 +    months: number\n96 +  ): number[] {\n97 +    const totals = this.calculateTotals(invoice);\n98 +    return splitPayment(totals.grandTotal, months);\n99 +  }\n100 +\n101 +  applyPromoCode(\n102 +    invoice: Invoice,\n103 +    discountPercent: number\n104 +  ): Invoice {\n105 +    return {\n106 +      ...invoice,\n107 +      items: invoice.items.map(item => ({\n108 +        ...item,\n109 +        discountPercent: (item.discountPercent ?? 0) + discountPercent,\n110 +      })),\n111 +    };\n112 +  }\n113 +\n114 +  validateInvoice(invoice: Invoice): string[] {\n115 +    const errors: string[] = [];\n116 +\n117 +    if (invoice.items.length === 0) {\n118 +      errors.push('Invoice must have at least one line item');\n119 +    }\n120 +\n121 +    for (const item of invoice.items) {\n122 +      if (item.quantity <= 0) {\n123 +        errors.push(`Item ${item.id}: quantity must be positive`);\n124 +      }\n125 +      if (item.unitPrice < 0) {\n126 +        errors.push(`Item ${item.id}: unit price cannot be negative`);\n127 +      }\n128 +      if (item.taxRate < 0 || item.taxRate > 100) {\n129 +        errors.push(`Item ${item.id}: tax rate must be between 0 and 100`);\n130 +      }\n131 +    }\n132 +\n133 +    return errors;\n134 +  }\n135 +}\n136 +\n137 +export default InvoiceCalculator;\n138 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/billing/src/services/InvoiceCalculator.ts\",\"relevantLinesStart\":40,\"relevantLinesEnd\":47}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"const baseAmount = item.quantity * item.unitPrice;\\n    const discount = item.discountPercent\\n      ? baseAmount * (item.discountPercent / 100)\\n      : 0;\\n    const afterDiscount = baseAmount - discount;\\n    const tax = afterDiscount * (item.taxRate / 100);\",\n    \"improvedCode\": \"const baseAmount = Math.round(item.quantity * item.unitPrice * 100) / 100;\\n    const discount = item.discountPercent\\n      ? Math.round(baseAmount * (item.discountPercent / 100) * 100) / 100\\n      : 0;\\n    const afterDiscount = Math.round((baseAmount - discount) * 100) / 100;\\n    const tax = Math.round(afterDiscount * (item.taxRate / 100) * 100) / 100;\",\n    \"relevantFile\": \"packages/billing/src/services/InvoiceCalculator.ts\",\n    \"relevantLinesEnd\": 47,\n    \"suggestionContent\": \"Financial calculations using floating point arithmetic will accumulate precision errors. For example, `0.1 + 0.2 = 0.30000000000000004` in JavaScript. When calculating invoice totals with multiple line items, these errors compound and can result in incorrect totals (e.g., $99.99999999 instead of $100.00). Use integer arithmetic with cents, a decimal library like decimal.js, or round intermediate results to avoid displaying incorrect amounts to customers.\",\n    \"oneSentenceSummary\": \"Floating point arithmetic in financial calculations causes precision errors\",\n    \"relevantLinesStart\": 40\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 16: packages/events/src/emitter/TypedEventEmitter.ts",
    "vars": {
      "fileContent": "export type EventCallback<T = unknown> = (data: T) => void | Promise<void>;\nexport type UnsubscribeFn = () => void;\n\ninterface EventSubscription<T> {\n  callback: EventCallback<T>;\n  once: boolean;\n  priority: number;\n}\n\nexport class TypedEventEmitter<TEvents extends Record<string, unknown>> {\n  private listeners: Map<keyof TEvents, EventSubscription<any>[]> = new Map();\n  private maxListeners = 10;\n  private eventHistory: Map<keyof TEvents, unknown[]> = new Map();\n  private historySize = 100;\n\n  setMaxListeners(n: number): this {\n    this.maxListeners = n;\n    return this;\n  }\n\n  on<K extends keyof TEvents>(\n    event: K,\n    callback: EventCallback<TEvents[K]>,\n    priority = 0\n  ): UnsubscribeFn {\n    if (!this.listeners.has(event)) {\n      this.listeners.set(event, []);\n    }\n\n    const subscriptions = this.listeners.get(event)!;\n\n    if (subscriptions.length >= this.maxListeners) {\n      console.warn(\n        `MaxListenersExceededWarning: Possible memory leak detected. ` +\n        `${subscriptions.length + 1} listeners added for event \"${String(event)}\".`\n      );\n    }\n\n    subscriptions.push({ callback, once: false, priority });\n    subscriptions.sort((a, b) => b.priority - a.priority);\n\n    return () => this.off(event, callback);\n  }\n\n  once<K extends keyof TEvents>(\n    event: K,\n    callback: EventCallback<TEvents[K]>,\n    priority = 0\n  ): UnsubscribeFn {\n    if (!this.listeners.has(event)) {\n      this.listeners.set(event, []);\n    }\n\n    const subscriptions = this.listeners.get(event)!;\n    subscriptions.push({ callback, once: true, priority });\n    subscriptions.sort((a, b) => b.priority - a.priority);\n\n    return () => this.off(event, callback);\n  }\n\n  off<K extends keyof TEvents>(\n    event: K,\n    callback: EventCallback<TEvents[K]>\n  ): this {\n    const subscriptions = this.listeners.get(event);\n    if (!subscriptions) return this;\n\n    const index = subscriptions.findIndex(sub => sub.callback === callback);\n    if (index !== -1) {\n      subscriptions.splice(index, 1);\n    }\n\n    return this;\n  }\n\n  emit<K extends keyof TEvents>(event: K, data: TEvents[K]): this {\n    this.recordHistory(event, data);\n\n    const subscriptions = this.listeners.get(event);\n    if (!subscriptions) return this;\n\n    const toRemove: EventSubscription<TEvents[K]>[] = [];\n\n    for (const sub of subscriptions) {\n      sub.callback(data);\n\n      if (sub.once) {\n        toRemove.push(sub);\n      }\n    }\n\n    for (const sub of toRemove) {\n      const index = subscriptions.indexOf(sub);\n      if (index !== -1) {\n        subscriptions.splice(index, 1);\n      }\n    }\n\n    return this;\n  }\n\n  async emitAsync<K extends keyof TEvents>(\n    event: K,\n    data: TEvents[K]\n  ): Promise<void> {\n    this.recordHistory(event, data);\n\n    const subscriptions = this.listeners.get(event);\n    if (!subscriptions) return;\n\n    for (const sub of subscriptions) {\n      await sub.callback(data);\n\n      if (sub.once) {\n        this.off(event, sub.callback);\n      }\n    }\n  }\n\n  private recordHistory<K extends keyof TEvents>(event: K, data: TEvents[K]): void {\n    if (!this.eventHistory.has(event)) {\n      this.eventHistory.set(event, []);\n    }\n\n    const history = this.eventHistory.get(event)!;\n    history.push(data);\n\n    if (history.length > this.historySize) {\n      history.shift();\n    }\n  }\n\n  getHistory<K extends keyof TEvents>(event: K): TEvents[K][] {\n    return (this.eventHistory.get(event) as TEvents[K][]) || [];\n  }\n\n  listenerCount<K extends keyof TEvents>(event: K): number {\n    return this.listeners.get(event)?.length ?? 0;\n  }\n\n  removeAllListeners<K extends keyof TEvents>(event?: K): this {\n    if (event) {\n      this.listeners.delete(event);\n    } else {\n      this.listeners.clear();\n    }\n    return this;\n  }\n\n  eventNames(): (keyof TEvents)[] {\n    return Array.from(this.listeners.keys());\n  }\n}\n\nexport function createEventEmitter<TEvents extends Record<string, unknown>>(): TypedEventEmitter<TEvents> {\n  return new TypedEventEmitter<TEvents>();\n}\n",
      "patchWithLinesStr": "## file: 'packages/events/src/emitter/TypedEventEmitter.ts'\n\n@@ -0,0 +1,158 @@\n__new hunk__\n1 +export type EventCallback<T = unknown> = (data: T) => void | Promise<void>;\n2 +export type UnsubscribeFn = () => void;\n3 +\n4 +interface EventSubscription<T> {\n5 +  callback: EventCallback<T>;\n6 +  once: boolean;\n7 +  priority: number;\n8 +}\n9 +\n10 +export class TypedEventEmitter<TEvents extends Record<string, unknown>> {\n11 +  private listeners: Map<keyof TEvents, EventSubscription<any>[]> = new Map();\n12 +  private maxListeners = 10;\n13 +  private eventHistory: Map<keyof TEvents, unknown[]> = new Map();\n14 +  private historySize = 100;\n15 +\n16 +  setMaxListeners(n: number): this {\n17 +    this.maxListeners = n;\n18 +    return this;\n19 +  }\n20 +\n21 +  on<K extends keyof TEvents>(\n22 +    event: K,\n23 +    callback: EventCallback<TEvents[K]>,\n24 +    priority = 0\n25 +  ): UnsubscribeFn {\n26 +    if (!this.listeners.has(event)) {\n27 +      this.listeners.set(event, []);\n28 +    }\n29 +\n30 +    const subscriptions = this.listeners.get(event)!;\n31 +\n32 +    if (subscriptions.length >= this.maxListeners) {\n33 +      console.warn(\n34 +        `MaxListenersExceededWarning: Possible memory leak detected. ` +\n35 +        `${subscriptions.length + 1} listeners added for event \"${String(event)}\".`\n36 +      );\n37 +    }\n38 +\n39 +    subscriptions.push({ callback, once: false, priority });\n40 +    subscriptions.sort((a, b) => b.priority - a.priority);\n41 +\n42 +    return () => this.off(event, callback);\n43 +  }\n44 +\n45 +  once<K extends keyof TEvents>(\n46 +    event: K,\n47 +    callback: EventCallback<TEvents[K]>,\n48 +    priority = 0\n49 +  ): UnsubscribeFn {\n50 +    if (!this.listeners.has(event)) {\n51 +      this.listeners.set(event, []);\n52 +    }\n53 +\n54 +    const subscriptions = this.listeners.get(event)!;\n55 +    subscriptions.push({ callback, once: true, priority });\n56 +    subscriptions.sort((a, b) => b.priority - a.priority);\n57 +\n58 +    return () => this.off(event, callback);\n59 +  }\n60 +\n61 +  off<K extends keyof TEvents>(\n62 +    event: K,\n63 +    callback: EventCallback<TEvents[K]>\n64 +  ): this {\n65 +    const subscriptions = this.listeners.get(event);\n66 +    if (!subscriptions) return this;\n67 +\n68 +    const index = subscriptions.findIndex(sub => sub.callback === callback);\n69 +    if (index !== -1) {\n70 +      subscriptions.splice(index, 1);\n71 +    }\n72 +\n73 +    return this;\n74 +  }\n75 +\n76 +  emit<K extends keyof TEvents>(event: K, data: TEvents[K]): this {\n77 +    this.recordHistory(event, data);\n78 +\n79 +    const subscriptions = this.listeners.get(event);\n80 +    if (!subscriptions) return this;\n81 +\n82 +    const toRemove: EventSubscription<TEvents[K]>[] = [];\n83 +\n84 +    for (const sub of subscriptions) {\n85 +      sub.callback(data);\n86 +\n87 +      if (sub.once) {\n88 +        toRemove.push(sub);\n89 +      }\n90 +    }\n91 +\n92 +    for (const sub of toRemove) {\n93 +      const index = subscriptions.indexOf(sub);\n94 +      if (index !== -1) {\n95 +        subscriptions.splice(index, 1);\n96 +      }\n97 +    }\n98 +\n99 +    return this;\n100 +  }\n101 +\n102 +  async emitAsync<K extends keyof TEvents>(\n103 +    event: K,\n104 +    data: TEvents[K]\n105 +  ): Promise<void> {\n106 +    this.recordHistory(event, data);\n107 +\n108 +    const subscriptions = this.listeners.get(event);\n109 +    if (!subscriptions) return;\n110 +\n111 +    for (const sub of subscriptions) {\n112 +      await sub.callback(data);\n113 +\n114 +      if (sub.once) {\n115 +        this.off(event, sub.callback);\n116 +      }\n117 +    }\n118 +  }\n119 +\n120 +  private recordHistory<K extends keyof TEvents>(event: K, data: TEvents[K]): void {\n121 +    if (!this.eventHistory.has(event)) {\n122 +      this.eventHistory.set(event, []);\n123 +    }\n124 +\n125 +    const history = this.eventHistory.get(event)!;\n126 +    history.push(data);\n127 +\n128 +    if (history.length > this.historySize) {\n129 +      history.shift();\n130 +    }\n131 +  }\n132 +\n133 +  getHistory<K extends keyof TEvents>(event: K): TEvents[K][] {\n134 +    return (this.eventHistory.get(event) as TEvents[K][]) || [];\n135 +  }\n136 +\n137 +  listenerCount<K extends keyof TEvents>(event: K): number {\n138 +    return this.listeners.get(event)?.length ?? 0;\n139 +  }\n140 +\n141 +  removeAllListeners<K extends keyof TEvents>(event?: K): this {\n142 +    if (event) {\n143 +      this.listeners.delete(event);\n144 +    } else {\n145 +      this.listeners.clear();\n146 +    }\n147 +    return this;\n148 +  }\n149 +\n150 +  eventNames(): (keyof TEvents)[] {\n151 +    return Array.from(this.listeners.keys());\n152 +  }\n153 +}\n154 +\n155 +export function createEventEmitter<TEvents extends Record<string, unknown>>(): TypedEventEmitter<TEvents> {\n156 +  return new TypedEventEmitter<TEvents>();\n157 +}\n158 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/events/src/emitter/TypedEventEmitter.ts\",\"relevantLinesStart\":74,\"relevantLinesEnd\":88}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"for (const sub of subscriptions) {\\n      sub.callback(data);\\n\\n      if (sub.once) {\\n        toRemove.push(sub);\\n      }\\n    }\\n\\n    for (const sub of toRemove) {\\n      const index = subscriptions.indexOf(sub);\\n      if (index !== -1) {\\n        subscriptions.splice(index, 1);\\n      }\\n    }\",\n    \"improvedCode\": \"const toExecute = [...subscriptions];\\n    \\n    for (const sub of toExecute) {\\n      sub.callback(data);\\n\\n      if (sub.once) {\\n        const index = subscriptions.indexOf(sub);\\n        if (index !== -1) {\\n          subscriptions.splice(index, 1);\\n        }\\n      }\\n    }\",\n    \"relevantFile\": \"packages/events/src/emitter/TypedEventEmitter.ts\",\n    \"relevantLinesEnd\": 88,\n    \"suggestionContent\": \"In the `emit` method, the code iterates over `subscriptions` array while also modifying it (removing 'once' listeners via splice). This causes items to be skipped when iterating. For example, if subscriptions[0] is a 'once' listener and gets removed, subscriptions[1] shifts to index 0, but the loop continues to index 1, skipping what was originally subscriptions[1].\",\n    \"oneSentenceSummary\": \"Iterating and splicing same array causes listeners to be skipped\",\n    \"relevantLinesStart\": 74\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 17: packages/dom/src/observers/ResizeObserverManager.ts",
    "vars": {
      "fileContent": "type ResizeCallback = (entry: ResizeObserverEntry) => void;\n\ninterface ObservedElement {\n  element: Element;\n  callback: ResizeCallback;\n}\n\nexport class ResizeObserverManager {\n  private observer: ResizeObserver;\n  private observedElements: Map<Element, ResizeCallback> = new Map();\n  private isInitialized = false;\n\n  constructor() {\n    this.observer = new ResizeObserver(this.handleResize.bind(this));\n    this.isInitialized = true;\n  }\n\n  private handleResize(entries: ResizeObserverEntry[]): void {\n    for (const entry of entries) {\n      const callback = this.observedElements.get(entry.target);\n      if (callback) {\n        try {\n          callback(entry);\n        } catch (error) {\n          console.error('Resize callback error:', error);\n        }\n      }\n    }\n  }\n\n  observe(element: Element, callback: ResizeCallback): void {\n    if (!this.isInitialized) {\n      throw new Error('ResizeObserverManager not initialized');\n    }\n\n    if (this.observedElements.has(element)) {\n      console.warn('Element already being observed, updating callback');\n    }\n\n    this.observedElements.set(element, callback);\n    this.observer.observe(element);\n  }\n\n  unobserve(element: Element): void {\n    this.observer.unobserve(element);\n    this.observedElements.delete(element);\n  }\n\n  disconnect(): void {\n    this.observer.disconnect();\n    this.observedElements.clear();\n  }\n\n  isObserving(element: Element): boolean {\n    return this.observedElements.has(element);\n  }\n}\n\nexport function useResizeObserver(\n  elementRef: { current: Element | null },\n  callback: ResizeCallback\n): void {\n  const manager = getGlobalManager();\n\n  if (elementRef.current) {\n    manager.observe(elementRef.current, callback);\n  }\n\n  return () => {\n    if (elementRef.current) {\n      manager.unobserve(elementRef.current);\n    }\n  };\n}\n\nlet globalManager: ResizeObserverManager | null = null;\n\nfunction getGlobalManager(): ResizeObserverManager {\n  if (!globalManager) {\n    globalManager = new ResizeObserverManager();\n  }\n  return globalManager;\n}\n\nexport class ElementResizeWatcher {\n  private cleanup: (() => void) | null = null;\n\n  watch(element: Element, onResize: ResizeCallback): void {\n    const manager = getGlobalManager();\n    manager.observe(element, onResize);\n\n    this.cleanup = () => {\n      manager.unobserve(element);\n    };\n\n    window.addEventListener('beforeunload', this.cleanup.bind(this));\n  }\n\n  unwatch(): void {\n    if (this.cleanup) {\n      this.cleanup();\n      this.cleanup = null;\n    }\n  }\n\n  destroy(): void {\n    this.unwatch();\n    window.removeEventListener('beforeunload', this.cleanup?.bind(this) as EventListener);\n  }\n}\n\nexport default ResizeObserverManager;\n",
      "patchWithLinesStr": "## file: 'packages/dom/src/observers/ResizeObserverManager.ts'\n\n@@ -0,0 +1,113 @@\n__new hunk__\n1 +type ResizeCallback = (entry: ResizeObserverEntry) => void;\n2 +\n3 +interface ObservedElement {\n4 +  element: Element;\n5 +  callback: ResizeCallback;\n6 +}\n7 +\n8 +export class ResizeObserverManager {\n9 +  private observer: ResizeObserver;\n10 +  private observedElements: Map<Element, ResizeCallback> = new Map();\n11 +  private isInitialized = false;\n12 +\n13 +  constructor() {\n14 +    this.observer = new ResizeObserver(this.handleResize.bind(this));\n15 +    this.isInitialized = true;\n16 +  }\n17 +\n18 +  private handleResize(entries: ResizeObserverEntry[]): void {\n19 +    for (const entry of entries) {\n20 +      const callback = this.observedElements.get(entry.target);\n21 +      if (callback) {\n22 +        try {\n23 +          callback(entry);\n24 +        } catch (error) {\n25 +          console.error('Resize callback error:', error);\n26 +        }\n27 +      }\n28 +    }\n29 +  }\n30 +\n31 +  observe(element: Element, callback: ResizeCallback): void {\n32 +    if (!this.isInitialized) {\n33 +      throw new Error('ResizeObserverManager not initialized');\n34 +    }\n35 +\n36 +    if (this.observedElements.has(element)) {\n37 +      console.warn('Element already being observed, updating callback');\n38 +    }\n39 +\n40 +    this.observedElements.set(element, callback);\n41 +    this.observer.observe(element);\n42 +  }\n43 +\n44 +  unobserve(element: Element): void {\n45 +    this.observer.unobserve(element);\n46 +    this.observedElements.delete(element);\n47 +  }\n48 +\n49 +  disconnect(): void {\n50 +    this.observer.disconnect();\n51 +    this.observedElements.clear();\n52 +  }\n53 +\n54 +  isObserving(element: Element): boolean {\n55 +    return this.observedElements.has(element);\n56 +  }\n57 +}\n58 +\n59 +export function useResizeObserver(\n60 +  elementRef: { current: Element | null },\n61 +  callback: ResizeCallback\n62 +): void {\n63 +  const manager = getGlobalManager();\n64 +\n65 +  if (elementRef.current) {\n66 +    manager.observe(elementRef.current, callback);\n67 +  }\n68 +\n69 +  return () => {\n70 +    if (elementRef.current) {\n71 +      manager.unobserve(elementRef.current);\n72 +    }\n73 +  };\n74 +}\n75 +\n76 +let globalManager: ResizeObserverManager | null = null;\n77 +\n78 +function getGlobalManager(): ResizeObserverManager {\n79 +  if (!globalManager) {\n80 +    globalManager = new ResizeObserverManager();\n81 +  }\n82 +  return globalManager;\n83 +}\n84 +\n85 +export class ElementResizeWatcher {\n86 +  private cleanup: (() => void) | null = null;\n87 +\n88 +  watch(element: Element, onResize: ResizeCallback): void {\n89 +    const manager = getGlobalManager();\n90 +    manager.observe(element, onResize);\n91 +\n92 +    this.cleanup = () => {\n93 +      manager.unobserve(element);\n94 +    };\n95 +\n96 +    window.addEventListener('beforeunload', this.cleanup.bind(this));\n97 +  }\n98 +\n99 +  unwatch(): void {\n100 +    if (this.cleanup) {\n101 +      this.cleanup();\n102 +      this.cleanup = null;\n103 +    }\n104 +  }\n105 +\n106 +  destroy(): void {\n107 +    this.unwatch();\n108 +    window.removeEventListener('beforeunload', this.cleanup?.bind(this) as EventListener);\n109 +  }\n110 +}\n111 +\n112 +export default ResizeObserverManager;\n113 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/dom/src/observers/ResizeObserverManager.ts\",\"relevantLinesStart\":89,\"relevantLinesEnd\":100}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"window.addEventListener('beforeunload', this.cleanup.bind(this));\\n  }\\n\\n  unwatch(): void {\\n    if (this.cleanup) {\\n      this.cleanup();\\n      this.cleanup = null;\\n    }\\n  }\\n\\n  destroy(): void {\\n    this.unwatch();\\n    window.removeEventListener('beforeunload', this.cleanup?.bind(this) as EventListener);\\n  }\",\n    \"improvedCode\": \"private boundCleanup: (() => void) | null = null;\\n\\n  watch(element: Element, onResize: ResizeCallback): void {\\n    // ... existing code ...\\n    this.boundCleanup = this.cleanup.bind(this);\\n    window.addEventListener('beforeunload', this.boundCleanup);\\n  }\\n\\n  destroy(): void {\\n    this.unwatch();\\n    if (this.boundCleanup) {\\n      window.removeEventListener('beforeunload', this.boundCleanup);\\n      this.boundCleanup = null;\\n    }\\n  }\",\n    \"relevantFile\": \"packages/dom/src/observers/ResizeObserverManager.ts\",\n    \"relevantLinesEnd\": 100,\n    \"suggestionContent\": \"In the `destroy` method, `removeEventListener` is called with `this.cleanup?.bind(this)` which creates a new function reference. Since `bind()` always creates a new function, this will never match the function added in `watch()` (which used a different `.bind(this)` call). The event listener will never be removed, causing a memory leak. Store the bound function reference and use the same reference for both `addEventListener` and `removeEventListener`.\",\n    \"oneSentenceSummary\": \"bind() creates new function reference - removeEventListener never matches addEventListener\",\n    \"relevantLinesStart\": 89\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 18: packages/ui/src/components/InfiniteScroll.tsx",
    "vars": {
      "fileContent": "import React, { useEffect, useRef, useState, useCallback } from 'react';\n\ninterface InfiniteScrollProps {\n  onLoadMore: () => Promise<void>;\n  hasMore: boolean;\n  threshold?: number;\n  children: React.ReactNode;\n  loader?: React.ReactNode;\n}\n\ninterface ScrollState {\n  isLoading: boolean;\n  error: Error | null;\n  page: number;\n}\n\nexport function InfiniteScroll({\n  onLoadMore,\n  hasMore,\n  threshold = 200,\n  children,\n  loader = <div className=\"loading\">Loading...</div>,\n}: InfiniteScrollProps) {\n  const [state, setState] = useState<ScrollState>({\n    isLoading: false,\n    error: null,\n    page: 1,\n  });\n\n  const containerRef = useRef<HTMLDivElement>(null);\n  const loadingRef = useRef(false);\n\n  const handleScroll = useCallback(() => {\n    const container = containerRef.current;\n    if (!container || loadingRef.current || !hasMore) return;\n\n    const { scrollTop, scrollHeight, clientHeight } = container;\n    const distanceFromBottom = scrollHeight - scrollTop - clientHeight;\n\n    if (distanceFromBottom < threshold) {\n      loadingRef.current = true;\n      setState(prev => ({ ...prev, isLoading: true }));\n\n      onLoadMore()\n        .then(() => {\n          setState(prev => ({\n            ...prev,\n            isLoading: false,\n            page: prev.page + 1,\n          }));\n        })\n        .catch((error) => {\n          setState(prev => ({\n            ...prev,\n            isLoading: false,\n            error,\n          }));\n        })\n        .finally(() => {\n          loadingRef.current = false;\n        });\n    }\n  }, [threshold, onLoadMore]);\n\n  useEffect(() => {\n    const container = containerRef.current;\n    if (!container) return;\n\n    container.addEventListener('scroll', handleScroll);\n    return () => container.removeEventListener('scroll', handleScroll);\n  }, [handleScroll]);\n\n  useEffect(() => {\n    handleScroll();\n  }, []);\n\n  return (\n    <div\n      ref={containerRef}\n      className=\"infinite-scroll-container\"\n      style={ { overflow: 'auto', height: '100%' } }\n    >\n      {children}\n      {state.isLoading && loader}\n      {state.error && (\n        <div className=\"error\">\n          Failed to load: {state.error.message}\n        </div>\n      )}\n    </div>\n  );\n}\n\nexport default InfiniteScroll;\n",
      "patchWithLinesStr": "## file: 'packages/ui/src/components/InfiniteScroll.tsx'\n\n@@ -0,0 +1,95 @@\n__new hunk__\n1 +import React, { useEffect, useRef, useState, useCallback } from 'react';\n2 +\n3 +interface InfiniteScrollProps {\n4 +  onLoadMore: () => Promise<void>;\n5 +  hasMore: boolean;\n6 +  threshold?: number;\n7 +  children: React.ReactNode;\n8 +  loader?: React.ReactNode;\n9 +}\n10 +\n11 +interface ScrollState {\n12 +  isLoading: boolean;\n13 +  error: Error | null;\n14 +  page: number;\n15 +}\n16 +\n17 +export function InfiniteScroll({\n18 +  onLoadMore,\n19 +  hasMore,\n20 +  threshold = 200,\n21 +  children,\n22 +  loader = <div className=\"loading\">Loading...</div>,\n23 +}: InfiniteScrollProps) {\n24 +  const [state, setState] = useState<ScrollState>({\n25 +    isLoading: false,\n26 +    error: null,\n27 +    page: 1,\n28 +  });\n29 +\n30 +  const containerRef = useRef<HTMLDivElement>(null);\n31 +  const loadingRef = useRef(false);\n32 +\n33 +  const handleScroll = useCallback(() => {\n34 +    const container = containerRef.current;\n35 +    if (!container || loadingRef.current || !hasMore) return;\n36 +\n37 +    const { scrollTop, scrollHeight, clientHeight } = container;\n38 +    const distanceFromBottom = scrollHeight - scrollTop - clientHeight;\n39 +\n40 +    if (distanceFromBottom < threshold) {\n41 +      loadingRef.current = true;\n42 +      setState(prev => ({ ...prev, isLoading: true }));\n43 +\n44 +      onLoadMore()\n45 +        .then(() => {\n46 +          setState(prev => ({\n47 +            ...prev,\n48 +            isLoading: false,\n49 +            page: prev.page + 1,\n50 +          }));\n51 +        })\n52 +        .catch((error) => {\n53 +          setState(prev => ({\n54 +            ...prev,\n55 +            isLoading: false,\n56 +            error,\n57 +          }));\n58 +        })\n59 +        .finally(() => {\n60 +          loadingRef.current = false;\n61 +        });\n62 +    }\n63 +  }, [threshold, onLoadMore]);\n64 +\n65 +  useEffect(() => {\n66 +    const container = containerRef.current;\n67 +    if (!container) return;\n68 +\n69 +    container.addEventListener('scroll', handleScroll);\n70 +    return () => container.removeEventListener('scroll', handleScroll);\n71 +  }, [handleScroll]);\n72 +\n73 +  useEffect(() => {\n74 +    handleScroll();\n75 +  }, []);\n76 +\n77 +  return (\n78 +    <div\n79 +      ref={containerRef}\n80 +      className=\"infinite-scroll-container\"\n81 +      style={ { overflow: 'auto', height: '100%' } }\n82 +    >\n83 +      {children}\n84 +      {state.isLoading && loader}\n85 +      {state.error && (\n86 +        <div className=\"error\">\n87 +          Failed to load: {state.error.message}\n88 +        </div>\n89 +      )}\n90 +    </div>\n91 +  );\n92 +}\n93 +\n94 +export default InfiniteScroll;\n95 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/ui/src/components/InfiniteScroll.tsx\",\"relevantLinesStart\":31,\"relevantLinesEnd\":56}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"const handleScroll = useCallback(() => {\\n    const container = containerRef.current;\\n    if (!container || loadingRef.current || !hasMore) return;\",\n    \"improvedCode\": \"const handleScroll = useCallback(() => {\\n    const container = containerRef.current;\\n    if (!container || loadingRef.current || !hasMore) return;\",\n    \"relevantFile\": \"packages/ui/src/components/InfiniteScroll.tsx\",\n    \"relevantLinesEnd\": 56,\n    \"suggestionContent\": \"The `handleScroll` callback has `hasMore` in its closure but `hasMore` is not included in the dependency array. When `hasMore` changes to `false`, the callback still uses the stale `true` value, causing unnecessary load attempts. Additionally, the initial scroll check in useEffect on line 68 has an empty dependency array but calls `handleScroll` which may not be the latest version.\",\n    \"oneSentenceSummary\": \"useCallback missing hasMore dependency causes stale closure bug\",\n    \"relevantLinesStart\": 31\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 19: packages/upload/src/handlers/FileUploadHandler.ts",
    "vars": {
      "fileContent": "import * as path from 'path';\nimport * as fs from 'fs/promises';\nimport * as crypto from 'crypto';\n\nexport interface UploadConfig {\n  uploadDir: string;\n  maxFileSize: number;\n  allowedExtensions: string[];\n  allowedMimeTypes: string[];\n}\n\nexport interface UploadedFile {\n  originalName: string;\n  savedPath: string;\n  size: number;\n  mimeType: string;\n  hash: string;\n}\n\nexport interface FileMetadata {\n  name: string;\n  size: number;\n  type: string;\n}\n\nconst DEFAULT_CONFIG: UploadConfig = {\n  uploadDir: './uploads',\n  maxFileSize: 10 * 1024 * 1024, // 10MB\n  allowedExtensions: ['.jpg', '.jpeg', '.png', '.gif', '.pdf', '.doc', '.docx'],\n  allowedMimeTypes: [\n    'image/jpeg',\n    'image/png',\n    'image/gif',\n    'application/pdf',\n    'application/msword',\n    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n  ],\n};\n\nexport function getFileExtension(filename: string): string {\n  return path.extname(filename).toLowerCase();\n}\n\nexport function generateUniqueFilename(originalName: string): string {\n  const ext = getFileExtension(originalName);\n  const timestamp = Date.now();\n  const random = crypto.randomBytes(8).toString('hex');\n  return `${timestamp}_${random}${ext}`;\n}\n\nexport function sanitizeFilename(filename: string): string {\n  return filename\n    .replace(/[^a-zA-Z0-9._-]/g, '_')\n    .replace(/_{2,}/g, '_');\n}\n\nexport async function calculateFileHash(buffer: Buffer): Promise<string> {\n  return crypto.createHash('sha256').update(buffer).digest('hex');\n}\n\nexport class FileUploadHandler {\n  private config: UploadConfig;\n\n  constructor(config: Partial<UploadConfig> = {}) {\n    this.config = { ...DEFAULT_CONFIG, ...config };\n  }\n\n  async ensureUploadDir(): Promise<void> {\n    await fs.mkdir(this.config.uploadDir, { recursive: true });\n  }\n\n  validateExtension(filename: string): boolean {\n    const ext = getFileExtension(filename);\n    return this.config.allowedExtensions.includes(ext);\n  }\n\n  validateMimeType(mimeType: string): boolean {\n    return this.config.allowedMimeTypes.includes(mimeType);\n  }\n\n  validateFileSize(size: number): boolean {\n    return size <= this.config.maxFileSize;\n  }\n\n  async saveFile(\n    buffer: Buffer,\n    metadata: FileMetadata\n  ): Promise<UploadedFile> {\n    await this.ensureUploadDir();\n\n    if (!this.validateExtension(metadata.name)) {\n      throw new Error(`File extension not allowed: ${getFileExtension(metadata.name)}`);\n    }\n\n    if (!this.validateMimeType(metadata.type)) {\n      throw new Error(`MIME type not allowed: ${metadata.type}`);\n    }\n\n    if (!this.validateFileSize(metadata.size)) {\n      throw new Error(`File size exceeds limit: ${metadata.size} bytes`);\n    }\n\n    const sanitized = sanitizeFilename(metadata.name);\n    const filename = generateUniqueFilename(sanitized);\n    const filepath = path.join(this.config.uploadDir, filename);\n\n    await fs.writeFile(filepath, buffer);\n\n    const hash = await calculateFileHash(buffer);\n\n    return {\n      originalName: metadata.name,\n      savedPath: filepath,\n      size: buffer.length,\n      mimeType: metadata.type,\n      hash,\n    };\n  }\n\n  async deleteFile(filepath: string): Promise<void> {\n    const fullPath = path.join(this.config.uploadDir, filepath);\n    await fs.unlink(fullPath);\n  }\n\n  async getFile(filepath: string): Promise<Buffer> {\n    const fullPath = path.join(this.config.uploadDir, filepath);\n    return fs.readFile(fullPath);\n  }\n\n  async listFiles(): Promise<string[]> {\n    return fs.readdir(this.config.uploadDir);\n  }\n\n  getConfig(): UploadConfig {\n    return { ...this.config };\n  }\n}\n\nexport function createUploadHandler(config?: Partial<UploadConfig>): FileUploadHandler {\n  return new FileUploadHandler(config);\n}\n",
      "patchWithLinesStr": "## file: 'packages/upload/src/handlers/FileUploadHandler.ts'\n\n@@ -0,0 +1,142 @@\n__new hunk__\n1 +import * as path from 'path';\n2 +import * as fs from 'fs/promises';\n3 +import * as crypto from 'crypto';\n4 +\n5 +export interface UploadConfig {\n6 +  uploadDir: string;\n7 +  maxFileSize: number;\n8 +  allowedExtensions: string[];\n9 +  allowedMimeTypes: string[];\n10 +}\n11 +\n12 +export interface UploadedFile {\n13 +  originalName: string;\n14 +  savedPath: string;\n15 +  size: number;\n16 +  mimeType: string;\n17 +  hash: string;\n18 +}\n19 +\n20 +export interface FileMetadata {\n21 +  name: string;\n22 +  size: number;\n23 +  type: string;\n24 +}\n25 +\n26 +const DEFAULT_CONFIG: UploadConfig = {\n27 +  uploadDir: './uploads',\n28 +  maxFileSize: 10 * 1024 * 1024, // 10MB\n29 +  allowedExtensions: ['.jpg', '.jpeg', '.png', '.gif', '.pdf', '.doc', '.docx'],\n30 +  allowedMimeTypes: [\n31 +    'image/jpeg',\n32 +    'image/png',\n33 +    'image/gif',\n34 +    'application/pdf',\n35 +    'application/msword',\n36 +    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n37 +  ],\n38 +};\n39 +\n40 +export function getFileExtension(filename: string): string {\n41 +  return path.extname(filename).toLowerCase();\n42 +}\n43 +\n44 +export function generateUniqueFilename(originalName: string): string {\n45 +  const ext = getFileExtension(originalName);\n46 +  const timestamp = Date.now();\n47 +  const random = crypto.randomBytes(8).toString('hex');\n48 +  return `${timestamp}_${random}${ext}`;\n49 +}\n50 +\n51 +export function sanitizeFilename(filename: string): string {\n52 +  return filename\n53 +    .replace(/[^a-zA-Z0-9._-]/g, '_')\n54 +    .replace(/_{2,}/g, '_');\n55 +}\n56 +\n57 +export async function calculateFileHash(buffer: Buffer): Promise<string> {\n58 +  return crypto.createHash('sha256').update(buffer).digest('hex');\n59 +}\n60 +\n61 +export class FileUploadHandler {\n62 +  private config: UploadConfig;\n63 +\n64 +  constructor(config: Partial<UploadConfig> = {}) {\n65 +    this.config = { ...DEFAULT_CONFIG, ...config };\n66 +  }\n67 +\n68 +  async ensureUploadDir(): Promise<void> {\n69 +    await fs.mkdir(this.config.uploadDir, { recursive: true });\n70 +  }\n71 +\n72 +  validateExtension(filename: string): boolean {\n73 +    const ext = getFileExtension(filename);\n74 +    return this.config.allowedExtensions.includes(ext);\n75 +  }\n76 +\n77 +  validateMimeType(mimeType: string): boolean {\n78 +    return this.config.allowedMimeTypes.includes(mimeType);\n79 +  }\n80 +\n81 +  validateFileSize(size: number): boolean {\n82 +    return size <= this.config.maxFileSize;\n83 +  }\n84 +\n85 +  async saveFile(\n86 +    buffer: Buffer,\n87 +    metadata: FileMetadata\n88 +  ): Promise<UploadedFile> {\n89 +    await this.ensureUploadDir();\n90 +\n91 +    if (!this.validateExtension(metadata.name)) {\n92 +      throw new Error(`File extension not allowed: ${getFileExtension(metadata.name)}`);\n93 +    }\n94 +\n95 +    if (!this.validateMimeType(metadata.type)) {\n96 +      throw new Error(`MIME type not allowed: ${metadata.type}`);\n97 +    }\n98 +\n99 +    if (!this.validateFileSize(metadata.size)) {\n100 +      throw new Error(`File size exceeds limit: ${metadata.size} bytes`);\n101 +    }\n102 +\n103 +    const sanitized = sanitizeFilename(metadata.name);\n104 +    const filename = generateUniqueFilename(sanitized);\n105 +    const filepath = path.join(this.config.uploadDir, filename);\n106 +\n107 +    await fs.writeFile(filepath, buffer);\n108 +\n109 +    const hash = await calculateFileHash(buffer);\n110 +\n111 +    return {\n112 +      originalName: metadata.name,\n113 +      savedPath: filepath,\n114 +      size: buffer.length,\n115 +      mimeType: metadata.type,\n116 +      hash,\n117 +    };\n118 +  }\n119 +\n120 +  async deleteFile(filepath: string): Promise<void> {\n121 +    const fullPath = path.join(this.config.uploadDir, filepath);\n122 +    await fs.unlink(fullPath);\n123 +  }\n124 +\n125 +  async getFile(filepath: string): Promise<Buffer> {\n126 +    const fullPath = path.join(this.config.uploadDir, filepath);\n127 +    return fs.readFile(fullPath);\n128 +  }\n129 +\n130 +  async listFiles(): Promise<string[]> {\n131 +    return fs.readdir(this.config.uploadDir);\n132 +  }\n133 +\n134 +  getConfig(): UploadConfig {\n135 +    return { ...this.config };\n136 +  }\n137 +}\n138 +\n139 +export function createUploadHandler(config?: Partial<UploadConfig>): FileUploadHandler {\n140 +  return new FileUploadHandler(config);\n141 +}\n142 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/upload/src/handlers/FileUploadHandler.ts\",\"relevantLinesStart\":106,\"relevantLinesEnd\":114},{\"relevantFile\":\"packages/upload/src/handlers/FileUploadHandler.ts\",\"relevantLinesStart\":91,\"relevantLinesEnd\":93}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"async deleteFile(filepath: string): Promise<void> {\\n    const fullPath = path.join(this.config.uploadDir, filepath);\\n    await fs.unlink(fullPath);\\n  }\\n\\n  async getFile(filepath: string): Promise<Buffer> {\\n    const fullPath = path.join(this.config.uploadDir, filepath);\\n    return fs.readFile(fullPath);\\n  }\",\n    \"improvedCode\": \"async deleteFile(filepath: string): Promise<void> {\\n    const fullPath = path.resolve(this.config.uploadDir, filepath);\\n    const uploadDirResolved = path.resolve(this.config.uploadDir);\\n    if (!fullPath.startsWith(uploadDirResolved + path.sep)) {\\n      throw new Error('Invalid file path');\\n    }\\n    await fs.unlink(fullPath);\\n  }\\n\\n  async getFile(filepath: string): Promise<Buffer> {\\n    const fullPath = path.resolve(this.config.uploadDir, filepath);\\n    const uploadDirResolved = path.resolve(this.config.uploadDir);\\n    if (!fullPath.startsWith(uploadDirResolved + path.sep)) {\\n      throw new Error('Invalid file path');\\n    }\\n    return fs.readFile(fullPath);\\n  }\",\n    \"relevantFile\": \"packages/upload/src/handlers/FileUploadHandler.ts\",\n    \"relevantLinesEnd\": 114,\n    \"suggestionContent\": \"The `deleteFile` and `getFile` methods are vulnerable to path traversal attacks. An attacker can pass `../../../etc/passwd` as the filepath parameter. Using `path.join(uploadDir, filepath)` doesn't prevent escaping the upload directory. Need to validate that the resolved path is still within the upload directory.\",\n    \"oneSentenceSummary\": \"Path traversal vulnerability - can read/delete files outside upload directory\",\n    \"relevantLinesStart\": 106\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"if (!this.validateFileSize(metadata.size)) {\\n      throw new Error(`File size exceeds limit: ${metadata.size} bytes`);\\n    }\",\n    \"improvedCode\": \"if (!this.validateFileSize(buffer.length)) {\\n      throw new Error(`File size exceeds limit: ${buffer.length} bytes`);\\n    }\\n    \\n    if (buffer.length !== metadata.size) {\\n      throw new Error(`Size mismatch: claimed ${metadata.size}, actual ${buffer.length}`);\\n    }\",\n    \"relevantFile\": \"packages/upload/src/handlers/FileUploadHandler.ts\",\n    \"relevantLinesEnd\": 93,\n    \"suggestionContent\": \"The `saveFile` method validates `metadata.size` but then writes `buffer` without checking if `buffer.length` matches `metadata.size`. An attacker can claim a small file size in metadata while sending a large buffer, bypassing the size limit check.\",\n    \"oneSentenceSummary\": \"Size validation uses metadata instead of actual buffer length - bypass possible\",\n    \"relevantLinesStart\": 91\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 20: packages/forms/src/validators/FormValidator.ts",
    "vars": {
      "fileContent": "export interface FieldValidation {\n  field: string;\n  isValid: boolean;\n  errors: string[];\n}\n\nexport interface FormValidationResult {\n  isValid: boolean;\n  fields: FieldValidation[];\n  summary: string;\n}\n\nexport interface ValidationRule {\n  name: string;\n  message: string;\n  validate: (value: string, formData?: Record<string, string>) => boolean;\n}\n\nconst emailRegex = /^([a-zA-Z0-9_\\-\\.]+)@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.)|(([a-zA-Z0-9\\-]+\\.)+))([a-zA-Z]{2,}|[0-9]{1,3})(\\]?)$/;\nconst passwordRegex = /^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[!@#$%^&*])[A-Za-z\\d!@#$%^&*]{8,}$/;\nconst urlRegex = /^(https?:\\/\\/)?(([\\da-z\\.-]+)\\.([a-z\\.]{2,6})|localhost)([\\/\\w \\.-]*)*\\/?$/;\n\nexport const commonRules: Record<string, ValidationRule> = {\n  required: {\n    name: 'required',\n    message: 'This field is required',\n    validate: (value) => value.trim().length > 0,\n  },\n  email: {\n    name: 'email',\n    message: 'Please enter a valid email address',\n    validate: (value) => emailRegex.test(value),\n  },\n  password: {\n    name: 'password',\n    message: 'Password must be at least 8 characters with uppercase, lowercase, number and special character',\n    validate: (value) => passwordRegex.test(value),\n  },\n  url: {\n    name: 'url',\n    message: 'Please enter a valid URL',\n    validate: (value) => urlRegex.test(value),\n  },\n  maxLength: {\n    name: 'maxLength',\n    message: 'Value exceeds maximum length',\n    validate: (value) => value.length <= 255,\n  },\n};\n\nexport function createMinLengthRule(min: number): ValidationRule {\n  return {\n    name: `minLength_${min}`,\n    message: `Must be at least ${min} characters`,\n    validate: (value) => value.length >= min,\n  };\n}\n\nexport function createMatchRule(fieldName: string): ValidationRule {\n  return {\n    name: `match_${fieldName}`,\n    message: `Must match ${fieldName}`,\n    validate: (value, formData) => formData?.[fieldName] === value,\n  };\n}\n\nexport function createPatternRule(pattern: RegExp, message: string): ValidationRule {\n  return {\n    name: 'pattern',\n    message,\n    validate: (value) => pattern.test(value),\n  };\n}\n\nexport class FormValidator {\n  private rules: Map<string, ValidationRule[]> = new Map();\n  private customMessages: Map<string, string> = new Map();\n\n  addRule(field: string, rule: ValidationRule): this {\n    const existing = this.rules.get(field) || [];\n    existing.push(rule);\n    this.rules.set(field, existing);\n    return this;\n  }\n\n  addRules(field: string, rules: ValidationRule[]): this {\n    rules.forEach(rule => this.addRule(field, rule));\n    return this;\n  }\n\n  setCustomMessage(field: string, message: string): this {\n    this.customMessages.set(field, message);\n    return this;\n  }\n\n  validateField(field: string, value: string, formData?: Record<string, string>): FieldValidation {\n    const rules = this.rules.get(field) || [];\n    const errors: string[] = [];\n\n    for (const rule of rules) {\n      if (!rule.validate(value, formData)) {\n        const customMessage = this.customMessages.get(`${field}_${rule.name}`);\n        errors.push(customMessage || rule.message);\n      }\n    }\n\n    return {\n      field,\n      isValid: errors.length === 0,\n      errors,\n    };\n  }\n\n  validate(formData: Record<string, string>): FormValidationResult {\n    const fields: FieldValidation[] = [];\n    let allValid = true;\n\n    for (const [field, _] of this.rules) {\n      const value = formData[field] || '';\n      const validation = this.validateField(field, value, formData);\n      fields.push(validation);\n\n      if (!validation.isValid) {\n        allValid = false;\n      }\n    }\n\n    return {\n      isValid: allValid,\n      fields,\n      summary: allValid\n        ? 'All fields are valid'\n        : `Found errors in: ${fields.filter(f => !f.isValid).map(f => f.field).join(', ')}`,\n    };\n  }\n\n  getErrorSummaryHtml(result: FormValidationResult): string {\n    if (result.isValid) {\n      return '<div class=\"success\">Form is valid!</div>';\n    }\n\n    const errorItems = result.fields\n      .filter(f => !f.isValid)\n      .map(f => `<li><strong>${f.field}:</strong> ${f.errors.join(', ')}</li>`)\n      .join('');\n\n    return `<div class=\"error-summary\"><ul>${errorItems}</ul></div>`;\n  }\n\n  comparePasswords(password: string, storedHash: string): boolean {\n    if (password.length !== storedHash.length) {\n      return false;\n    }\n\n    let result = true;\n    for (let i = 0; i < password.length; i++) {\n      if (password[i] !== storedHash[i]) {\n        result = false;\n      }\n    }\n    return result;\n  }\n\n  reset(): void {\n    this.rules.clear();\n    this.customMessages.clear();\n  }\n}\n\nexport function validateEmail(email: string): boolean {\n  return emailRegex.test(email);\n}\n\nexport function validatePassword(password: string): boolean {\n  return passwordRegex.test(password);\n}\n\nexport default FormValidator;\n",
      "patchWithLinesStr": "## file: 'packages/forms/src/validators/FormValidator.ts'\n\n@@ -0,0 +1,179 @@\n__new hunk__\n1 +export interface FieldValidation {\n2 +  field: string;\n3 +  isValid: boolean;\n4 +  errors: string[];\n5 +}\n6 +\n7 +export interface FormValidationResult {\n8 +  isValid: boolean;\n9 +  fields: FieldValidation[];\n10 +  summary: string;\n11 +}\n12 +\n13 +export interface ValidationRule {\n14 +  name: string;\n15 +  message: string;\n16 +  validate: (value: string, formData?: Record<string, string>) => boolean;\n17 +}\n18 +\n19 +const emailRegex = /^([a-zA-Z0-9_\\-\\.]+)@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.)|(([a-zA-Z0-9\\-]+\\.)+))([a-zA-Z]{2,}|[0-9]{1,3})(\\]?)$/;\n20 +const passwordRegex = /^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[!@#$%^&*])[A-Za-z\\d!@#$%^&*]{8,}$/;\n21 +const urlRegex = /^(https?:\\/\\/)?(([\\da-z\\.-]+)\\.([a-z\\.]{2,6})|localhost)([\\/\\w \\.-]*)*\\/?$/;\n22 +\n23 +export const commonRules: Record<string, ValidationRule> = {\n24 +  required: {\n25 +    name: 'required',\n26 +    message: 'This field is required',\n27 +    validate: (value) => value.trim().length > 0,\n28 +  },\n29 +  email: {\n30 +    name: 'email',\n31 +    message: 'Please enter a valid email address',\n32 +    validate: (value) => emailRegex.test(value),\n33 +  },\n34 +  password: {\n35 +    name: 'password',\n36 +    message: 'Password must be at least 8 characters with uppercase, lowercase, number and special character',\n37 +    validate: (value) => passwordRegex.test(value),\n38 +  },\n39 +  url: {\n40 +    name: 'url',\n41 +    message: 'Please enter a valid URL',\n42 +    validate: (value) => urlRegex.test(value),\n43 +  },\n44 +  maxLength: {\n45 +    name: 'maxLength',\n46 +    message: 'Value exceeds maximum length',\n47 +    validate: (value) => value.length <= 255,\n48 +  },\n49 +};\n50 +\n51 +export function createMinLengthRule(min: number): ValidationRule {\n52 +  return {\n53 +    name: `minLength_${min}`,\n54 +    message: `Must be at least ${min} characters`,\n55 +    validate: (value) => value.length >= min,\n56 +  };\n57 +}\n58 +\n59 +export function createMatchRule(fieldName: string): ValidationRule {\n60 +  return {\n61 +    name: `match_${fieldName}`,\n62 +    message: `Must match ${fieldName}`,\n63 +    validate: (value, formData) => formData?.[fieldName] === value,\n64 +  };\n65 +}\n66 +\n67 +export function createPatternRule(pattern: RegExp, message: string): ValidationRule {\n68 +  return {\n69 +    name: 'pattern',\n70 +    message,\n71 +    validate: (value) => pattern.test(value),\n72 +  };\n73 +}\n74 +\n75 +export class FormValidator {\n76 +  private rules: Map<string, ValidationRule[]> = new Map();\n77 +  private customMessages: Map<string, string> = new Map();\n78 +\n79 +  addRule(field: string, rule: ValidationRule): this {\n80 +    const existing = this.rules.get(field) || [];\n81 +    existing.push(rule);\n82 +    this.rules.set(field, existing);\n83 +    return this;\n84 +  }\n85 +\n86 +  addRules(field: string, rules: ValidationRule[]): this {\n87 +    rules.forEach(rule => this.addRule(field, rule));\n88 +    return this;\n89 +  }\n90 +\n91 +  setCustomMessage(field: string, message: string): this {\n92 +    this.customMessages.set(field, message);\n93 +    return this;\n94 +  }\n95 +\n96 +  validateField(field: string, value: string, formData?: Record<string, string>): FieldValidation {\n97 +    const rules = this.rules.get(field) || [];\n98 +    const errors: string[] = [];\n99 +\n100 +    for (const rule of rules) {\n101 +      if (!rule.validate(value, formData)) {\n102 +        const customMessage = this.customMessages.get(`${field}_${rule.name}`);\n103 +        errors.push(customMessage || rule.message);\n104 +      }\n105 +    }\n106 +\n107 +    return {\n108 +      field,\n109 +      isValid: errors.length === 0,\n110 +      errors,\n111 +    };\n112 +  }\n113 +\n114 +  validate(formData: Record<string, string>): FormValidationResult {\n115 +    const fields: FieldValidation[] = [];\n116 +    let allValid = true;\n117 +\n118 +    for (const [field, _] of this.rules) {\n119 +      const value = formData[field] || '';\n120 +      const validation = this.validateField(field, value, formData);\n121 +      fields.push(validation);\n122 +\n123 +      if (!validation.isValid) {\n124 +        allValid = false;\n125 +      }\n126 +    }\n127 +\n128 +    return {\n129 +      isValid: allValid,\n130 +      fields,\n131 +      summary: allValid\n132 +        ? 'All fields are valid'\n133 +        : `Found errors in: ${fields.filter(f => !f.isValid).map(f => f.field).join(', ')}`,\n134 +    };\n135 +  }\n136 +\n137 +  getErrorSummaryHtml(result: FormValidationResult): string {\n138 +    if (result.isValid) {\n139 +      return '<div class=\"success\">Form is valid!</div>';\n140 +    }\n141 +\n142 +    const errorItems = result.fields\n143 +      .filter(f => !f.isValid)\n144 +      .map(f => `<li><strong>${f.field}:</strong> ${f.errors.join(', ')}</li>`)\n145 +      .join('');\n146 +\n147 +    return `<div class=\"error-summary\"><ul>${errorItems}</ul></div>`;\n148 +  }\n149 +\n150 +  comparePasswords(password: string, storedHash: string): boolean {\n151 +    if (password.length !== storedHash.length) {\n152 +      return false;\n153 +    }\n154 +\n155 +    let result = true;\n156 +    for (let i = 0; i < password.length; i++) {\n157 +      if (password[i] !== storedHash[i]) {\n158 +        result = false;\n159 +      }\n160 +    }\n161 +    return result;\n162 +  }\n163 +\n164 +  reset(): void {\n165 +    this.rules.clear();\n166 +    this.customMessages.clear();\n167 +  }\n168 +}\n169 +\n170 +export function validateEmail(email: string): boolean {\n171 +  return emailRegex.test(email);\n172 +}\n173 +\n174 +export function validatePassword(password: string): boolean {\n175 +  return passwordRegex.test(password);\n176 +}\n177 +\n178 +export default FormValidator;\n179 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"packages/forms/src/validators/FormValidator.ts\",\"relevantLinesStart\":127,\"relevantLinesEnd\":130},{\"relevantFile\":\"packages/forms/src/validators/FormValidator.ts\",\"relevantLinesStart\":21,\"relevantLinesEnd\":21},{\"relevantFile\":\"packages/forms/src/validators/FormValidator.ts\",\"relevantLinesStart\":133,\"relevantLinesEnd\":145}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \".map(f => `<li><strong>${f.field}:</strong> ${f.errors.join(', ')}</li>`)\",\n    \"improvedCode\": \".map(f => `<li><strong>${escapeHtml(f.field)}:</strong> ${escapeHtml(f.errors.join(', '))}</li>`)\",\n    \"relevantFile\": \"packages/forms/src/validators/FormValidator.ts\",\n    \"relevantLinesEnd\": 130,\n    \"suggestionContent\": \"The `getErrorSummaryHtml` method directly interpolates field names and error messages into HTML without escaping. If an attacker can control field names or validation messages (e.g., through a malicious form configuration or i18n injection), they can inject arbitrary HTML/JavaScript, leading to XSS vulnerabilities.\",\n    \"oneSentenceSummary\": \"XSS vulnerability - field names and errors interpolated into HTML without escaping\",\n    \"relevantLinesStart\": 127\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"const urlRegex = /^(https?:\\\\/\\\\/)?(([\\\\da-z\\\\.-]+)\\\\.([a-z\\\\.]{2,6})|localhost)([\\\\/\\\\w \\\\.-]*)*\\\\/?$/;\",\n    \"improvedCode\": \"const urlRegex = /^(https?:\\\\/\\\\/)?([\\\\da-z\\\\.-]+\\\\.([a-z]{2,6})|localhost)(\\\\/[\\\\w\\\\.-]*)*\\\\/?$/;\",\n    \"relevantFile\": \"packages/forms/src/validators/FormValidator.ts\",\n    \"relevantLinesEnd\": 21,\n    \"suggestionContent\": \"The `urlRegex` pattern `([\\\\/\\\\w \\\\.-]*)*` contains nested quantifiers that can cause catastrophic backtracking (ReDoS). A malicious input like 'http://a.aa/' followed by many spaces can cause the regex engine to hang for an extremely long time, enabling denial-of-service attacks.\",\n    \"oneSentenceSummary\": \"ReDoS vulnerability - nested quantifiers in URL regex cause catastrophic backtracking\",\n    \"relevantLinesStart\": 21\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"TypeScript\",\n    \"existingCode\": \"comparePasswords(password: string, storedHash: string): boolean {\\n    if (password.length !== storedHash.length) {\\n      return false;\\n    }\\n\\n    let result = true;\\n    for (let i = 0; i < password.length; i++) {\\n      if (password[i] !== storedHash[i]) {\\n        result = false;\\n      }\\n    }\\n    return result;\\n  }\",\n    \"improvedCode\": \"comparePasswords(password: string, storedHash: string): boolean {\\n    const encoder = new TextEncoder();\\n    const a = encoder.encode(password);\\n    const b = encoder.encode(storedHash);\\n    if (a.length !== b.length) {\\n      // Still compare to maintain constant time\\n      crypto.subtle.timingSafeEqual?.(a, a);\\n      return false;\\n    }\\n    return crypto.subtle.timingSafeEqual?.(a, b) ?? false;\\n  }\",\n    \"relevantFile\": \"packages/forms/src/validators/FormValidator.ts\",\n    \"relevantLinesEnd\": 145,\n    \"suggestionContent\": \"The `comparePasswords` method attempts constant-time comparison but fails. The early return when lengths differ leaks length information. Also, even when lengths match, the JavaScript engine may optimize the loop and short-circuit when `result` becomes false. Use a proper constant-time comparison function like `crypto.timingSafeEqual`.\",\n    \"oneSentenceSummary\": \"Timing attack vulnerability - password comparison is not constant-time\",\n    \"relevantLinesStart\": 133\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 21: src/queue/async_queue.py",
    "vars": {
      "fileContent": "import asyncio\nfrom typing import TypeVar, Generic, Callable, Awaitable\nfrom dataclasses import dataclass\nfrom datetime import datetime\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\n\n@dataclass\nclass QueueItem(Generic[T]):\n    id: str\n    data: T\n    priority: int\n    created_at: datetime\n    attempts: int = 0\n\n\nclass AsyncQueue(Generic[T]):\n    def __init__(self, max_size: int = 1000):\n        self._queue: asyncio.Queue[QueueItem[T]] = asyncio.Queue(maxsize=max_size)\n        self._processing = False\n        self._handlers: list[Callable[[T], Awaitable[None]]] = []\n\n    def add_handler(self, handler: Callable[[T], Awaitable[None]]):\n        self._handlers.append(handler)\n\n    async def enqueue(self, item_id: str, data: T, priority: int = 0) -> bool:\n        try:\n            item = QueueItem(\n                id=item_id,\n                data=data,\n                priority=priority,\n                created_at=datetime.now()\n            )\n            await self._queue.put(item)\n            logger.debug(f\"Enqueued item {item_id}\")\n            return True\n        except asyncio.QueueFull:\n            logger.warning(f\"Queue full, dropping item {item_id}\")\n            return False\n\n    async def process_one(self) -> bool:\n        try:\n            item = await asyncio.wait_for(\n                self._queue.get(),\n                timeout=1.0\n            )\n\n            for handler in self._handlers:\n                handler(item.data)\n\n            self._queue.task_done()\n            return True\n\n        except asyncio.TimeoutError:\n            return False\n        except Exception as e:\n            logger.error(f\"Error processing item: {e}\")\n            return False\n\n    async def start_processing(self):\n        self._processing = True\n        while self._processing:\n            await self.process_one()\n\n    def stop_processing(self):\n        self._processing = False\n\n    def get_size(self) -> int:\n        return self._queue.qsize()\n\n\nclass BatchProcessor:\n    def __init__(self, batch_size: int = 10):\n        self.batch_size = batch_size\n        self._items: list = []\n\n    async def add_item(self, item):\n        self._items.append(item)\n        if len(self._items) >= self.batch_size:\n            await self.flush()\n\n    async def flush(self):\n        if not self._items:\n            return\n\n        batch = self._items\n        self._items = []\n\n        tasks = []\n        for item in batch:\n            task = asyncio.create_task(self._process_item(item))\n            tasks.append(task)\n\n        await asyncio.gather(tasks)\n\n    async def _process_item(self, item):\n        await asyncio.sleep(0.01)\n        logger.info(f\"Processed item: {item}\")\n\n\nasync def run_with_timeout(coro, timeout_seconds: float):\n    try:\n        return await asyncio.wait_for(coro, timeout=timeout_seconds)\n    except asyncio.TimeoutError:\n        logger.warning(\"Operation timed out\")\n        return None\n",
      "patchWithLinesStr": "## file: 'src/queue/async_queue.py'\n\n@@ -0,0 +1,111 @@\n__new hunk__\n1 +import asyncio\n2 +from typing import TypeVar, Generic, Callable, Awaitable\n3 +from dataclasses import dataclass\n4 +from datetime import datetime\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +T = TypeVar(\"T\")\n10 +\n11 +\n12 +@dataclass\n13 +class QueueItem(Generic[T]):\n14 +    id: str\n15 +    data: T\n16 +    priority: int\n17 +    created_at: datetime\n18 +    attempts: int = 0\n19 +\n20 +\n21 +class AsyncQueue(Generic[T]):\n22 +    def __init__(self, max_size: int = 1000):\n23 +        self._queue: asyncio.Queue[QueueItem[T]] = asyncio.Queue(maxsize=max_size)\n24 +        self._processing = False\n25 +        self._handlers: list[Callable[[T], Awaitable[None]]] = []\n26 +\n27 +    def add_handler(self, handler: Callable[[T], Awaitable[None]]):\n28 +        self._handlers.append(handler)\n29 +\n30 +    async def enqueue(self, item_id: str, data: T, priority: int = 0) -> bool:\n31 +        try:\n32 +            item = QueueItem(\n33 +                id=item_id,\n34 +                data=data,\n35 +                priority=priority,\n36 +                created_at=datetime.now()\n37 +            )\n38 +            await self._queue.put(item)\n39 +            logger.debug(f\"Enqueued item {item_id}\")\n40 +            return True\n41 +        except asyncio.QueueFull:\n42 +            logger.warning(f\"Queue full, dropping item {item_id}\")\n43 +            return False\n44 +\n45 +    async def process_one(self) -> bool:\n46 +        try:\n47 +            item = await asyncio.wait_for(\n48 +                self._queue.get(),\n49 +                timeout=1.0\n50 +            )\n51 +\n52 +            for handler in self._handlers:\n53 +                handler(item.data)\n54 +\n55 +            self._queue.task_done()\n56 +            return True\n57 +\n58 +        except asyncio.TimeoutError:\n59 +            return False\n60 +        except Exception as e:\n61 +            logger.error(f\"Error processing item: {e}\")\n62 +            return False\n63 +\n64 +    async def start_processing(self):\n65 +        self._processing = True\n66 +        while self._processing:\n67 +            await self.process_one()\n68 +\n69 +    def stop_processing(self):\n70 +        self._processing = False\n71 +\n72 +    def get_size(self) -> int:\n73 +        return self._queue.qsize()\n74 +\n75 +\n76 +class BatchProcessor:\n77 +    def __init__(self, batch_size: int = 10):\n78 +        self.batch_size = batch_size\n79 +        self._items: list = []\n80 +\n81 +    async def add_item(self, item):\n82 +        self._items.append(item)\n83 +        if len(self._items) >= self.batch_size:\n84 +            await self.flush()\n85 +\n86 +    async def flush(self):\n87 +        if not self._items:\n88 +            return\n89 +\n90 +        batch = self._items\n91 +        self._items = []\n92 +\n93 +        tasks = []\n94 +        for item in batch:\n95 +            task = asyncio.create_task(self._process_item(item))\n96 +            tasks.append(task)\n97 +\n98 +        await asyncio.gather(tasks)\n99 +\n100 +    async def _process_item(self, item):\n101 +        await asyncio.sleep(0.01)\n102 +        logger.info(f\"Processed item: {item}\")\n103 +\n104 +\n105 +async def run_with_timeout(coro, timeout_seconds: float):\n106 +    try:\n107 +        return await asyncio.wait_for(coro, timeout=timeout_seconds)\n108 +    except asyncio.TimeoutError:\n109 +        logger.warning(\"Operation timed out\")\n110 +        return None\n111 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/queue/async_queue.py\",\"relevantLinesStart\":50,\"relevantLinesEnd\":51},{\"relevantFile\":\"src/queue/async_queue.py\",\"relevantLinesStart\":90,\"relevantLinesEnd\":90}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"for handler in self._handlers:\\n                handler(item.data)\",\n    \"improvedCode\": \"for handler in self._handlers:\\n                await handler(item.data)\",\n    \"relevantFile\": \"src/queue/async_queue.py\",\n    \"relevantLinesEnd\": 51,\n    \"suggestionContent\": \"In `process_one`, the handler is called without `await`: `handler(item.data)`. Since handlers are typed as `Callable[[T], Awaitable[None]]`, they return coroutines that must be awaited. Without `await`, the coroutine is created but never executed, and Python will emit a 'coroutine was never awaited' warning.\",\n    \"oneSentenceSummary\": \"Missing await on async handler - coroutine created but never executed\",\n    \"relevantLinesStart\": 50\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"await asyncio.gather(tasks)\",\n    \"improvedCode\": \"await asyncio.gather(*tasks)\",\n    \"relevantFile\": \"src/queue/async_queue.py\",\n    \"relevantLinesEnd\": 90,\n    \"suggestionContent\": \"In `BatchProcessor.flush`, `asyncio.gather(tasks)` is called but `tasks` is a list, and gather expects individual awaitables as positional arguments. This should be `asyncio.gather(*tasks)` with unpacking. As written, it awaits a single-element tuple containing the list, which doesn't properly parallelize.\",\n    \"oneSentenceSummary\": \"Missing * unpacking in asyncio.gather - tasks not parallelized correctly\",\n    \"relevantLinesStart\": 90\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 22: src/tools/git_helper.py",
    "vars": {
      "fileContent": "import subprocess\nimport os\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass GitResult:\n    success: bool\n    output: str\n    error: str | None = None\n\n\nclass GitHelper:\n    def __init__(self, repo_path: str):\n        self.repo_path = Path(repo_path)\n        if not (self.repo_path / \".git\").exists():\n            raise ValueError(f\"Not a git repository: {repo_path}\")\n\n    def run_command(self, command: str) -> GitResult:\n        try:\n            result = subprocess.run(\n                command,\n                shell=True,\n                cwd=self.repo_path,\n                capture_output=True,\n                text=True\n            )\n            return GitResult(\n                success=result.returncode == 0,\n                output=result.stdout.strip(),\n                error=result.stderr.strip() if result.stderr else None\n            )\n        except Exception as e:\n            return GitResult(success=False, output=\"\", error=str(e))\n\n    def get_current_branch(self) -> str:\n        result = self.run_command(\"git branch --show-current\")\n        return result.output if result.success else \"unknown\"\n\n    def checkout(self, branch: str) -> GitResult:\n        return self.run_command(f\"git checkout {branch}\")\n\n    def create_branch(self, branch_name: str) -> GitResult:\n        return self.run_command(f\"git checkout -b {branch_name}\")\n\n    def commit(self, message: str) -> GitResult:\n        return self.run_command(f'git commit -m \"{message}\"')\n\n    def get_log(self, count: int = 10, author: str = None) -> GitResult:\n        cmd = f\"git log -n {count}\"\n        if author:\n            cmd += f' --author=\"{author}\"'\n        return self.run_command(cmd)\n\n    def diff(self, file_path: str = None) -> GitResult:\n        cmd = \"git diff\"\n        if file_path:\n            cmd += f\" -- {file_path}\"\n        return self.run_command(cmd)\n\n    def add_files(self, *files: str) -> GitResult:\n        files_str = \" \".join(files)\n        return self.run_command(f\"git add {files_str}\")\n\n    def get_status(self) -> GitResult:\n        return self.run_command(\"git status --porcelain\")\n\n\ndef clone_repository(url: str, destination: str) -> GitResult:\n    try:\n        result = subprocess.run(\n            f\"git clone {url} {destination}\",\n            shell=True,\n            capture_output=True,\n            text=True\n        )\n        return GitResult(\n            success=result.returncode == 0,\n            output=result.stdout.strip(),\n            error=result.stderr.strip() if result.stderr else None\n        )\n    except Exception as e:\n        return GitResult(success=False, output=\"\", error=str(e))\n",
      "patchWithLinesStr": "## file: 'src/tools/git_helper.py'\n\n@@ -0,0 +1,89 @@\n__new hunk__\n1 +import subprocess\n2 +import os\n3 +from pathlib import Path\n4 +from dataclasses import dataclass\n5 +from typing import Optional\n6 +import logging\n7 +\n8 +logger = logging.getLogger(__name__)\n9 +\n10 +\n11 +@dataclass\n12 +class GitResult:\n13 +    success: bool\n14 +    output: str\n15 +    error: str | None = None\n16 +\n17 +\n18 +class GitHelper:\n19 +    def __init__(self, repo_path: str):\n20 +        self.repo_path = Path(repo_path)\n21 +        if not (self.repo_path / \".git\").exists():\n22 +            raise ValueError(f\"Not a git repository: {repo_path}\")\n23 +\n24 +    def run_command(self, command: str) -> GitResult:\n25 +        try:\n26 +            result = subprocess.run(\n27 +                command,\n28 +                shell=True,\n29 +                cwd=self.repo_path,\n30 +                capture_output=True,\n31 +                text=True\n32 +            )\n33 +            return GitResult(\n34 +                success=result.returncode == 0,\n35 +                output=result.stdout.strip(),\n36 +                error=result.stderr.strip() if result.stderr else None\n37 +            )\n38 +        except Exception as e:\n39 +            return GitResult(success=False, output=\"\", error=str(e))\n40 +\n41 +    def get_current_branch(self) -> str:\n42 +        result = self.run_command(\"git branch --show-current\")\n43 +        return result.output if result.success else \"unknown\"\n44 +\n45 +    def checkout(self, branch: str) -> GitResult:\n46 +        return self.run_command(f\"git checkout {branch}\")\n47 +\n48 +    def create_branch(self, branch_name: str) -> GitResult:\n49 +        return self.run_command(f\"git checkout -b {branch_name}\")\n50 +\n51 +    def commit(self, message: str) -> GitResult:\n52 +        return self.run_command(f'git commit -m \"{message}\"')\n53 +\n54 +    def get_log(self, count: int = 10, author: str = None) -> GitResult:\n55 +        cmd = f\"git log -n {count}\"\n56 +        if author:\n57 +            cmd += f' --author=\"{author}\"'\n58 +        return self.run_command(cmd)\n59 +\n60 +    def diff(self, file_path: str = None) -> GitResult:\n61 +        cmd = \"git diff\"\n62 +        if file_path:\n63 +            cmd += f\" -- {file_path}\"\n64 +        return self.run_command(cmd)\n65 +\n66 +    def add_files(self, *files: str) -> GitResult:\n67 +        files_str = \" \".join(files)\n68 +        return self.run_command(f\"git add {files_str}\")\n69 +\n70 +    def get_status(self) -> GitResult:\n71 +        return self.run_command(\"git status --porcelain\")\n72 +\n73 +\n74 +def clone_repository(url: str, destination: str) -> GitResult:\n75 +    try:\n76 +        result = subprocess.run(\n77 +            f\"git clone {url} {destination}\",\n78 +            shell=True,\n79 +            capture_output=True,\n80 +            text=True\n81 +        )\n82 +        return GitResult(\n83 +            success=result.returncode == 0,\n84 +            output=result.stdout.strip(),\n85 +            error=result.stderr.strip() if result.stderr else None\n86 +        )\n87 +    except Exception as e:\n88 +        return GitResult(success=False, output=\"\", error=str(e))\n89 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/tools/git_helper.py\",\"relevantLinesStart\":45,\"relevantLinesEnd\":46},{\"relevantFile\":\"src/tools/git_helper.py\",\"relevantLinesStart\":51,\"relevantLinesEnd\":52}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def checkout(self, branch: str) -> GitResult:\\n        return self.run_command(f\\\"git checkout {branch}\\\")\",\n    \"improvedCode\": \"def checkout(self, branch: str) -> GitResult:\\n        return self.run_command_safe([\\\"git\\\", \\\"checkout\\\", branch])\\n\\n    def run_command_safe(self, args: list[str]) -> GitResult:\\n        result = subprocess.run(args, cwd=self.repo_path, capture_output=True, text=True)\\n        return GitResult(success=result.returncode == 0, output=result.stdout.strip())\",\n    \"relevantFile\": \"src/tools/git_helper.py\",\n    \"relevantLinesEnd\": 46,\n    \"suggestionContent\": \"Multiple methods pass user input directly to shell commands via `shell=True`. For example, `checkout` passes `branch` directly to the command. An attacker can inject commands like `main; rm -rf /` as the branch name. Use `subprocess.run` with a list of arguments instead of shell=True.\",\n    \"oneSentenceSummary\": \"Command injection via shell=True - user input in branch/file names executes arbitrary commands\",\n    \"relevantLinesStart\": 45\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def commit(self, message: str) -> GitResult:\\n        return self.run_command(f'git commit -m \\\"{message}\\\"')\",\n    \"improvedCode\": \"def commit(self, message: str) -> GitResult:\\n        result = subprocess.run(\\n            [\\\"git\\\", \\\"commit\\\", \\\"-m\\\", message],\\n            cwd=self.repo_path,\\n            capture_output=True,\\n            text=True\\n        )\\n        return GitResult(success=result.returncode == 0, output=result.stdout.strip())\",\n    \"relevantFile\": \"src/tools/git_helper.py\",\n    \"relevantLinesEnd\": 52,\n    \"suggestionContent\": \"The `commit` method is especially dangerous as it passes the message in quotes, but those quotes can be escaped. Input like `test\\\"; rm -rf / #` breaks out of the quotes and executes arbitrary commands.\",\n    \"oneSentenceSummary\": \"Command injection in commit message - quotes can be escaped to run arbitrary commands\",\n    \"relevantLinesStart\": 51\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 23: src/storage/file_storage.py",
    "vars": {
      "fileContent": "import os\nimport shutil\nfrom pathlib import Path\nfrom typing import BinaryIO\nfrom datetime import datetime\nimport hashlib\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass FileStorage:\n    def __init__(self, base_path: str):\n        self.base_path = Path(base_path)\n        self.base_path.mkdir(parents=True, exist_ok=True)\n\n    def save_file(self, filename: str, content: bytes) -> str:\n        filepath = self.base_path / filename\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n\n        with open(filepath, \"wb\") as f:\n            f.write(content)\n\n        logger.info(f\"Saved file: {filepath}\")\n        return str(filepath)\n\n    def read_file(self, filename: str) -> bytes:\n        filepath = self.base_path / filename\n\n        if not filepath.exists():\n            raise FileNotFoundError(f\"File not found: {filename}\")\n\n        with open(filepath, \"rb\") as f:\n            return f.read()\n\n    def delete_file(self, filename: str) -> bool:\n        filepath = self.base_path / filename\n\n        if filepath.exists():\n            filepath.unlink()\n            logger.info(f\"Deleted file: {filepath}\")\n            return True\n        return False\n\n    def list_files(self, directory: str = \"\") -> list[str]:\n        search_path = self.base_path / directory\n\n        if not search_path.exists():\n            return []\n\n        return [\n            str(p.relative_to(self.base_path))\n            for p in search_path.rglob(\"*\")\n            if p.is_file()\n        ]\n\n    def get_file_info(self, filename: str) -> dict:\n        filepath = self.base_path / filename\n\n        if not filepath.exists():\n            raise FileNotFoundError(f\"File not found: {filename}\")\n\n        stat = filepath.stat()\n        return {\n            \"name\": filepath.name,\n            \"size\": stat.st_size,\n            \"created\": datetime.fromtimestamp(stat.st_ctime).isoformat(),\n            \"modified\": datetime.fromtimestamp(stat.st_mtime).isoformat(),\n        }\n\n    def copy_file(self, source: str, destination: str) -> str:\n        src_path = self.base_path / source\n        dst_path = self.base_path / destination\n\n        if not src_path.exists():\n            raise FileNotFoundError(f\"Source file not found: {source}\")\n\n        dst_path.parent.mkdir(parents=True, exist_ok=True)\n        shutil.copy2(src_path, dst_path)\n\n        return str(dst_path)\n\n    def move_file(self, source: str, destination: str) -> str:\n        src_path = self.base_path / source\n        dst_path = self.base_path / destination\n\n        if not src_path.exists():\n            raise FileNotFoundError(f\"Source file not found: {source}\")\n\n        dst_path.parent.mkdir(parents=True, exist_ok=True)\n        shutil.move(str(src_path), str(dst_path))\n\n        return str(dst_path)\n\n    def get_file_hash(self, filename: str, algorithm: str = \"sha256\") -> str:\n        filepath = self.base_path / filename\n\n        if not filepath.exists():\n            raise FileNotFoundError(f\"File not found: {filename}\")\n\n        hasher = hashlib.new(algorithm)\n        with open(filepath, \"rb\") as f:\n            for chunk in iter(lambda: f.read(8192), b\"\"):\n                hasher.update(chunk)\n\n        return hasher.hexdigest()\n\n\ndef sanitize_filename(filename: str) -> str:\n    return filename.replace(\"..\", \"\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
      "patchWithLinesStr": "## file: 'src/storage/file_storage.py'\n\n@@ -0,0 +1,111 @@\n__new hunk__\n1 +import os\n2 +import shutil\n3 +from pathlib import Path\n4 +from typing import BinaryIO\n5 +from datetime import datetime\n6 +import hashlib\n7 +import logging\n8 +\n9 +logger = logging.getLogger(__name__)\n10 +\n11 +\n12 +class FileStorage:\n13 +    def __init__(self, base_path: str):\n14 +        self.base_path = Path(base_path)\n15 +        self.base_path.mkdir(parents=True, exist_ok=True)\n16 +\n17 +    def save_file(self, filename: str, content: bytes) -> str:\n18 +        filepath = self.base_path / filename\n19 +        filepath.parent.mkdir(parents=True, exist_ok=True)\n20 +\n21 +        with open(filepath, \"wb\") as f:\n22 +            f.write(content)\n23 +\n24 +        logger.info(f\"Saved file: {filepath}\")\n25 +        return str(filepath)\n26 +\n27 +    def read_file(self, filename: str) -> bytes:\n28 +        filepath = self.base_path / filename\n29 +\n30 +        if not filepath.exists():\n31 +            raise FileNotFoundError(f\"File not found: {filename}\")\n32 +\n33 +        with open(filepath, \"rb\") as f:\n34 +            return f.read()\n35 +\n36 +    def delete_file(self, filename: str) -> bool:\n37 +        filepath = self.base_path / filename\n38 +\n39 +        if filepath.exists():\n40 +            filepath.unlink()\n41 +            logger.info(f\"Deleted file: {filepath}\")\n42 +            return True\n43 +        return False\n44 +\n45 +    def list_files(self, directory: str = \"\") -> list[str]:\n46 +        search_path = self.base_path / directory\n47 +\n48 +        if not search_path.exists():\n49 +            return []\n50 +\n51 +        return [\n52 +            str(p.relative_to(self.base_path))\n53 +            for p in search_path.rglob(\"*\")\n54 +            if p.is_file()\n55 +        ]\n56 +\n57 +    def get_file_info(self, filename: str) -> dict:\n58 +        filepath = self.base_path / filename\n59 +\n60 +        if not filepath.exists():\n61 +            raise FileNotFoundError(f\"File not found: {filename}\")\n62 +\n63 +        stat = filepath.stat()\n64 +        return {\n65 +            \"name\": filepath.name,\n66 +            \"size\": stat.st_size,\n67 +            \"created\": datetime.fromtimestamp(stat.st_ctime).isoformat(),\n68 +            \"modified\": datetime.fromtimestamp(stat.st_mtime).isoformat(),\n69 +        }\n70 +\n71 +    def copy_file(self, source: str, destination: str) -> str:\n72 +        src_path = self.base_path / source\n73 +        dst_path = self.base_path / destination\n74 +\n75 +        if not src_path.exists():\n76 +            raise FileNotFoundError(f\"Source file not found: {source}\")\n77 +\n78 +        dst_path.parent.mkdir(parents=True, exist_ok=True)\n79 +        shutil.copy2(src_path, dst_path)\n80 +\n81 +        return str(dst_path)\n82 +\n83 +    def move_file(self, source: str, destination: str) -> str:\n84 +        src_path = self.base_path / source\n85 +        dst_path = self.base_path / destination\n86 +\n87 +        if not src_path.exists():\n88 +            raise FileNotFoundError(f\"Source file not found: {source}\")\n89 +\n90 +        dst_path.parent.mkdir(parents=True, exist_ok=True)\n91 +        shutil.move(str(src_path), str(dst_path))\n92 +\n93 +        return str(dst_path)\n94 +\n95 +    def get_file_hash(self, filename: str, algorithm: str = \"sha256\") -> str:\n96 +        filepath = self.base_path / filename\n97 +\n98 +        if not filepath.exists():\n99 +            raise FileNotFoundError(f\"File not found: {filename}\")\n100 +\n101 +        hasher = hashlib.new(algorithm)\n102 +        with open(filepath, \"rb\") as f:\n103 +            for chunk in iter(lambda: f.read(8192), b\"\"):\n104 +                hasher.update(chunk)\n105 +\n106 +        return hasher.hexdigest()\n107 +\n108 +\n109 +def sanitize_filename(filename: str) -> str:\n110 +    return filename.replace(\"..\", \"\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n111 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/storage/file_storage.py\",\"relevantLinesStart\":26,\"relevantLinesEnd\":30},{\"relevantFile\":\"src/storage/file_storage.py\",\"relevantLinesStart\":103,\"relevantLinesEnd\":104}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def read_file(self, filename: str) -> bytes:\\n        filepath = self.base_path / filename\\n\\n        if not filepath.exists():\\n            raise FileNotFoundError(f\\\"File not found: {filename}\\\")\",\n    \"improvedCode\": \"def read_file(self, filename: str) -> bytes:\\n        filepath = (self.base_path / filename).resolve()\\n\\n        if not filepath.is_relative_to(self.base_path.resolve()):\\n            raise ValueError(\\\"Invalid file path\\\")\\n\\n        if not filepath.exists():\\n            raise FileNotFoundError(f\\\"File not found: {filename}\\\")\",\n    \"relevantFile\": \"src/storage/file_storage.py\",\n    \"relevantLinesEnd\": 30,\n    \"suggestionContent\": \"All file operations (`save_file`, `read_file`, `delete_file`, etc.) are vulnerable to path traversal attacks. An attacker can pass `../../../etc/passwd` as filename to access files outside the base directory. Using `Path(base_path) / filename` doesn't prevent `..` sequences. Need to resolve the path and verify it's still under base_path.\",\n    \"oneSentenceSummary\": \"Path traversal vulnerability allows reading files outside storage directory\",\n    \"relevantLinesStart\": 26\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def sanitize_filename(filename: str) -> str:\\n    return filename.replace(\\\"..\\\", \\\"\\\").replace(\\\"/\\\", \\\"_\\\").replace(\\\"\\\\\\\\\\\\\\\\\\\", \\\"_\\\")\",\n    \"improvedCode\": \"def sanitize_filename(filename: str) -> str:\\n    # Remove any path components, keep only the final filename\\n    from pathlib import PurePath\\n    return PurePath(filename).name\",\n    \"relevantFile\": \"src/storage/file_storage.py\",\n    \"relevantLinesEnd\": 104,\n    \"suggestionContent\": \"The `sanitize_filename` function is insufficient - it removes `..` but an attacker can use `....//` which becomes `../` after replacement. Also, it doesn't handle URL-encoded sequences like `%2e%2e%2f`. Path resolution and containment check is the proper solution.\",\n    \"oneSentenceSummary\": \"Sanitize function can be bypassed with ....// or URL-encoded sequences\",\n    \"relevantLinesStart\": 103\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 24: src/services/notification_service.py",
    "vars": {
      "fileContent": "from dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass Notification:\n    id: str\n    user_id: str\n    message: str\n    created_at: datetime\n    read: bool = False\n    metadata: dict = None\n\n\nclass NotificationService:\n    def __init__(self, max_notifications: int = 100):\n        self.max_notifications = max_notifications\n        self._notifications: dict[str, list[Notification]] = {}\n\n    def create_notification(\n        self,\n        user_id: str,\n        message: str,\n        metadata: dict = {}\n    ) -> Notification:\n        notification = Notification(\n            id=f\"notif_{datetime.now().timestamp()}\",\n            user_id=user_id,\n            message=message,\n            created_at=datetime.now(),\n            metadata=metadata\n        )\n\n        if user_id not in self._notifications:\n            self._notifications[user_id] = []\n\n        user_notifications = self._notifications[user_id]\n\n        if len(user_notifications) >= self.max_notifications:\n            user_notifications.pop(0)\n\n        user_notifications.append(notification)\n        logger.info(f\"Created notification for user {user_id}\")\n\n        return notification\n\n    def get_notifications(self, user_id: str) -> list[Notification]:\n        return self._notifications.get(user_id, [])\n\n    def mark_as_read(self, user_id: str, notification_id: str) -> bool:\n        notifications = self._notifications.get(user_id, [])\n        for notif in notifications:\n            if notif.id == notification_id:\n                notif.read = True\n                return True\n        return False\n\n    def get_unread_count(self, user_id: str) -> int:\n        notifications = self._notifications.get(user_id, [])\n        return sum(1 for n in notifications if not n.read)\n\n    def clear_notifications(self, user_id: str) -> int:\n        if user_id in self._notifications:\n            count = len(self._notifications[user_id])\n            self._notifications[user_id] = []\n            return count\n        return 0\n\n\ndef create_bulk_notifications(\n    service: NotificationService,\n    user_ids: list[str],\n    message: str,\n    tags: list = []\n) -> list[Notification]:\n    notifications = []\n    for user_id in user_ids:\n        notif = service.create_notification(\n            user_id=user_id,\n            message=message,\n            metadata={\"tags\": tags}\n        )\n        notifications.append(notif)\n    return notifications\n",
      "patchWithLinesStr": "## file: 'src/services/notification_service.py'\n\n@@ -0,0 +1,89 @@\n__new hunk__\n1 +from dataclasses import dataclass\n2 +from datetime import datetime\n3 +from typing import Optional\n4 +import logging\n5 +\n6 +logger = logging.getLogger(__name__)\n7 +\n8 +\n9 +@dataclass\n10 +class Notification:\n11 +    id: str\n12 +    user_id: str\n13 +    message: str\n14 +    created_at: datetime\n15 +    read: bool = False\n16 +    metadata: dict = None\n17 +\n18 +\n19 +class NotificationService:\n20 +    def __init__(self, max_notifications: int = 100):\n21 +        self.max_notifications = max_notifications\n22 +        self._notifications: dict[str, list[Notification]] = {}\n23 +\n24 +    def create_notification(\n25 +        self,\n26 +        user_id: str,\n27 +        message: str,\n28 +        metadata: dict = {}\n29 +    ) -> Notification:\n30 +        notification = Notification(\n31 +            id=f\"notif_{datetime.now().timestamp()}\",\n32 +            user_id=user_id,\n33 +            message=message,\n34 +            created_at=datetime.now(),\n35 +            metadata=metadata\n36 +        )\n37 +\n38 +        if user_id not in self._notifications:\n39 +            self._notifications[user_id] = []\n40 +\n41 +        user_notifications = self._notifications[user_id]\n42 +\n43 +        if len(user_notifications) >= self.max_notifications:\n44 +            user_notifications.pop(0)\n45 +\n46 +        user_notifications.append(notification)\n47 +        logger.info(f\"Created notification for user {user_id}\")\n48 +\n49 +        return notification\n50 +\n51 +    def get_notifications(self, user_id: str) -> list[Notification]:\n52 +        return self._notifications.get(user_id, [])\n53 +\n54 +    def mark_as_read(self, user_id: str, notification_id: str) -> bool:\n55 +        notifications = self._notifications.get(user_id, [])\n56 +        for notif in notifications:\n57 +            if notif.id == notification_id:\n58 +                notif.read = True\n59 +                return True\n60 +        return False\n61 +\n62 +    def get_unread_count(self, user_id: str) -> int:\n63 +        notifications = self._notifications.get(user_id, [])\n64 +        return sum(1 for n in notifications if not n.read)\n65 +\n66 +    def clear_notifications(self, user_id: str) -> int:\n67 +        if user_id in self._notifications:\n68 +            count = len(self._notifications[user_id])\n69 +            self._notifications[user_id] = []\n70 +            return count\n71 +        return 0\n72 +\n73 +\n74 +def create_bulk_notifications(\n75 +    service: NotificationService,\n76 +    user_ids: list[str],\n77 +    message: str,\n78 +    tags: list = []\n79 +) -> list[Notification]:\n80 +    notifications = []\n81 +    for user_id in user_ids:\n82 +        notif = service.create_notification(\n83 +            user_id=user_id,\n84 +            message=message,\n85 +            metadata={\"tags\": tags}\n86 +        )\n87 +        notifications.append(notif)\n88 +    return notifications\n89 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/services/notification_service.py\",\"relevantLinesStart\":26,\"relevantLinesEnd\":31},{\"relevantFile\":\"src/services/notification_service.py\",\"relevantLinesStart\":79,\"relevantLinesEnd\":84}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def create_notification(\\n        self,\\n        user_id: str,\\n        message: str,\\n        metadata: dict = {}\\n    ) -> Notification:\",\n    \"improvedCode\": \"def create_notification(\\n        self,\\n        user_id: str,\\n        message: str,\\n        metadata: dict | None = None\\n    ) -> Notification:\\n        if metadata is None:\\n            metadata = {}\",\n    \"relevantFile\": \"src/services/notification_service.py\",\n    \"relevantLinesEnd\": 31,\n    \"suggestionContent\": \"The `create_notification` method uses a mutable default argument `metadata: dict = {}`. In Python, default arguments are evaluated once when the function is defined, not each time it's called. All calls that don't provide metadata will share the same dict object, causing unexpected data sharing between notifications.\",\n    \"oneSentenceSummary\": \"Mutable default argument causes shared state between function calls\",\n    \"relevantLinesStart\": 26\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def create_bulk_notifications(\\n    service: NotificationService,\\n    user_ids: list[str],\\n    message: str,\\n    tags: list = []\\n) -> list[Notification]:\",\n    \"improvedCode\": \"def create_bulk_notifications(\\n    service: NotificationService,\\n    user_ids: list[str],\\n    message: str,\\n    tags: list | None = None\\n) -> list[Notification]:\\n    if tags is None:\\n        tags = []\",\n    \"relevantFile\": \"src/services/notification_service.py\",\n    \"relevantLinesEnd\": 84,\n    \"suggestionContent\": \"The `create_bulk_notifications` function has the same mutable default argument bug with `tags: list = []`. Additionally, since the same `tags` list is passed to all notifications' metadata, modifying tags in one notification will affect all others.\",\n    \"oneSentenceSummary\": \"Mutable default argument for tags list shared across all bulk notifications\",\n    \"relevantLinesStart\": 79\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 25: src/data/data_processor.py",
    "vars": {
      "fileContent": "from typing import Iterator, Iterable, TypeVar, Callable\nfrom dataclasses import dataclass\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\nR = TypeVar(\"R\")\n\n\n@dataclass\nclass ProcessingResult:\n    total: int\n    processed: int\n    failed: int\n    results: list\n\n\ndef process_items(items: Iterator[T], processor: Callable[[T], R]) -> ProcessingResult:\n    total = sum(1 for _ in items)\n\n    processed = 0\n    failed = 0\n    results = []\n\n    for item in items:\n        try:\n            result = processor(item)\n            results.append(result)\n            processed += 1\n        except Exception as e:\n            logger.error(f\"Failed to process item: {e}\")\n            failed += 1\n\n    return ProcessingResult(\n        total=total,\n        processed=processed,\n        failed=failed,\n        results=results\n    )\n\n\ndef filter_and_transform(\n    items: Iterator[T],\n    filter_fn: Callable[[T], bool],\n    transform_fn: Callable[[T], R]\n) -> list[R]:\n    filtered = (item for item in items if filter_fn(item))\n\n    if not any(filtered):\n        logger.info(\"No items passed filter\")\n        return []\n\n    return [transform_fn(item) for item in filtered]\n\n\ndef batch_process(items: Iterator[T], batch_size: int) -> Iterator[list[T]]:\n    batch = []\n    for item in items:\n        batch.append(item)\n        if len(batch) >= batch_size:\n            yield batch\n            batch = []\n    if batch:\n        yield batch\n\n\ndef get_statistics(numbers: Iterator[float]) -> dict:\n    numbers_list = list(numbers)\n\n    if not numbers_list:\n        return {\"count\": 0, \"sum\": 0, \"avg\": 0, \"min\": 0, \"max\": 0}\n\n    return {\n        \"count\": len(numbers_list),\n        \"sum\": sum(numbers_list),\n        \"avg\": sum(numbers_list) / len(numbers_list),\n        \"min\": min(numbers_list),\n        \"max\": max(numbers_list)\n    }\n\n\nclass DataPipeline:\n    def __init__(self):\n        self.steps: list[Callable] = []\n\n    def add_step(self, step: Callable):\n        self.steps.append(step)\n        return self\n\n    def execute(self, data: Iterable[T]) -> list:\n        current = iter(data)\n        for step in self.steps:\n            current = step(current)\n        return list(current)\n\n\ndef validate_all(items: Iterator[T], validator: Callable[[T], bool]) -> tuple[bool, list[T]]:\n    invalid_items = [item for item in items if not validator(item)]\n\n    all_valid = len(invalid_items) == 0\n\n    valid_items = [item for item in items if validator(item)]\n\n    return all_valid, valid_items\n",
      "patchWithLinesStr": "## file: 'src/data/data_processor.py'\n\n@@ -0,0 +1,106 @@\n__new hunk__\n1 +from typing import Iterator, Iterable, TypeVar, Callable\n2 +from dataclasses import dataclass\n3 +import logging\n4 +\n5 +logger = logging.getLogger(__name__)\n6 +\n7 +T = TypeVar(\"T\")\n8 +R = TypeVar(\"R\")\n9 +\n10 +\n11 +@dataclass\n12 +class ProcessingResult:\n13 +    total: int\n14 +    processed: int\n15 +    failed: int\n16 +    results: list\n17 +\n18 +\n19 +def process_items(items: Iterator[T], processor: Callable[[T], R]) -> ProcessingResult:\n20 +    total = sum(1 for _ in items)\n21 +\n22 +    processed = 0\n23 +    failed = 0\n24 +    results = []\n25 +\n26 +    for item in items:\n27 +        try:\n28 +            result = processor(item)\n29 +            results.append(result)\n30 +            processed += 1\n31 +        except Exception as e:\n32 +            logger.error(f\"Failed to process item: {e}\")\n33 +            failed += 1\n34 +\n35 +    return ProcessingResult(\n36 +        total=total,\n37 +        processed=processed,\n38 +        failed=failed,\n39 +        results=results\n40 +    )\n41 +\n42 +\n43 +def filter_and_transform(\n44 +    items: Iterator[T],\n45 +    filter_fn: Callable[[T], bool],\n46 +    transform_fn: Callable[[T], R]\n47 +) -> list[R]:\n48 +    filtered = (item for item in items if filter_fn(item))\n49 +\n50 +    if not any(filtered):\n51 +        logger.info(\"No items passed filter\")\n52 +        return []\n53 +\n54 +    return [transform_fn(item) for item in filtered]\n55 +\n56 +\n57 +def batch_process(items: Iterator[T], batch_size: int) -> Iterator[list[T]]:\n58 +    batch = []\n59 +    for item in items:\n60 +        batch.append(item)\n61 +        if len(batch) >= batch_size:\n62 +            yield batch\n63 +            batch = []\n64 +    if batch:\n65 +        yield batch\n66 +\n67 +\n68 +def get_statistics(numbers: Iterator[float]) -> dict:\n69 +    numbers_list = list(numbers)\n70 +\n71 +    if not numbers_list:\n72 +        return {\"count\": 0, \"sum\": 0, \"avg\": 0, \"min\": 0, \"max\": 0}\n73 +\n74 +    return {\n75 +        \"count\": len(numbers_list),\n76 +        \"sum\": sum(numbers_list),\n77 +        \"avg\": sum(numbers_list) / len(numbers_list),\n78 +        \"min\": min(numbers_list),\n79 +        \"max\": max(numbers_list)\n80 +    }\n81 +\n82 +\n83 +class DataPipeline:\n84 +    def __init__(self):\n85 +        self.steps: list[Callable] = []\n86 +\n87 +    def add_step(self, step: Callable):\n88 +        self.steps.append(step)\n89 +        return self\n90 +\n91 +    def execute(self, data: Iterable[T]) -> list:\n92 +        current = iter(data)\n93 +        for step in self.steps:\n94 +            current = step(current)\n95 +        return list(current)\n96 +\n97 +\n98 +def validate_all(items: Iterator[T], validator: Callable[[T], bool]) -> tuple[bool, list[T]]:\n99 +    invalid_items = [item for item in items if not validator(item)]\n100 +\n101 +    all_valid = len(invalid_items) == 0\n102 +\n103 +    valid_items = [item for item in items if validator(item)]\n104 +\n105 +    return all_valid, valid_items\n106 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/data/data_processor.py\",\"relevantLinesStart\":19,\"relevantLinesEnd\":26},{\"relevantFile\":\"src/data/data_processor.py\",\"relevantLinesStart\":44,\"relevantLinesEnd\":50},{\"relevantFile\":\"src/data/data_processor.py\",\"relevantLinesStart\":94,\"relevantLinesEnd\":98}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def process_items(items: Iterator[T], processor: Callable[[T], R]) -> ProcessingResult:\\n    total = sum(1 for _ in items)\\n\\n    processed = 0\\n    failed = 0\\n    results = []\\n\\n    for item in items:\",\n    \"improvedCode\": \"def process_items(items: Iterator[T], processor: Callable[[T], R]) -> ProcessingResult:\\n    items_list = list(items)\\n    total = len(items_list)\\n\\n    processed = 0\\n    failed = 0\\n    results = []\\n\\n    for item in items_list:\",\n    \"relevantFile\": \"src/data/data_processor.py\",\n    \"relevantLinesEnd\": 26,\n    \"suggestionContent\": \"In `process_items`, the iterator `items` is consumed by `sum(1 for _ in items)` to count total items. When the for loop tries to iterate over `items` again, it's already exhausted and yields nothing. The function will always report 0 processed items. Convert to list first or use itertools.tee.\",\n    \"oneSentenceSummary\": \"Iterator exhausted by sum() - second iteration processes zero items\",\n    \"relevantLinesStart\": 19\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"filtered = (item for item in items if filter_fn(item))\\n\\n    if not any(filtered):\\n        logger.info(\\\"No items passed filter\\\")\\n        return []\\n\\n    return [transform_fn(item) for item in filtered]\",\n    \"improvedCode\": \"filtered = [item for item in items if filter_fn(item)]\\n\\n    if not filtered:\\n        logger.info(\\\"No items passed filter\\\")\\n        return []\\n\\n    return [transform_fn(item) for item in filtered]\",\n    \"relevantFile\": \"src/data/data_processor.py\",\n    \"relevantLinesEnd\": 50,\n    \"suggestionContent\": \"In `filter_and_transform`, the generator `filtered` is consumed by `any(filtered)` to check if items exist. Then the list comprehension tries to iterate over the same exhausted generator, producing an empty list even when items passed the filter.\",\n    \"oneSentenceSummary\": \"Generator exhausted by any() check - returns empty list for valid data\",\n    \"relevantLinesStart\": 44\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"invalid_items = [item for item in items if not validator(item)]\\n\\n    all_valid = len(invalid_items) == 0\\n\\n    valid_items = [item for item in items if validator(item)]\",\n    \"improvedCode\": \"items_list = list(items)\\n    invalid_items = [item for item in items_list if not validator(item)]\\n\\n    all_valid = len(invalid_items) == 0\\n\\n    valid_items = [item for item in items_list if validator(item)]\",\n    \"relevantFile\": \"src/data/data_processor.py\",\n    \"relevantLinesEnd\": 98,\n    \"suggestionContent\": \"In `validate_all`, the iterator `items` is consumed by the first list comprehension to find invalid items. The second comprehension iterates over the same exhausted iterator, always producing an empty `valid_items` list.\",\n    \"oneSentenceSummary\": \"Iterator consumed twice - valid_items always empty after invalid_items check\",\n    \"relevantLinesStart\": 94\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 26: src/cache/serialization_cache.py",
    "vars": {
      "fileContent": "import pickle\nimport json\nimport zlib\nfrom typing import Any, TypeVar\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nimport hashlib\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\n\nclass SerializationCache:\n    def __init__(self, cache_dir: str = \"./cache\"):\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n\n    def _get_cache_path(self, key: str) -> Path:\n        key_hash = hashlib.sha256(key.encode()).hexdigest()[:16]\n        return self.cache_dir / f\"{key_hash}.cache\"\n\n    def set(self, key: str, value: Any, compress: bool = False) -> None:\n        cache_path = self._get_cache_path(key)\n\n        data = pickle.dumps(value)\n\n        if compress:\n            data = zlib.compress(data)\n\n        cache_path.write_bytes(data)\n        logger.debug(f\"Cached value for key: {key}\")\n\n    def get(self, key: str, decompress: bool = False) -> Any | None:\n        cache_path = self._get_cache_path(key)\n\n        if not cache_path.exists():\n            return None\n\n        data = cache_path.read_bytes()\n\n        if decompress:\n            data = zlib.decompress(data)\n\n        return pickle.loads(data)\n\n    def delete(self, key: str) -> bool:\n        cache_path = self._get_cache_path(key)\n        if cache_path.exists():\n            cache_path.unlink()\n            return True\n        return False\n\n    def clear(self) -> int:\n        count = 0\n        for cache_file in self.cache_dir.glob(\"*.cache\"):\n            cache_file.unlink()\n            count += 1\n        return count\n\n\nclass RemoteCache:\n    def __init__(self, local_cache: SerializationCache):\n        self.local_cache = local_cache\n        self._remote_data: dict[str, bytes] = {}\n\n    def fetch_and_cache(self, key: str, remote_data: bytes) -> Any:\n        value = pickle.loads(remote_data)\n        self.local_cache.set(key, value)\n        return value\n\n    def export_to_remote(self, key: str) -> bytes:\n        value = self.local_cache.get(key)\n        if value is None:\n            raise KeyError(f\"Key not found: {key}\")\n        return pickle.dumps(value)\n\n    def import_from_bytes(self, data: bytes) -> Any:\n        return pickle.loads(data)\n\n\nclass CacheSerializer:\n    @staticmethod\n    def serialize(value: Any, format: str = \"pickle\") -> bytes:\n        if format == \"pickle\":\n            return pickle.dumps(value)\n        elif format == \"json\":\n            return json.dumps(value).encode()\n        else:\n            raise ValueError(f\"Unsupported format: {format}\")\n\n    @staticmethod\n    def deserialize(data: bytes, format: str = \"pickle\") -> Any:\n        if format == \"pickle\":\n            return pickle.loads(data)\n        elif format == \"json\":\n            return json.loads(data.decode())\n        else:\n            raise ValueError(f\"Unsupported format: {format}\")\n",
      "patchWithLinesStr": "## file: 'src/cache/serialization_cache.py'\n\n@@ -0,0 +1,101 @@\n__new hunk__\n1 +import pickle\n2 +import json\n3 +import zlib\n4 +from typing import Any, TypeVar\n5 +from pathlib import Path\n6 +from datetime import datetime, timedelta\n7 +import hashlib\n8 +import logging\n9 +\n10 +logger = logging.getLogger(__name__)\n11 +\n12 +T = TypeVar(\"T\")\n13 +\n14 +\n15 +class SerializationCache:\n16 +    def __init__(self, cache_dir: str = \"./cache\"):\n17 +        self.cache_dir = Path(cache_dir)\n18 +        self.cache_dir.mkdir(parents=True, exist_ok=True)\n19 +\n20 +    def _get_cache_path(self, key: str) -> Path:\n21 +        key_hash = hashlib.sha256(key.encode()).hexdigest()[:16]\n22 +        return self.cache_dir / f\"{key_hash}.cache\"\n23 +\n24 +    def set(self, key: str, value: Any, compress: bool = False) -> None:\n25 +        cache_path = self._get_cache_path(key)\n26 +\n27 +        data = pickle.dumps(value)\n28 +\n29 +        if compress:\n30 +            data = zlib.compress(data)\n31 +\n32 +        cache_path.write_bytes(data)\n33 +        logger.debug(f\"Cached value for key: {key}\")\n34 +\n35 +    def get(self, key: str, decompress: bool = False) -> Any | None:\n36 +        cache_path = self._get_cache_path(key)\n37 +\n38 +        if not cache_path.exists():\n39 +            return None\n40 +\n41 +        data = cache_path.read_bytes()\n42 +\n43 +        if decompress:\n44 +            data = zlib.decompress(data)\n45 +\n46 +        return pickle.loads(data)\n47 +\n48 +    def delete(self, key: str) -> bool:\n49 +        cache_path = self._get_cache_path(key)\n50 +        if cache_path.exists():\n51 +            cache_path.unlink()\n52 +            return True\n53 +        return False\n54 +\n55 +    def clear(self) -> int:\n56 +        count = 0\n57 +        for cache_file in self.cache_dir.glob(\"*.cache\"):\n58 +            cache_file.unlink()\n59 +            count += 1\n60 +        return count\n61 +\n62 +\n63 +class RemoteCache:\n64 +    def __init__(self, local_cache: SerializationCache):\n65 +        self.local_cache = local_cache\n66 +        self._remote_data: dict[str, bytes] = {}\n67 +\n68 +    def fetch_and_cache(self, key: str, remote_data: bytes) -> Any:\n69 +        value = pickle.loads(remote_data)\n70 +        self.local_cache.set(key, value)\n71 +        return value\n72 +\n73 +    def export_to_remote(self, key: str) -> bytes:\n74 +        value = self.local_cache.get(key)\n75 +        if value is None:\n76 +            raise KeyError(f\"Key not found: {key}\")\n77 +        return pickle.dumps(value)\n78 +\n79 +    def import_from_bytes(self, data: bytes) -> Any:\n80 +        return pickle.loads(data)\n81 +\n82 +\n83 +class CacheSerializer:\n84 +    @staticmethod\n85 +    def serialize(value: Any, format: str = \"pickle\") -> bytes:\n86 +        if format == \"pickle\":\n87 +            return pickle.dumps(value)\n88 +        elif format == \"json\":\n89 +            return json.dumps(value).encode()\n90 +        else:\n91 +            raise ValueError(f\"Unsupported format: {format}\")\n92 +\n93 +    @staticmethod\n94 +    def deserialize(data: bytes, format: str = \"pickle\") -> Any:\n95 +        if format == \"pickle\":\n96 +            return pickle.loads(data)\n97 +        elif format == \"json\":\n98 +            return json.loads(data.decode())\n99 +        else:\n100 +            raise ValueError(f\"Unsupported format: {format}\")\n101 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/cache/serialization_cache.py\",\"relevantLinesStart\":65,\"relevantLinesEnd\":68}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def fetch_and_cache(self, key: str, remote_data: bytes) -> Any:\\n        value = pickle.loads(remote_data)\\n        self.local_cache.set(key, value)\\n        return value\",\n    \"improvedCode\": \"def fetch_and_cache(self, key: str, remote_data: bytes) -> Any:\\n        # Use JSON for untrusted data, or implement a RestrictedUnpickler\\n        import json\\n        value = json.loads(remote_data.decode())\\n        self.local_cache.set(key, value)\\n        return value\",\n    \"relevantFile\": \"src/cache/serialization_cache.py\",\n    \"relevantLinesEnd\": 68,\n    \"suggestionContent\": \"Multiple methods use `pickle.loads()` to deserialize data, including data from external sources (`fetch_and_cache`, `import_from_bytes`). Pickle can execute arbitrary code during deserialization. An attacker can craft a malicious pickle payload that runs system commands when loaded. Never unpickle data from untrusted sources.\",\n    \"oneSentenceSummary\": \"Pickle deserialization of untrusted data allows arbitrary code execution\",\n    \"relevantLinesStart\": 65\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 27: src/database/user_repository.py",
    "vars": {
      "fileContent": "from dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional\nimport sqlite3\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass User:\n    id: int\n    username: str\n    email: str\n    created_at: datetime\n    is_active: bool = True\n\n\nclass UserRepository:\n    def __init__(self, db_path: str):\n        self.db_path = db_path\n        self._connection: sqlite3.Connection | None = None\n\n    def _get_connection(self) -> sqlite3.Connection:\n        if self._connection is None:\n            self._connection = sqlite3.connect(self.db_path)\n            self._connection.row_factory = sqlite3.Row\n        return self._connection\n\n    def find_by_id(self, user_id: int) -> User | None:\n        conn = self._get_connection()\n        cursor = conn.execute(\n            \"SELECT * FROM users WHERE id = ?\",\n            (user_id,)\n        )\n        row = cursor.fetchone()\n        return self._row_to_user(row) if row else None\n\n    def find_by_username(self, username: str) -> User | None:\n        conn = self._get_connection()\n        query = f\"SELECT * FROM users WHERE username = '{username}'\"\n        cursor = conn.execute(query)\n        row = cursor.fetchone()\n        return self._row_to_user(row) if row else None\n\n    def find_by_email(self, email: str) -> User | None:\n        conn = self._get_connection()\n        cursor = conn.execute(\n            \"SELECT * FROM users WHERE email = ?\",\n            (email,)\n        )\n        row = cursor.fetchone()\n        return self._row_to_user(row) if row else None\n\n    def search_users(self, search_term: str, field: str = \"username\") -> list[User]:\n        conn = self._get_connection()\n        query = f\"SELECT * FROM users WHERE {field} LIKE '%{search_term}%'\"\n        cursor = conn.execute(query)\n        return [self._row_to_user(row) for row in cursor.fetchall()]\n\n    def create_user(self, username: str, email: str) -> User:\n        conn = self._get_connection()\n        cursor = conn.execute(\n            \"INSERT INTO users (username, email, created_at) VALUES (?, ?, ?)\",\n            (username, email, datetime.now().isoformat())\n        )\n        conn.commit()\n        return self.find_by_id(cursor.lastrowid)\n\n    def update_user(self, user_id: int, **fields) -> bool:\n        if not fields:\n            return False\n\n        conn = self._get_connection()\n        set_clause = \", \".join(f\"{k} = ?\" for k in fields.keys())\n        values = list(fields.values()) + [user_id]\n\n        conn.execute(\n            f\"UPDATE users SET {set_clause} WHERE id = ?\",\n            values\n        )\n        conn.commit()\n        return True\n\n    def delete_user(self, user_id: int) -> bool:\n        conn = self._get_connection()\n        cursor = conn.execute(\n            \"DELETE FROM users WHERE id = ?\",\n            (user_id,)\n        )\n        conn.commit()\n        return cursor.rowcount > 0\n\n    def get_users_by_status(self, is_active: bool, order_by: str = \"created_at\") -> list[User]:\n        conn = self._get_connection()\n        query = f\"SELECT * FROM users WHERE is_active = ? ORDER BY {order_by}\"\n        cursor = conn.execute(query, (is_active,))\n        return [self._row_to_user(row) for row in cursor.fetchall()]\n\n    def _row_to_user(self, row: sqlite3.Row) -> User:\n        return User(\n            id=row[\"id\"],\n            username=row[\"username\"],\n            email=row[\"email\"],\n            created_at=datetime.fromisoformat(row[\"created_at\"]),\n            is_active=bool(row[\"is_active\"])\n        )\n\n    def close(self):\n        if self._connection:\n            self._connection.close()\n            self._connection = None\n",
      "patchWithLinesStr": "## file: 'src/database/user_repository.py'\n\n@@ -0,0 +1,113 @@\n__new hunk__\n1 +from dataclasses import dataclass\n2 +from datetime import datetime\n3 +from typing import Optional\n4 +import sqlite3\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +\n10 +@dataclass\n11 +class User:\n12 +    id: int\n13 +    username: str\n14 +    email: str\n15 +    created_at: datetime\n16 +    is_active: bool = True\n17 +\n18 +\n19 +class UserRepository:\n20 +    def __init__(self, db_path: str):\n21 +        self.db_path = db_path\n22 +        self._connection: sqlite3.Connection | None = None\n23 +\n24 +    def _get_connection(self) -> sqlite3.Connection:\n25 +        if self._connection is None:\n26 +            self._connection = sqlite3.connect(self.db_path)\n27 +            self._connection.row_factory = sqlite3.Row\n28 +        return self._connection\n29 +\n30 +    def find_by_id(self, user_id: int) -> User | None:\n31 +        conn = self._get_connection()\n32 +        cursor = conn.execute(\n33 +            \"SELECT * FROM users WHERE id = ?\",\n34 +            (user_id,)\n35 +        )\n36 +        row = cursor.fetchone()\n37 +        return self._row_to_user(row) if row else None\n38 +\n39 +    def find_by_username(self, username: str) -> User | None:\n40 +        conn = self._get_connection()\n41 +        query = f\"SELECT * FROM users WHERE username = '{username}'\"\n42 +        cursor = conn.execute(query)\n43 +        row = cursor.fetchone()\n44 +        return self._row_to_user(row) if row else None\n45 +\n46 +    def find_by_email(self, email: str) -> User | None:\n47 +        conn = self._get_connection()\n48 +        cursor = conn.execute(\n49 +            \"SELECT * FROM users WHERE email = ?\",\n50 +            (email,)\n51 +        )\n52 +        row = cursor.fetchone()\n53 +        return self._row_to_user(row) if row else None\n54 +\n55 +    def search_users(self, search_term: str, field: str = \"username\") -> list[User]:\n56 +        conn = self._get_connection()\n57 +        query = f\"SELECT * FROM users WHERE {field} LIKE '%{search_term}%'\"\n58 +        cursor = conn.execute(query)\n59 +        return [self._row_to_user(row) for row in cursor.fetchall()]\n60 +\n61 +    def create_user(self, username: str, email: str) -> User:\n62 +        conn = self._get_connection()\n63 +        cursor = conn.execute(\n64 +            \"INSERT INTO users (username, email, created_at) VALUES (?, ?, ?)\",\n65 +            (username, email, datetime.now().isoformat())\n66 +        )\n67 +        conn.commit()\n68 +        return self.find_by_id(cursor.lastrowid)\n69 +\n70 +    def update_user(self, user_id: int, **fields) -> bool:\n71 +        if not fields:\n72 +            return False\n73 +\n74 +        conn = self._get_connection()\n75 +        set_clause = \", \".join(f\"{k} = ?\" for k in fields.keys())\n76 +        values = list(fields.values()) + [user_id]\n77 +\n78 +        conn.execute(\n79 +            f\"UPDATE users SET {set_clause} WHERE id = ?\",\n80 +            values\n81 +        )\n82 +        conn.commit()\n83 +        return True\n84 +\n85 +    def delete_user(self, user_id: int) -> bool:\n86 +        conn = self._get_connection()\n87 +        cursor = conn.execute(\n88 +            \"DELETE FROM users WHERE id = ?\",\n89 +            (user_id,)\n90 +        )\n91 +        conn.commit()\n92 +        return cursor.rowcount > 0\n93 +\n94 +    def get_users_by_status(self, is_active: bool, order_by: str = \"created_at\") -> list[User]:\n95 +        conn = self._get_connection()\n96 +        query = f\"SELECT * FROM users WHERE is_active = ? ORDER BY {order_by}\"\n97 +        cursor = conn.execute(query, (is_active,))\n98 +        return [self._row_to_user(row) for row in cursor.fetchall()]\n99 +\n100 +    def _row_to_user(self, row: sqlite3.Row) -> User:\n101 +        return User(\n102 +            id=row[\"id\"],\n103 +            username=row[\"username\"],\n104 +            email=row[\"email\"],\n105 +            created_at=datetime.fromisoformat(row[\"created_at\"]),\n106 +            is_active=bool(row[\"is_active\"])\n107 +        )\n108 +\n109 +    def close(self):\n110 +        if self._connection:\n111 +            self._connection.close()\n112 +            self._connection = None\n113 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/database/user_repository.py\",\"relevantLinesStart\":40,\"relevantLinesEnd\":40},{\"relevantFile\":\"src/database/user_repository.py\",\"relevantLinesStart\":54,\"relevantLinesEnd\":54},{\"relevantFile\":\"src/database/user_repository.py\",\"relevantLinesStart\":88,\"relevantLinesEnd\":88}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"query = f\\\"SELECT * FROM users WHERE username = '{username}'\\\"\",\n    \"improvedCode\": \"cursor = conn.execute(\\n            \\\"SELECT * FROM users WHERE username = ?\\\",\\n            (username,)\\n        )\",\n    \"relevantFile\": \"src/database/user_repository.py\",\n    \"relevantLinesEnd\": 40,\n    \"suggestionContent\": \"The `find_by_username` method uses f-string formatting to build SQL query, making it vulnerable to SQL injection. An attacker can pass `' OR '1'='1` as username to bypass authentication or `'; DROP TABLE users; --` to delete data. Use parameterized queries instead.\",\n    \"oneSentenceSummary\": \"SQL injection vulnerability - username directly interpolated into query\",\n    \"relevantLinesStart\": 40\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"query = f\\\"SELECT * FROM users WHERE {field} LIKE '%{search_term}%'\\\"\",\n    \"improvedCode\": \"allowed_fields = {'username', 'email'}\\n        if field not in allowed_fields:\\n            raise ValueError(f\\\"Invalid field: {field}\\\")\\n        query = f\\\"SELECT * FROM users WHERE {field} LIKE ?\\\"\\n        cursor = conn.execute(query, (f'%{search_term}%',))\",\n    \"relevantFile\": \"src/database/user_repository.py\",\n    \"relevantLinesEnd\": 54,\n    \"suggestionContent\": \"The `search_users` method has two SQL injection vulnerabilities: both `field` and `search_term` are interpolated directly into the query. An attacker can inject via the field parameter (e.g., `username; DROP TABLE users; --`) or the search term.\",\n    \"oneSentenceSummary\": \"SQL injection via field name and search term parameters\",\n    \"relevantLinesStart\": 54\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"query = f\\\"SELECT * FROM users WHERE is_active = ? ORDER BY {order_by}\\\"\",\n    \"improvedCode\": \"allowed_order_fields = {'created_at', 'username', 'email', 'id'}\\n        if order_by not in allowed_order_fields:\\n            raise ValueError(f\\\"Invalid order field: {order_by}\\\")\\n        query = f\\\"SELECT * FROM users WHERE is_active = ? ORDER BY {order_by}\\\"\",\n    \"relevantFile\": \"src/database/user_repository.py\",\n    \"relevantLinesEnd\": 88,\n    \"suggestionContent\": \"The `get_users_by_status` method interpolates `order_by` directly into the query without validation. An attacker can inject SQL via the order_by parameter, e.g., `created_at; DROP TABLE users; --`.\",\n    \"oneSentenceSummary\": \"SQL injection via order_by parameter not validated\",\n    \"relevantLinesStart\": 88\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 28: src/session/session_manager.py",
    "vars": {
      "fileContent": "from datetime import datetime, timedelta\nfrom typing import Any\nfrom dataclasses import dataclass, field\nimport secrets\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass Session:\n    id: str\n    user_id: str\n    data: dict[str, Any]\n    created_at: datetime\n    last_accessed: datetime\n    expires_at: datetime\n\n    def is_expired(self) -> bool:\n        return datetime.now() > self.expires_at\n\n    def touch(self):\n        self.last_accessed = datetime.now()\n\n\nclass SessionManager:\n    def __init__(self, session_ttl_minutes: int = 30):\n        self._sessions: dict[str, Session] = {}\n        self._user_sessions: dict[str, set[str]] = {}\n        self._ttl = timedelta(minutes=session_ttl_minutes)\n\n    def create_session(self, user_id: str, data: dict = None) -> Session:\n        session_id = secrets.token_urlsafe(32)\n        now = datetime.now()\n\n        session = Session(\n            id=session_id,\n            user_id=user_id,\n            data=data or {},\n            created_at=now,\n            last_accessed=now,\n            expires_at=now + self._ttl\n        )\n\n        self._sessions[session_id] = session\n\n        if user_id not in self._user_sessions:\n            self._user_sessions[user_id] = set()\n        self._user_sessions[user_id].add(session_id)\n\n        logger.info(f\"Created session {session_id} for user {user_id}\")\n        return session\n\n    def get_session(self, session_id: str) -> Session | None:\n        session = self._sessions.get(session_id)\n        if session and not session.is_expired():\n            session.touch()\n            return session\n        return None\n\n    def delete_session(self, session_id: str) -> bool:\n        session = self._sessions.get(session_id)\n        if session:\n            del self._sessions[session_id]\n            if session.user_id in self._user_sessions:\n                self._user_sessions[session.user_id].discard(session_id)\n            return True\n        return False\n\n    def cleanup_expired_sessions(self) -> int:\n        count = 0\n        for session_id, session in self._sessions.items():\n            if session.is_expired():\n                del self._sessions[session_id]\n                if session.user_id in self._user_sessions:\n                    self._user_sessions[session.user_id].discard(session_id)\n                count += 1\n                logger.info(f\"Cleaned up expired session {session_id}\")\n        return count\n\n    def get_user_sessions(self, user_id: str) -> list[Session]:\n        session_ids = self._user_sessions.get(user_id, set())\n        sessions = []\n        for sid in session_ids:\n            session = self.get_session(sid)\n            if session:\n                sessions.append(session)\n        return sessions\n\n    def invalidate_user_sessions(self, user_id: str) -> int:\n        session_ids = self._user_sessions.get(user_id, set())\n        count = 0\n        for session_id in session_ids:\n            if self.delete_session(session_id):\n                count += 1\n        return count\n\n    def get_active_session_count(self) -> int:\n        return sum(1 for s in self._sessions.values() if not s.is_expired())\n\n    def get_stats(self) -> dict:\n        total = len(self._sessions)\n        active = self.get_active_session_count()\n        return {\n            \"total_sessions\": total,\n            \"active_sessions\": active,\n            \"expired_sessions\": total - active,\n            \"unique_users\": len(self._user_sessions)\n        }\n",
      "patchWithLinesStr": "## file: 'src/session/session_manager.py'\n\n@@ -0,0 +1,110 @@\n__new hunk__\n1 +from datetime import datetime, timedelta\n2 +from typing import Any\n3 +from dataclasses import dataclass, field\n4 +import secrets\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +\n10 +@dataclass\n11 +class Session:\n12 +    id: str\n13 +    user_id: str\n14 +    data: dict[str, Any]\n15 +    created_at: datetime\n16 +    last_accessed: datetime\n17 +    expires_at: datetime\n18 +\n19 +    def is_expired(self) -> bool:\n20 +        return datetime.now() > self.expires_at\n21 +\n22 +    def touch(self):\n23 +        self.last_accessed = datetime.now()\n24 +\n25 +\n26 +class SessionManager:\n27 +    def __init__(self, session_ttl_minutes: int = 30):\n28 +        self._sessions: dict[str, Session] = {}\n29 +        self._user_sessions: dict[str, set[str]] = {}\n30 +        self._ttl = timedelta(minutes=session_ttl_minutes)\n31 +\n32 +    def create_session(self, user_id: str, data: dict = None) -> Session:\n33 +        session_id = secrets.token_urlsafe(32)\n34 +        now = datetime.now()\n35 +\n36 +        session = Session(\n37 +            id=session_id,\n38 +            user_id=user_id,\n39 +            data=data or {},\n40 +            created_at=now,\n41 +            last_accessed=now,\n42 +            expires_at=now + self._ttl\n43 +        )\n44 +\n45 +        self._sessions[session_id] = session\n46 +\n47 +        if user_id not in self._user_sessions:\n48 +            self._user_sessions[user_id] = set()\n49 +        self._user_sessions[user_id].add(session_id)\n50 +\n51 +        logger.info(f\"Created session {session_id} for user {user_id}\")\n52 +        return session\n53 +\n54 +    def get_session(self, session_id: str) -> Session | None:\n55 +        session = self._sessions.get(session_id)\n56 +        if session and not session.is_expired():\n57 +            session.touch()\n58 +            return session\n59 +        return None\n60 +\n61 +    def delete_session(self, session_id: str) -> bool:\n62 +        session = self._sessions.get(session_id)\n63 +        if session:\n64 +            del self._sessions[session_id]\n65 +            if session.user_id in self._user_sessions:\n66 +                self._user_sessions[session.user_id].discard(session_id)\n67 +            return True\n68 +        return False\n69 +\n70 +    def cleanup_expired_sessions(self) -> int:\n71 +        count = 0\n72 +        for session_id, session in self._sessions.items():\n73 +            if session.is_expired():\n74 +                del self._sessions[session_id]\n75 +                if session.user_id in self._user_sessions:\n76 +                    self._user_sessions[session.user_id].discard(session_id)\n77 +                count += 1\n78 +                logger.info(f\"Cleaned up expired session {session_id}\")\n79 +        return count\n80 +\n81 +    def get_user_sessions(self, user_id: str) -> list[Session]:\n82 +        session_ids = self._user_sessions.get(user_id, set())\n83 +        sessions = []\n84 +        for sid in session_ids:\n85 +            session = self.get_session(sid)\n86 +            if session:\n87 +                sessions.append(session)\n88 +        return sessions\n89 +\n90 +    def invalidate_user_sessions(self, user_id: str) -> int:\n91 +        session_ids = self._user_sessions.get(user_id, set())\n92 +        count = 0\n93 +        for session_id in session_ids:\n94 +            if self.delete_session(session_id):\n95 +                count += 1\n96 +        return count\n97 +\n98 +    def get_active_session_count(self) -> int:\n99 +        return sum(1 for s in self._sessions.values() if not s.is_expired())\n100 +\n101 +    def get_stats(self) -> dict:\n102 +        total = len(self._sessions)\n103 +        active = self.get_active_session_count()\n104 +        return {\n105 +            \"total_sessions\": total,\n106 +            \"active_sessions\": active,\n107 +            \"expired_sessions\": total - active,\n108 +            \"unique_users\": len(self._user_sessions)\n109 +        }\n110 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/session/session_manager.py\",\"relevantLinesStart\":68,\"relevantLinesEnd\":76},{\"relevantFile\":\"src/session/session_manager.py\",\"relevantLinesStart\":86,\"relevantLinesEnd\":92}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def cleanup_expired_sessions(self) -> int:\\n        count = 0\\n        for session_id, session in self._sessions.items():\\n            if session.is_expired():\\n                del self._sessions[session_id]\",\n    \"improvedCode\": \"def cleanup_expired_sessions(self) -> int:\\n        count = 0\\n        expired_ids = [\\n            sid for sid, session in self._sessions.items()\\n            if session.is_expired()\\n        ]\\n        for session_id in expired_ids:\\n            session = self._sessions[session_id]\\n            del self._sessions[session_id]\",\n    \"relevantFile\": \"src/session/session_manager.py\",\n    \"relevantLinesEnd\": 76,\n    \"suggestionContent\": \"The `cleanup_expired_sessions` method modifies `self._sessions` dict while iterating over it with `.items()`. This raises `RuntimeError: dictionary changed size during iteration` in Python 3. Create a list of keys to delete first, then delete them in a separate loop.\",\n    \"oneSentenceSummary\": \"Dictionary modified during iteration causes RuntimeError\",\n    \"relevantLinesStart\": 68\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def invalidate_user_sessions(self, user_id: str) -> int:\\n        session_ids = self._user_sessions.get(user_id, set())\\n        count = 0\\n        for session_id in session_ids:\\n            if self.delete_session(session_id):\\n                count += 1\\n        return count\",\n    \"improvedCode\": \"def invalidate_user_sessions(self, user_id: str) -> int:\\n        session_ids = list(self._user_sessions.get(user_id, set()))\\n        count = 0\\n        for session_id in session_ids:\\n            if self.delete_session(session_id):\\n                count += 1\\n        return count\",\n    \"relevantFile\": \"src/session/session_manager.py\",\n    \"relevantLinesEnd\": 92,\n    \"suggestionContent\": \"The `invalidate_user_sessions` method iterates over `session_ids` set while `delete_session` modifies the same set via `self._user_sessions[session.user_id].discard(session_id)`. This causes `RuntimeError: Set changed size during iteration`.\",\n    \"oneSentenceSummary\": \"Set modified during iteration via delete_session causes RuntimeError\",\n    \"relevantLinesStart\": 86\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 29: src/workers/task_scheduler.py",
    "vars": {
      "fileContent": "import asyncio\nfrom datetime import datetime, timedelta\nfrom typing import Callable, Awaitable\nfrom dataclasses import dataclass, field\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ScheduledTask:\n    id: str\n    name: str\n    callback: Callable[[], Awaitable[None]]\n    interval_seconds: int\n    last_run: datetime | None = None\n    is_running: bool = False\n    run_count: int = 0\n\n\nclass TaskScheduler:\n    def __init__(self):\n        self.tasks: dict[str, ScheduledTask] = {}\n        self._running = False\n        self._task_handles: list[asyncio.Task] = []\n\n    def add_task(\n        self,\n        task_id: str,\n        name: str,\n        callback: Callable[[], Awaitable[None]],\n        interval_seconds: int\n    ) -> ScheduledTask:\n        task = ScheduledTask(\n            id=task_id,\n            name=name,\n            callback=callback,\n            interval_seconds=interval_seconds\n        )\n        self.tasks[task_id] = task\n        logger.info(f\"Added task: {name} (interval: {interval_seconds}s)\")\n        return task\n\n    async def _run_task(self, task: ScheduledTask):\n        while self._running:\n            try:\n                task.is_running = True\n                await task.callback()\n                task.last_run = datetime.now()\n                task.run_count += 1\n            except Exception as e:\n                logger.error(f\"Task {task.name} failed: {e}\")\n            finally:\n                task.is_running = False\n\n            await asyncio.sleep(task.interval_seconds)\n\n    async def start(self):\n        if self._running:\n            return\n\n        self._running = True\n        logger.info(\"Starting task scheduler\")\n\n        for task_id in self.tasks:\n            task = self.tasks[task_id]\n            handle = asyncio.create_task(self._run_task(task))\n            self._task_handles.append(handle)\n\n    async def stop(self):\n        self._running = False\n        for handle in self._task_handles:\n            handle.cancel()\n        self._task_handles.clear()\n        logger.info(\"Task scheduler stopped\")\n\n    def get_task_status(self, task_id: str) -> dict | None:\n        task = self.tasks.get(task_id)\n        if not task:\n            return None\n        return {\n            \"id\": task.id,\n            \"name\": task.name,\n            \"is_running\": task.is_running,\n            \"run_count\": task.run_count,\n            \"last_run\": task.last_run.isoformat() if task.last_run else None\n        }\n\n\ndef create_scheduled_tasks(scheduler: TaskScheduler, task_configs: list[dict]):\n    callbacks = []\n\n    for config in task_configs:\n        async def task_callback():\n            logger.info(f\"Executing task: {config['name']}\")\n            await asyncio.sleep(0.1)\n\n        callbacks.append(task_callback)\n\n        scheduler.add_task(\n            task_id=config[\"id\"],\n            name=config[\"name\"],\n            callback=task_callback,\n            interval_seconds=config[\"interval\"]\n        )\n\n\nasync def run_parallel_tasks(tasks: list[Callable[[], Awaitable[None]]]):\n    handles = []\n    for i, task in enumerate(tasks):\n        handle = asyncio.create_task(task())\n        handles.append(handle)\n\n    await asyncio.gather(*handles)\n",
      "patchWithLinesStr": "## file: 'src/workers/task_scheduler.py'\n\n@@ -0,0 +1,115 @@\n__new hunk__\n1 +import asyncio\n2 +from datetime import datetime, timedelta\n3 +from typing import Callable, Awaitable\n4 +from dataclasses import dataclass, field\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +\n10 +@dataclass\n11 +class ScheduledTask:\n12 +    id: str\n13 +    name: str\n14 +    callback: Callable[[], Awaitable[None]]\n15 +    interval_seconds: int\n16 +    last_run: datetime | None = None\n17 +    is_running: bool = False\n18 +    run_count: int = 0\n19 +\n20 +\n21 +class TaskScheduler:\n22 +    def __init__(self):\n23 +        self.tasks: dict[str, ScheduledTask] = {}\n24 +        self._running = False\n25 +        self._task_handles: list[asyncio.Task] = []\n26 +\n27 +    def add_task(\n28 +        self,\n29 +        task_id: str,\n30 +        name: str,\n31 +        callback: Callable[[], Awaitable[None]],\n32 +        interval_seconds: int\n33 +    ) -> ScheduledTask:\n34 +        task = ScheduledTask(\n35 +            id=task_id,\n36 +            name=name,\n37 +            callback=callback,\n38 +            interval_seconds=interval_seconds\n39 +        )\n40 +        self.tasks[task_id] = task\n41 +        logger.info(f\"Added task: {name} (interval: {interval_seconds}s)\")\n42 +        return task\n43 +\n44 +    async def _run_task(self, task: ScheduledTask):\n45 +        while self._running:\n46 +            try:\n47 +                task.is_running = True\n48 +                await task.callback()\n49 +                task.last_run = datetime.now()\n50 +                task.run_count += 1\n51 +            except Exception as e:\n52 +                logger.error(f\"Task {task.name} failed: {e}\")\n53 +            finally:\n54 +                task.is_running = False\n55 +\n56 +            await asyncio.sleep(task.interval_seconds)\n57 +\n58 +    async def start(self):\n59 +        if self._running:\n60 +            return\n61 +\n62 +        self._running = True\n63 +        logger.info(\"Starting task scheduler\")\n64 +\n65 +        for task_id in self.tasks:\n66 +            task = self.tasks[task_id]\n67 +            handle = asyncio.create_task(self._run_task(task))\n68 +            self._task_handles.append(handle)\n69 +\n70 +    async def stop(self):\n71 +        self._running = False\n72 +        for handle in self._task_handles:\n73 +            handle.cancel()\n74 +        self._task_handles.clear()\n75 +        logger.info(\"Task scheduler stopped\")\n76 +\n77 +    def get_task_status(self, task_id: str) -> dict | None:\n78 +        task = self.tasks.get(task_id)\n79 +        if not task:\n80 +            return None\n81 +        return {\n82 +            \"id\": task.id,\n83 +            \"name\": task.name,\n84 +            \"is_running\": task.is_running,\n85 +            \"run_count\": task.run_count,\n86 +            \"last_run\": task.last_run.isoformat() if task.last_run else None\n87 +        }\n88 +\n89 +\n90 +def create_scheduled_tasks(scheduler: TaskScheduler, task_configs: list[dict]):\n91 +    callbacks = []\n92 +\n93 +    for config in task_configs:\n94 +        async def task_callback():\n95 +            logger.info(f\"Executing task: {config['name']}\")\n96 +            await asyncio.sleep(0.1)\n97 +\n98 +        callbacks.append(task_callback)\n99 +\n100 +        scheduler.add_task(\n101 +            task_id=config[\"id\"],\n102 +            name=config[\"name\"],\n103 +            callback=task_callback,\n104 +            interval_seconds=config[\"interval\"]\n105 +        )\n106 +\n107 +\n108 +async def run_parallel_tasks(tasks: list[Callable[[], Awaitable[None]]]):\n109 +    handles = []\n110 +    for i, task in enumerate(tasks):\n111 +        handle = asyncio.create_task(task())\n112 +        handles.append(handle)\n113 +\n114 +    await asyncio.gather(*handles)\n115 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/workers/task_scheduler.py\",\"relevantLinesStart\":87,\"relevantLinesEnd\":90}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"for config in task_configs:\\n        async def task_callback():\\n            logger.info(f\\\"Executing task: {config['name']}\\\")\\n            await asyncio.sleep(0.1)\",\n    \"improvedCode\": \"for config in task_configs:\\n        async def task_callback(cfg=config):  # Capture by default argument\\n            logger.info(f\\\"Executing task: {cfg['name']}\\\")\\n            await asyncio.sleep(0.1)\",\n    \"relevantFile\": \"src/workers/task_scheduler.py\",\n    \"relevantLinesEnd\": 90,\n    \"suggestionContent\": \"The `create_scheduled_tasks` function has a late binding closure bug. The `task_callback` function captures the variable `config` by reference, not by value. By the time any callback executes, the loop has finished and `config` refers to the last item in `task_configs`. All tasks will log the same name (the last config's name).\",\n    \"oneSentenceSummary\": \"Late binding closure captures loop variable by reference - all callbacks use last value\",\n    \"relevantLinesStart\": 87\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 30: src/cache/memory_cache.py",
    "vars": {
      "fileContent": "from datetime import datetime, timedelta\nfrom typing import Any, Generic, TypeVar\nfrom dataclasses import dataclass\nimport threading\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\nCACHE_MISS = object()\n\n\n@dataclass\nclass CacheEntry(Generic[T]):\n    value: T\n    expires_at: datetime | None\n    created_at: datetime\n    access_count: int = 0\n\n\nclass MemoryCache(Generic[T]):\n    def __init__(self, default_ttl_seconds: int = 300):\n        self._store: dict[str, CacheEntry[T]] = {}\n        self._default_ttl = default_ttl_seconds\n        self._lock = threading.RLock()\n        self._stats = {\"hits\": 0, \"misses\": 0}\n\n    def get(self, key: str, default: T = None) -> T | None:\n        with self._lock:\n            entry = self._store.get(key)\n\n            if entry is None:\n                self._stats[\"misses\"] += 1\n                return default\n\n            if entry.expires_at and datetime.now() > entry.expires_at:\n                del self._store[key]\n                self._stats[\"misses\"] += 1\n                return default\n\n            entry.access_count += 1\n            self._stats[\"hits\"] += 1\n            return entry.value\n\n    def set(\n        self,\n        key: str,\n        value: T,\n        ttl_seconds: int | None = None\n    ) -> None:\n        with self._lock:\n            ttl = ttl_seconds if ttl_seconds is not None else self._default_ttl\n            expires_at = datetime.now() + timedelta(seconds=ttl) if ttl else None\n\n            self._store[key] = CacheEntry(\n                value=value,\n                expires_at=expires_at,\n                created_at=datetime.now()\n            )\n\n    def delete(self, key: str) -> bool:\n        with self._lock:\n            if key in self._store:\n                del self._store[key]\n                return True\n            return False\n\n    def clear(self) -> int:\n        with self._lock:\n            count = len(self._store)\n            self._store.clear()\n            return count\n\n    def get_stats(self) -> dict:\n        return self._stats.copy()\n\n\nclass CacheManager:\n    def __init__(self):\n        self._caches: dict[str, MemoryCache] = {}\n\n    def get_cache(self, namespace: str) -> MemoryCache:\n        if namespace not in self._caches:\n            self._caches[namespace] = MemoryCache()\n        return self._caches[namespace]\n\n    def get_or_compute(\n        self,\n        namespace: str,\n        key: str,\n        compute_fn,\n        ttl_seconds: int = 300\n    ) -> Any:\n        cache = self.get_cache(namespace)\n        value = cache.get(key, default=CACHE_MISS)\n\n        if value is CACHE_MISS:\n            value = compute_fn()\n            cache.set(key, value, ttl_seconds)\n\n        return value\n\n    def invalidate_namespace(self, namespace: str) -> int:\n        if namespace in self._caches:\n            return self._caches[namespace].clear()\n        return 0\n\n\ndef cached_result(key: str, result: Any, expected: Any) -> bool:\n    if result is None and expected is None:\n        return True\n    if result is expected:\n        return True\n    return result == expected\n\n\ndef check_cache_value(cache: MemoryCache, key: str, expected_value: int) -> bool:\n    value = cache.get(key)\n    if value is expected_value:\n        return True\n    if value is None:\n        return False\n    return value == expected_value\n",
      "patchWithLinesStr": "## file: 'src/cache/memory_cache.py'\n\n@@ -0,0 +1,125 @@\n__new hunk__\n1 +from datetime import datetime, timedelta\n2 +from typing import Any, Generic, TypeVar\n3 +from dataclasses import dataclass\n4 +import threading\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +T = TypeVar(\"T\")\n10 +\n11 +CACHE_MISS = object()\n12 +\n13 +\n14 +@dataclass\n15 +class CacheEntry(Generic[T]):\n16 +    value: T\n17 +    expires_at: datetime | None\n18 +    created_at: datetime\n19 +    access_count: int = 0\n20 +\n21 +\n22 +class MemoryCache(Generic[T]):\n23 +    def __init__(self, default_ttl_seconds: int = 300):\n24 +        self._store: dict[str, CacheEntry[T]] = {}\n25 +        self._default_ttl = default_ttl_seconds\n26 +        self._lock = threading.RLock()\n27 +        self._stats = {\"hits\": 0, \"misses\": 0}\n28 +\n29 +    def get(self, key: str, default: T = None) -> T | None:\n30 +        with self._lock:\n31 +            entry = self._store.get(key)\n32 +\n33 +            if entry is None:\n34 +                self._stats[\"misses\"] += 1\n35 +                return default\n36 +\n37 +            if entry.expires_at and datetime.now() > entry.expires_at:\n38 +                del self._store[key]\n39 +                self._stats[\"misses\"] += 1\n40 +                return default\n41 +\n42 +            entry.access_count += 1\n43 +            self._stats[\"hits\"] += 1\n44 +            return entry.value\n45 +\n46 +    def set(\n47 +        self,\n48 +        key: str,\n49 +        value: T,\n50 +        ttl_seconds: int | None = None\n51 +    ) -> None:\n52 +        with self._lock:\n53 +            ttl = ttl_seconds if ttl_seconds is not None else self._default_ttl\n54 +            expires_at = datetime.now() + timedelta(seconds=ttl) if ttl else None\n55 +\n56 +            self._store[key] = CacheEntry(\n57 +                value=value,\n58 +                expires_at=expires_at,\n59 +                created_at=datetime.now()\n60 +            )\n61 +\n62 +    def delete(self, key: str) -> bool:\n63 +        with self._lock:\n64 +            if key in self._store:\n65 +                del self._store[key]\n66 +                return True\n67 +            return False\n68 +\n69 +    def clear(self) -> int:\n70 +        with self._lock:\n71 +            count = len(self._store)\n72 +            self._store.clear()\n73 +            return count\n74 +\n75 +    def get_stats(self) -> dict:\n76 +        return self._stats.copy()\n77 +\n78 +\n79 +class CacheManager:\n80 +    def __init__(self):\n81 +        self._caches: dict[str, MemoryCache] = {}\n82 +\n83 +    def get_cache(self, namespace: str) -> MemoryCache:\n84 +        if namespace not in self._caches:\n85 +            self._caches[namespace] = MemoryCache()\n86 +        return self._caches[namespace]\n87 +\n88 +    def get_or_compute(\n89 +        self,\n90 +        namespace: str,\n91 +        key: str,\n92 +        compute_fn,\n93 +        ttl_seconds: int = 300\n94 +    ) -> Any:\n95 +        cache = self.get_cache(namespace)\n96 +        value = cache.get(key, default=CACHE_MISS)\n97 +\n98 +        if value is CACHE_MISS:\n99 +            value = compute_fn()\n100 +            cache.set(key, value, ttl_seconds)\n101 +\n102 +        return value\n103 +\n104 +    def invalidate_namespace(self, namespace: str) -> int:\n105 +        if namespace in self._caches:\n106 +            return self._caches[namespace].clear()\n107 +        return 0\n108 +\n109 +\n110 +def cached_result(key: str, result: Any, expected: Any) -> bool:\n111 +    if result is None and expected is None:\n112 +        return True\n113 +    if result is expected:\n114 +        return True\n115 +    return result == expected\n116 +\n117 +\n118 +def check_cache_value(cache: MemoryCache, key: str, expected_value: int) -> bool:\n119 +    value = cache.get(key)\n120 +    if value is expected_value:\n121 +        return True\n122 +    if value is None:\n123 +        return False\n124 +    return value == expected_value\n125 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/cache/memory_cache.py\",\"relevantLinesStart\":108,\"relevantLinesEnd\":114}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def check_cache_value(cache: MemoryCache, key: str, expected_value: int) -> bool:\\n    value = cache.get(key)\\n    if value is expected_value:\\n        return True\\n    if value is None:\\n        return False\\n    return value == expected_value\",\n    \"improvedCode\": \"def check_cache_value(cache: MemoryCache, key: str, expected_value: int) -> bool:\\n    value = cache.get(key)\\n    if value is None:\\n        return expected_value is None\\n    return value == expected_value\",\n    \"relevantFile\": \"src/cache/memory_cache.py\",\n    \"relevantLinesEnd\": 114,\n    \"suggestionContent\": \"The `check_cache_value` function uses `is` to compare integer values (`value is expected_value`). In Python, `is` checks object identity, not equality. While small integers (-5 to 256) are cached and `is` may work, larger integers create new objects and `is` will return `False` even when values are equal. Use `==` for value comparison.\",\n    \"oneSentenceSummary\": \"Using 'is' instead of '==' for integer comparison fails for values outside -5 to 256\",\n    \"relevantLinesStart\": 108\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 31: src/http/http_client.py",
    "vars": {
      "fileContent": "import urllib.request\nimport urllib.parse\nimport json\nimport ssl\nfrom typing import Any\nfrom dataclasses import dataclass\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass HttpResponse:\n    status: int\n    body: str\n    headers: dict[str, str]\n\n\nclass HttpClient:\n    def __init__(self, base_url: str = \"\", timeout: int = 30):\n        self.base_url = base_url\n        self.timeout = timeout\n        self.default_headers = {\n            \"User-Agent\": \"Python HttpClient/1.0\",\n            \"Accept\": \"application/json\",\n        }\n\n    def _create_context(self) -> ssl.SSLContext:\n        context = ssl.create_default_context()\n        context.check_hostname = False\n        context.verify_mode = ssl.CERT_NONE\n        return context\n\n    def get(self, url: str, params: dict = None, headers: dict = None) -> HttpResponse:\n        full_url = self.base_url + url\n\n        if params:\n            query_string = urllib.parse.urlencode(params)\n            full_url = f\"{full_url}?{query_string}\"\n\n        return self._request(\"GET\", full_url, headers=headers)\n\n    def post(self, url: str, data: Any = None, headers: dict = None) -> HttpResponse:\n        full_url = self.base_url + url\n        return self._request(\"POST\", full_url, data=data, headers=headers)\n\n    def _request(\n        self,\n        method: str,\n        url: str,\n        data: Any = None,\n        headers: dict = None\n    ) -> HttpResponse:\n        all_headers = {**self.default_headers, **(headers or {})}\n\n        body = None\n        if data is not None:\n            if isinstance(data, dict):\n                body = json.dumps(data).encode(\"utf-8\")\n                all_headers[\"Content-Type\"] = \"application/json\"\n            elif isinstance(data, str):\n                body = data.encode(\"utf-8\")\n            else:\n                body = data\n\n        request = urllib.request.Request(\n            url,\n            data=body,\n            headers=all_headers,\n            method=method\n        )\n\n        try:\n            context = self._create_context()\n            response = urllib.request.urlopen(\n                request,\n                timeout=self.timeout,\n                context=context\n            )\n\n            return HttpResponse(\n                status=response.status,\n                body=response.read().decode(\"utf-8\"),\n                headers=dict(response.headers)\n            )\n        except urllib.error.HTTPError as e:\n            return HttpResponse(\n                status=e.code,\n                body=e.read().decode(\"utf-8\"),\n                headers=dict(e.headers)\n            )\n\n\ndef fetch_json(url: str) -> dict:\n    client = HttpClient()\n    response = client.get(url)\n    return json.loads(response.body)\n\n\ndef make_api_call(endpoint: str, api_key: str) -> dict:\n    url = f\"https://api.example.com{endpoint}\"\n    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n\n    client = HttpClient()\n    response = client.get(url, headers=headers)\n\n    if response.status >= 400:\n        raise Exception(f\"API error: {response.status}\")\n\n    return json.loads(response.body)\n",
      "patchWithLinesStr": "## file: 'src/http/http_client.py'\n\n@@ -0,0 +1,111 @@\n__new hunk__\n1 +import urllib.request\n2 +import urllib.parse\n3 +import json\n4 +import ssl\n5 +from typing import Any\n6 +from dataclasses import dataclass\n7 +import logging\n8 +\n9 +logger = logging.getLogger(__name__)\n10 +\n11 +\n12 +@dataclass\n13 +class HttpResponse:\n14 +    status: int\n15 +    body: str\n16 +    headers: dict[str, str]\n17 +\n18 +\n19 +class HttpClient:\n20 +    def __init__(self, base_url: str = \"\", timeout: int = 30):\n21 +        self.base_url = base_url\n22 +        self.timeout = timeout\n23 +        self.default_headers = {\n24 +            \"User-Agent\": \"Python HttpClient/1.0\",\n25 +            \"Accept\": \"application/json\",\n26 +        }\n27 +\n28 +    def _create_context(self) -> ssl.SSLContext:\n29 +        context = ssl.create_default_context()\n30 +        context.check_hostname = False\n31 +        context.verify_mode = ssl.CERT_NONE\n32 +        return context\n33 +\n34 +    def get(self, url: str, params: dict = None, headers: dict = None) -> HttpResponse:\n35 +        full_url = self.base_url + url\n36 +\n37 +        if params:\n38 +            query_string = urllib.parse.urlencode(params)\n39 +            full_url = f\"{full_url}?{query_string}\"\n40 +\n41 +        return self._request(\"GET\", full_url, headers=headers)\n42 +\n43 +    def post(self, url: str, data: Any = None, headers: dict = None) -> HttpResponse:\n44 +        full_url = self.base_url + url\n45 +        return self._request(\"POST\", full_url, data=data, headers=headers)\n46 +\n47 +    def _request(\n48 +        self,\n49 +        method: str,\n50 +        url: str,\n51 +        data: Any = None,\n52 +        headers: dict = None\n53 +    ) -> HttpResponse:\n54 +        all_headers = {**self.default_headers, **(headers or {})}\n55 +\n56 +        body = None\n57 +        if data is not None:\n58 +            if isinstance(data, dict):\n59 +                body = json.dumps(data).encode(\"utf-8\")\n60 +                all_headers[\"Content-Type\"] = \"application/json\"\n61 +            elif isinstance(data, str):\n62 +                body = data.encode(\"utf-8\")\n63 +            else:\n64 +                body = data\n65 +\n66 +        request = urllib.request.Request(\n67 +            url,\n68 +            data=body,\n69 +            headers=all_headers,\n70 +            method=method\n71 +        )\n72 +\n73 +        try:\n74 +            context = self._create_context()\n75 +            response = urllib.request.urlopen(\n76 +                request,\n77 +                timeout=self.timeout,\n78 +                context=context\n79 +            )\n80 +\n81 +            return HttpResponse(\n82 +                status=response.status,\n83 +                body=response.read().decode(\"utf-8\"),\n84 +                headers=dict(response.headers)\n85 +            )\n86 +        except urllib.error.HTTPError as e:\n87 +            return HttpResponse(\n88 +                status=e.code,\n89 +                body=e.read().decode(\"utf-8\"),\n90 +                headers=dict(e.headers)\n91 +            )\n92 +\n93 +\n94 +def fetch_json(url: str) -> dict:\n95 +    client = HttpClient()\n96 +    response = client.get(url)\n97 +    return json.loads(response.body)\n98 +\n99 +\n100 +def make_api_call(endpoint: str, api_key: str) -> dict:\n101 +    url = f\"https://api.example.com{endpoint}\"\n102 +    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n103 +\n104 +    client = HttpClient()\n105 +    response = client.get(url, headers=headers)\n106 +\n107 +    if response.status >= 400:\n108 +        raise Exception(f\"API error: {response.status}\")\n109 +\n110 +    return json.loads(response.body)\n111 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/http/http_client.py\",\"relevantLinesStart\":28,\"relevantLinesEnd\":32},{\"relevantFile\":\"src/http/http_client.py\",\"relevantLinesStart\":34,\"relevantLinesEnd\":35}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def _create_context(self) -> ssl.SSLContext:\\n        context = ssl.create_default_context()\\n        context.check_hostname = False\\n        context.verify_mode = ssl.CERT_NONE\\n        return context\",\n    \"improvedCode\": \"def _create_context(self) -> ssl.SSLContext:\\n        # Use default secure context, don't disable verification\\n        return ssl.create_default_context()\",\n    \"relevantFile\": \"src/http/http_client.py\",\n    \"relevantLinesEnd\": 32,\n    \"suggestionContent\": \"The `_create_context` method disables SSL certificate verification with `context.check_hostname = False` and `context.verify_mode = ssl.CERT_NONE`. This makes the application vulnerable to man-in-the-middle attacks where an attacker can intercept and modify HTTPS traffic. Never disable SSL verification in production code.\",\n    \"oneSentenceSummary\": \"SSL verification disabled - vulnerable to man-in-the-middle attacks\",\n    \"relevantLinesStart\": 28\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def get(self, url: str, params: dict = None, headers: dict = None) -> HttpResponse:\\n        full_url = self.base_url + url\",\n    \"improvedCode\": \"def get(self, url: str, params: dict = None, headers: dict = None) -> HttpResponse:\\n        full_url = self.base_url + url\\n        parsed = urllib.parse.urlparse(full_url)\\n        # Block private/internal IPs\\n        if parsed.hostname in ('localhost', '127.0.0.1') or parsed.hostname.startswith('192.168.'):\\n            raise ValueError(\\\"Access to internal URLs is not allowed\\\")\",\n    \"relevantFile\": \"src/http/http_client.py\",\n    \"relevantLinesEnd\": 35,\n    \"suggestionContent\": \"The client doesn't validate or sanitize URLs before making requests. If `url` parameter comes from user input, an attacker could cause SSRF (Server-Side Request Forgery) by providing URLs to internal services like `http://localhost:8080/admin` or `http://169.254.169.254/` (AWS metadata).\",\n    \"oneSentenceSummary\": \"No URL validation enables SSRF attacks to internal services\",\n    \"relevantLinesStart\": 34\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 32: src/pagination/paginator.py",
    "vars": {
      "fileContent": "from typing import TypeVar, Generic, Sequence\nfrom dataclasses import dataclass\nimport math\n\nT = TypeVar(\"T\")\n\n\n@dataclass\nclass Page(Generic[T]):\n    items: list[T]\n    page: int\n    page_size: int\n    total_items: int\n    total_pages: int\n    has_next: bool\n    has_previous: bool\n\n\nclass Paginator(Generic[T]):\n    def __init__(self, items: Sequence[T], page_size: int = 20):\n        self.items = items\n        self.page_size = page_size\n        self.total_items = len(items)\n        self.total_pages = math.ceil(self.total_items / page_size)\n\n    def get_page(self, page: int) -> Page[T]:\n        if page < 1:\n            page = 1\n        if page > self.total_pages:\n            page = self.total_pages\n\n        start = (page - 1) * self.page_size\n        end = start + self.page_size\n\n        return Page(\n            items=list(self.items[start:end]),\n            page=page,\n            page_size=self.page_size,\n            total_items=self.total_items,\n            total_pages=self.total_pages,\n            has_next=page < self.total_pages,\n            has_previous=page > 1\n        )\n\n    def get_offset_page(self, offset: int, limit: int) -> Page[T]:\n        if offset < 0:\n            offset = 0\n\n        page_num = (offset // limit) + 1\n\n        return Page(\n            items=list(self.items[offset:offset + limit]),\n            page=page_num,\n            page_size=limit,\n            total_items=self.total_items,\n            total_pages=math.ceil(self.total_items / limit),\n            has_next=offset + limit < self.total_items,\n            has_previous=offset > 0\n        )\n\n\ndef paginate_query(query_fn, page: int, page_size: int) -> Page:\n    offset = (page - 1) * page_size\n\n    items = query_fn(offset=offset, limit=page_size + 1)\n\n    has_next = len(items) > page_size\n    if has_next:\n        items = items[:page_size]\n\n    return Page(\n        items=items,\n        page=page,\n        page_size=page_size,\n        total_items=-1,\n        total_pages=-1,\n        has_next=has_next,\n        has_previous=page > 1\n    )\n\n\ndef calculate_range(start: int, end: int, step: int) -> list[int]:\n    if step == 0:\n        return []\n\n    result = []\n    current = start\n    while current < end:\n        result.append(current)\n        current += step\n\n    return result\n\n\ndef safe_divide_pages(total: int, per_page: int) -> int:\n    if per_page <= 0:\n        return 0\n    return (total + per_page - 1) // per_page\n",
      "patchWithLinesStr": "## file: 'src/pagination/paginator.py'\n\n@@ -0,0 +1,99 @@\n__new hunk__\n1 +from typing import TypeVar, Generic, Sequence\n2 +from dataclasses import dataclass\n3 +import math\n4 +\n5 +T = TypeVar(\"T\")\n6 +\n7 +\n8 +@dataclass\n9 +class Page(Generic[T]):\n10 +    items: list[T]\n11 +    page: int\n12 +    page_size: int\n13 +    total_items: int\n14 +    total_pages: int\n15 +    has_next: bool\n16 +    has_previous: bool\n17 +\n18 +\n19 +class Paginator(Generic[T]):\n20 +    def __init__(self, items: Sequence[T], page_size: int = 20):\n21 +        self.items = items\n22 +        self.page_size = page_size\n23 +        self.total_items = len(items)\n24 +        self.total_pages = math.ceil(self.total_items / page_size)\n25 +\n26 +    def get_page(self, page: int) -> Page[T]:\n27 +        if page < 1:\n28 +            page = 1\n29 +        if page > self.total_pages:\n30 +            page = self.total_pages\n31 +\n32 +        start = (page - 1) * self.page_size\n33 +        end = start + self.page_size\n34 +\n35 +        return Page(\n36 +            items=list(self.items[start:end]),\n37 +            page=page,\n38 +            page_size=self.page_size,\n39 +            total_items=self.total_items,\n40 +            total_pages=self.total_pages,\n41 +            has_next=page < self.total_pages,\n42 +            has_previous=page > 1\n43 +        )\n44 +\n45 +    def get_offset_page(self, offset: int, limit: int) -> Page[T]:\n46 +        if offset < 0:\n47 +            offset = 0\n48 +\n49 +        page_num = (offset // limit) + 1\n50 +\n51 +        return Page(\n52 +            items=list(self.items[offset:offset + limit]),\n53 +            page=page_num,\n54 +            page_size=limit,\n55 +            total_items=self.total_items,\n56 +            total_pages=math.ceil(self.total_items / limit),\n57 +            has_next=offset + limit < self.total_items,\n58 +            has_previous=offset > 0\n59 +        )\n60 +\n61 +\n62 +def paginate_query(query_fn, page: int, page_size: int) -> Page:\n63 +    offset = (page - 1) * page_size\n64 +\n65 +    items = query_fn(offset=offset, limit=page_size + 1)\n66 +\n67 +    has_next = len(items) > page_size\n68 +    if has_next:\n69 +        items = items[:page_size]\n70 +\n71 +    return Page(\n72 +        items=items,\n73 +        page=page,\n74 +        page_size=page_size,\n75 +        total_items=-1,\n76 +        total_pages=-1,\n77 +        has_next=has_next,\n78 +        has_previous=page > 1\n79 +    )\n80 +\n81 +\n82 +def calculate_range(start: int, end: int, step: int) -> list[int]:\n83 +    if step == 0:\n84 +        return []\n85 +\n86 +    result = []\n87 +    current = start\n88 +    while current < end:\n89 +        result.append(current)\n90 +        current += step\n91 +\n92 +    return result\n93 +\n94 +\n95 +def safe_divide_pages(total: int, per_page: int) -> int:\n96 +    if per_page <= 0:\n97 +        return 0\n98 +    return (total + per_page - 1) // per_page\n99 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/pagination/paginator.py\",\"relevantLinesStart\":28,\"relevantLinesEnd\":31}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"if page > self.total_pages:\\n            page = self.total_pages\\n\\n        start = (page - 1) * self.page_size\",\n    \"improvedCode\": \"if self.total_pages == 0:\\n            return Page(items=[], page=1, page_size=self.page_size,\\n                       total_items=0, total_pages=0, has_next=False, has_previous=False)\\n        if page > self.total_pages:\\n            page = self.total_pages\\n\\n        start = (page - 1) * self.page_size\",\n    \"relevantFile\": \"src/pagination/paginator.py\",\n    \"relevantLinesEnd\": 31,\n    \"suggestionContent\": \"The `get_page` method doesn't handle the case when `total_pages` is 0 (empty list). When `total_items` is 0, `total_pages` is 0, and the line `if page > self.total_pages` sets page to 0. Then `start = (0 - 1) * page_size` becomes negative, causing unexpected behavior with slice indexing.\",\n    \"oneSentenceSummary\": \"Empty list causes page=0 leading to negative start index in pagination\",\n    \"relevantLinesStart\": 28\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 33: src/resources/resource_manager.py",
    "vars": {
      "fileContent": "from typing import TypeVar, Generic, Callable\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nimport threading\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\n\n@dataclass\nclass Resource(Generic[T]):\n    value: T\n    is_acquired: bool = False\n    acquired_by: str | None = None\n\n\nclass ResourcePool(Generic[T]):\n    def __init__(self, factory: Callable[[], T], max_size: int = 10):\n        self.factory = factory\n        self.max_size = max_size\n        self._available: list[Resource[T]] = []\n        self._in_use: list[Resource[T]] = []\n        self._lock = threading.Lock()\n\n    def acquire(self, owner: str = \"unknown\") -> Resource[T]:\n        with self._lock:\n            if self._available:\n                resource = self._available.pop()\n            elif len(self._in_use) < self.max_size:\n                resource = Resource(value=self.factory())\n            else:\n                raise RuntimeError(\"Resource pool exhausted\")\n\n            resource.is_acquired = True\n            resource.acquired_by = owner\n            self._in_use.append(resource)\n\n            return resource\n\n    def release(self, resource: Resource[T]):\n        with self._lock:\n            if resource in self._in_use:\n                self._in_use.remove(resource)\n                resource.is_acquired = False\n                resource.acquired_by = None\n                self._available.append(resource)\n\n    @contextmanager\n    def get_resource(self, owner: str = \"unknown\"):\n        resource = self.acquire(owner)\n        yield resource.value\n        self.release(resource)\n\n    def get_stats(self) -> dict:\n        return {\n            \"available\": len(self._available),\n            \"in_use\": len(self._in_use),\n            \"max_size\": self.max_size\n        }\n\n\nclass FileHandler:\n    def __init__(self, filepath: str):\n        self.filepath = filepath\n        self.file = None\n\n    def open(self, mode: str = \"r\"):\n        self.file = open(self.filepath, mode)\n        return self\n\n    def read(self) -> str:\n        return self.file.read()\n\n    def write(self, content: str):\n        self.file.write(content)\n\n    def close(self):\n        if self.file:\n            self.file.close()\n\n    def __enter__(self):\n        return self.open()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n\n\nclass DatabaseConnection:\n    def __init__(self, connection_string: str):\n        self.connection_string = connection_string\n        self.is_connected = False\n        self._transaction_active = False\n\n    def connect(self):\n        logger.info(f\"Connecting to {self.connection_string}\")\n        self.is_connected = True\n        return self\n\n    def disconnect(self):\n        if self._transaction_active:\n            self.rollback()\n        self.is_connected = False\n        logger.info(\"Disconnected\")\n\n    def begin_transaction(self):\n        self._transaction_active = True\n\n    def commit(self):\n        self._transaction_active = False\n        logger.info(\"Transaction committed\")\n\n    def rollback(self):\n        self._transaction_active = False\n        logger.info(\"Transaction rolled back\")\n\n    def __enter__(self):\n        return self.connect()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.disconnect()\n\n\n@contextmanager\ndef managed_transaction(connection: DatabaseConnection):\n    connection.begin_transaction()\n    yield connection\n    connection.commit()\n",
      "patchWithLinesStr": "## file: 'src/resources/resource_manager.py'\n\n@@ -0,0 +1,130 @@\n__new hunk__\n1 +from typing import TypeVar, Generic, Callable\n2 +from contextlib import contextmanager\n3 +from dataclasses import dataclass\n4 +import threading\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +T = TypeVar(\"T\")\n10 +\n11 +\n12 +@dataclass\n13 +class Resource(Generic[T]):\n14 +    value: T\n15 +    is_acquired: bool = False\n16 +    acquired_by: str | None = None\n17 +\n18 +\n19 +class ResourcePool(Generic[T]):\n20 +    def __init__(self, factory: Callable[[], T], max_size: int = 10):\n21 +        self.factory = factory\n22 +        self.max_size = max_size\n23 +        self._available: list[Resource[T]] = []\n24 +        self._in_use: list[Resource[T]] = []\n25 +        self._lock = threading.Lock()\n26 +\n27 +    def acquire(self, owner: str = \"unknown\") -> Resource[T]:\n28 +        with self._lock:\n29 +            if self._available:\n30 +                resource = self._available.pop()\n31 +            elif len(self._in_use) < self.max_size:\n32 +                resource = Resource(value=self.factory())\n33 +            else:\n34 +                raise RuntimeError(\"Resource pool exhausted\")\n35 +\n36 +            resource.is_acquired = True\n37 +            resource.acquired_by = owner\n38 +            self._in_use.append(resource)\n39 +\n40 +            return resource\n41 +\n42 +    def release(self, resource: Resource[T]):\n43 +        with self._lock:\n44 +            if resource in self._in_use:\n45 +                self._in_use.remove(resource)\n46 +                resource.is_acquired = False\n47 +                resource.acquired_by = None\n48 +                self._available.append(resource)\n49 +\n50 +    @contextmanager\n51 +    def get_resource(self, owner: str = \"unknown\"):\n52 +        resource = self.acquire(owner)\n53 +        yield resource.value\n54 +        self.release(resource)\n55 +\n56 +    def get_stats(self) -> dict:\n57 +        return {\n58 +            \"available\": len(self._available),\n59 +            \"in_use\": len(self._in_use),\n60 +            \"max_size\": self.max_size\n61 +        }\n62 +\n63 +\n64 +class FileHandler:\n65 +    def __init__(self, filepath: str):\n66 +        self.filepath = filepath\n67 +        self.file = None\n68 +\n69 +    def open(self, mode: str = \"r\"):\n70 +        self.file = open(self.filepath, mode)\n71 +        return self\n72 +\n73 +    def read(self) -> str:\n74 +        return self.file.read()\n75 +\n76 +    def write(self, content: str):\n77 +        self.file.write(content)\n78 +\n79 +    def close(self):\n80 +        if self.file:\n81 +            self.file.close()\n82 +\n83 +    def __enter__(self):\n84 +        return self.open()\n85 +\n86 +    def __exit__(self, exc_type, exc_val, exc_tb):\n87 +        self.close()\n88 +\n89 +\n90 +class DatabaseConnection:\n91 +    def __init__(self, connection_string: str):\n92 +        self.connection_string = connection_string\n93 +        self.is_connected = False\n94 +        self._transaction_active = False\n95 +\n96 +    def connect(self):\n97 +        logger.info(f\"Connecting to {self.connection_string}\")\n98 +        self.is_connected = True\n99 +        return self\n100 +\n101 +    def disconnect(self):\n102 +        if self._transaction_active:\n103 +            self.rollback()\n104 +        self.is_connected = False\n105 +        logger.info(\"Disconnected\")\n106 +\n107 +    def begin_transaction(self):\n108 +        self._transaction_active = True\n109 +\n110 +    def commit(self):\n111 +        self._transaction_active = False\n112 +        logger.info(\"Transaction committed\")\n113 +\n114 +    def rollback(self):\n115 +        self._transaction_active = False\n116 +        logger.info(\"Transaction rolled back\")\n117 +\n118 +    def __enter__(self):\n119 +        return self.connect()\n120 +\n121 +    def __exit__(self, exc_type, exc_val, exc_tb):\n122 +        self.disconnect()\n123 +\n124 +\n125 +@contextmanager\n126 +def managed_transaction(connection: DatabaseConnection):\n127 +    connection.begin_transaction()\n128 +    yield connection\n129 +    connection.commit()\n130 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/resources/resource_manager.py\",\"relevantLinesStart\":47,\"relevantLinesEnd\":51},{\"relevantFile\":\"src/resources/resource_manager.py\",\"relevantLinesStart\":118,\"relevantLinesEnd\":122}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"@contextmanager\\n    def get_resource(self, owner: str = \\\"unknown\\\"):\\n        resource = self.acquire(owner)\\n        yield resource.value\\n        self.release(resource)\",\n    \"improvedCode\": \"@contextmanager\\n    def get_resource(self, owner: str = \\\"unknown\\\"):\\n        resource = self.acquire(owner)\\n        try:\\n            yield resource.value\\n        finally:\\n            self.release(resource)\",\n    \"relevantFile\": \"src/resources/resource_manager.py\",\n    \"relevantLinesEnd\": 51,\n    \"suggestionContent\": \"The `get_resource` context manager doesn't handle exceptions. If code inside the `with` block raises an exception, `release()` is never called, causing the resource to leak from the pool. Use try/finally to ensure cleanup.\",\n    \"oneSentenceSummary\": \"Context manager doesn't release resource on exception - causes pool leaks\",\n    \"relevantLinesStart\": 47\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"@contextmanager\\ndef managed_transaction(connection: DatabaseConnection):\\n    connection.begin_transaction()\\n    yield connection\\n    connection.commit()\",\n    \"improvedCode\": \"@contextmanager\\ndef managed_transaction(connection: DatabaseConnection):\\n    connection.begin_transaction()\\n    try:\\n        yield connection\\n        connection.commit()\\n    except Exception:\\n        connection.rollback()\\n        raise\",\n    \"relevantFile\": \"src/resources/resource_manager.py\",\n    \"relevantLinesEnd\": 122,\n    \"suggestionContent\": \"The `managed_transaction` context manager always calls `commit()` even if an exception occurred. It should call `rollback()` on exception and only `commit()` on success. Also doesn't re-raise the exception properly.\",\n    \"oneSentenceSummary\": \"Transaction commits even on exception instead of rolling back\",\n    \"relevantLinesStart\": 118\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 34: src/validation/input_validator.py",
    "vars": {
      "fileContent": "import re\nfrom typing import Optional\nfrom dataclasses import dataclass\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ValidationResult:\n    is_valid: bool\n    error: str | None = None\n\n\nEMAIL_PATTERN = re.compile(\n    r\"^([a-zA-Z0-9_\\-\\.]+)+@(([a-zA-Z0-9\\-])+\\.)+([a-zA-Z]{2,})+$\"\n)\n\nURL_PATTERN = re.compile(\n    r\"^(https?:\\/\\/)?([\\w\\-]+\\.)+[\\w\\-]+(\\/[\\w\\-\\.~!$&'()*+,;=:@%]*)*\\/?$\"\n)\n\nSLUG_PATTERN = re.compile(r\"^[a-z0-9]+(-[a-z0-9]+)*$\")\n\nPASSWORD_PATTERN = re.compile(\n    r\"^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[@$!%*?&])[A-Za-z\\d@$!%*?&]{8,}$\"\n)\n\n\ndef validate_email(email: str) -> ValidationResult:\n    if not email:\n        return ValidationResult(False, \"Email is required\")\n\n    if len(email) > 254:\n        return ValidationResult(False, \"Email too long\")\n\n    if EMAIL_PATTERN.match(email):\n        return ValidationResult(True)\n\n    return ValidationResult(False, \"Invalid email format\")\n\n\ndef validate_url(url: str) -> ValidationResult:\n    if not url:\n        return ValidationResult(False, \"URL is required\")\n\n    if URL_PATTERN.match(url):\n        return ValidationResult(True)\n\n    return ValidationResult(False, \"Invalid URL format\")\n\n\ndef validate_slug(slug: str) -> ValidationResult:\n    if not slug:\n        return ValidationResult(False, \"Slug is required\")\n\n    if len(slug) > 100:\n        return ValidationResult(False, \"Slug too long\")\n\n    if SLUG_PATTERN.match(slug):\n        return ValidationResult(True)\n\n    return ValidationResult(False, \"Invalid slug format\")\n\n\ndef validate_password(password: str) -> ValidationResult:\n    if not password:\n        return ValidationResult(False, \"Password is required\")\n\n    if len(password) < 8:\n        return ValidationResult(False, \"Password must be at least 8 characters\")\n\n    if PASSWORD_PATTERN.match(password):\n        return ValidationResult(True)\n\n    return ValidationResult(False, \"Password must contain uppercase, lowercase, number and special character\")\n\n\nclass InputValidator:\n    def __init__(self):\n        self.custom_patterns: dict[str, re.Pattern] = {}\n\n    def add_pattern(self, name: str, pattern: str):\n        self.custom_patterns[name] = re.compile(pattern)\n\n    def validate(self, name: str, value: str) -> ValidationResult:\n        pattern = self.custom_patterns.get(name)\n        if not pattern:\n            return ValidationResult(False, f\"Unknown validator: {name}\")\n\n        if pattern.match(value):\n            return ValidationResult(True)\n\n        return ValidationResult(False, f\"Value does not match {name} pattern\")\n\n    def validate_all(self, data: dict[str, str], validators: dict[str, str]) -> dict[str, ValidationResult]:\n        results = {}\n        for field, validator_name in validators.items():\n            value = data.get(field, \"\")\n            results[field] = self.validate(validator_name, value)\n        return results\n",
      "patchWithLinesStr": "## file: 'src/validation/input_validator.py'\n\n@@ -0,0 +1,102 @@\n__new hunk__\n1 +import re\n2 +from typing import Optional\n3 +from dataclasses import dataclass\n4 +import logging\n5 +\n6 +logger = logging.getLogger(__name__)\n7 +\n8 +\n9 +@dataclass\n10 +class ValidationResult:\n11 +    is_valid: bool\n12 +    error: str | None = None\n13 +\n14 +\n15 +EMAIL_PATTERN = re.compile(\n16 +    r\"^([a-zA-Z0-9_\\-\\.]+)+@(([a-zA-Z0-9\\-])+\\.)+([a-zA-Z]{2,})+$\"\n17 +)\n18 +\n19 +URL_PATTERN = re.compile(\n20 +    r\"^(https?:\\/\\/)?([\\w\\-]+\\.)+[\\w\\-]+(\\/[\\w\\-\\.~!$&'()*+,;=:@%]*)*\\/?$\"\n21 +)\n22 +\n23 +SLUG_PATTERN = re.compile(r\"^[a-z0-9]+(-[a-z0-9]+)*$\")\n24 +\n25 +PASSWORD_PATTERN = re.compile(\n26 +    r\"^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[@$!%*?&])[A-Za-z\\d@$!%*?&]{8,}$\"\n27 +)\n28 +\n29 +\n30 +def validate_email(email: str) -> ValidationResult:\n31 +    if not email:\n32 +        return ValidationResult(False, \"Email is required\")\n33 +\n34 +    if len(email) > 254:\n35 +        return ValidationResult(False, \"Email too long\")\n36 +\n37 +    if EMAIL_PATTERN.match(email):\n38 +        return ValidationResult(True)\n39 +\n40 +    return ValidationResult(False, \"Invalid email format\")\n41 +\n42 +\n43 +def validate_url(url: str) -> ValidationResult:\n44 +    if not url:\n45 +        return ValidationResult(False, \"URL is required\")\n46 +\n47 +    if URL_PATTERN.match(url):\n48 +        return ValidationResult(True)\n49 +\n50 +    return ValidationResult(False, \"Invalid URL format\")\n51 +\n52 +\n53 +def validate_slug(slug: str) -> ValidationResult:\n54 +    if not slug:\n55 +        return ValidationResult(False, \"Slug is required\")\n56 +\n57 +    if len(slug) > 100:\n58 +        return ValidationResult(False, \"Slug too long\")\n59 +\n60 +    if SLUG_PATTERN.match(slug):\n61 +        return ValidationResult(True)\n62 +\n63 +    return ValidationResult(False, \"Invalid slug format\")\n64 +\n65 +\n66 +def validate_password(password: str) -> ValidationResult:\n67 +    if not password:\n68 +        return ValidationResult(False, \"Password is required\")\n69 +\n70 +    if len(password) < 8:\n71 +        return ValidationResult(False, \"Password must be at least 8 characters\")\n72 +\n73 +    if PASSWORD_PATTERN.match(password):\n74 +        return ValidationResult(True)\n75 +\n76 +    return ValidationResult(False, \"Password must contain uppercase, lowercase, number and special character\")\n77 +\n78 +\n79 +class InputValidator:\n80 +    def __init__(self):\n81 +        self.custom_patterns: dict[str, re.Pattern] = {}\n82 +\n83 +    def add_pattern(self, name: str, pattern: str):\n84 +        self.custom_patterns[name] = re.compile(pattern)\n85 +\n86 +    def validate(self, name: str, value: str) -> ValidationResult:\n87 +        pattern = self.custom_patterns.get(name)\n88 +        if not pattern:\n89 +            return ValidationResult(False, f\"Unknown validator: {name}\")\n90 +\n91 +        if pattern.match(value):\n92 +            return ValidationResult(True)\n93 +\n94 +        return ValidationResult(False, f\"Value does not match {name} pattern\")\n95 +\n96 +    def validate_all(self, data: dict[str, str], validators: dict[str, str]) -> dict[str, ValidationResult]:\n97 +        results = {}\n98 +        for field, validator_name in validators.items():\n99 +            value = data.get(field, \"\")\n100 +            results[field] = self.validate(validator_name, value)\n101 +        return results\n102 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/validation/input_validator.py\",\"relevantLinesStart\":15,\"relevantLinesEnd\":17}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"EMAIL_PATTERN = re.compile(\\n    r\\\"^([a-zA-Z0-9_\\\\\\\\-\\\\\\\\.]+)+@((\\\\[[0-9]{1,3}\\\\\\\\.[0-9]{1,3}\\\\\\\\.[0-9]{1,3}\\\\\\\\.)|(([a-zA-Z0-9\\\\\\\\-]+\\\\\\\\.)+))([a-zA-Z]{2,}|[0-9]{1,3})(\\\\\\\\]?)$\\\"\\n)\",\n    \"improvedCode\": \"EMAIL_PATTERN = re.compile(\\n    r\\\"^[a-zA-Z0-9_\\\\\\\\-\\\\\\\\.]+@[a-zA-Z0-9\\\\\\\\-]+(\\\\\\\\.[a-zA-Z0-9\\\\\\\\-]+)*\\\\\\\\.[a-zA-Z]{2,}$\\\"\\n)\",\n    \"relevantFile\": \"src/validation/input_validator.py\",\n    \"relevantLinesEnd\": 17,\n    \"suggestionContent\": \"The `EMAIL_PATTERN` regex has nested quantifiers `([a-zA-Z0-9_\\\\-\\\\.]+)+` which causes catastrophic backtracking. For an input like 'aaaaaaaaaaaaaaaaaaaaaaaaa@' (many a's with no valid domain), the regex engine explores exponentially many paths before failing. This enables ReDoS attacks that can hang the server for minutes with a short malicious input.\",\n    \"oneSentenceSummary\": \"ReDoS vulnerability - nested quantifiers in email regex cause exponential backtracking\",\n    \"relevantLinesStart\": 15\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 35: src/auth/auth_service.py",
    "vars": {
      "fileContent": "import hashlib\nimport hmac\nimport secrets\nimport time\nfrom dataclasses import dataclass\nfrom datetime import datetime, timedelta\nfrom typing import Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass User:\n    id: str\n    username: str\n    password_hash: str\n    salt: str\n    failed_attempts: int = 0\n    locked_until: datetime | None = None\n\n\n@dataclass\nclass Session:\n    token: str\n    user_id: str\n    created_at: datetime\n    expires_at: datetime\n\n\nclass AuthService:\n    def __init__(self, secret_key: str, max_attempts: int = 5, lockout_minutes: int = 15):\n        self.secret_key = secret_key\n        self.max_attempts = max_attempts\n        self.lockout_duration = timedelta(minutes=lockout_minutes)\n        self._users: dict[str, User] = {}\n        self._sessions: dict[str, Session] = {}\n\n    def hash_password(self, password: str, salt: str) -> str:\n        return hashlib.sha256((password + salt).encode()).hexdigest()\n\n    def create_user(self, username: str, password: str) -> User:\n        salt = secrets.token_hex(16)\n        password_hash = self.hash_password(password, salt)\n\n        user = User(\n            id=secrets.token_urlsafe(16),\n            username=username,\n            password_hash=password_hash,\n            salt=salt\n        )\n\n        self._users[username] = user\n        return user\n\n    def authenticate(self, username: str, password: str) -> Session | None:\n        user = self._users.get(username)\n\n        if not user:\n            return None\n\n        if user.locked_until and datetime.now() < user.locked_until:\n            logger.warning(f\"Account locked: {username}\")\n            return None\n\n        password_hash = self.hash_password(password, user.salt)\n\n        if password_hash != user.password_hash:\n            user.failed_attempts += 1\n            if user.failed_attempts >= self.max_attempts:\n                user.locked_until = datetime.now() + self.lockout_duration\n                logger.warning(f\"Account locked due to failed attempts: {username}\")\n            return None\n\n        user.failed_attempts = 0\n        user.locked_until = None\n\n        session = Session(\n            token=secrets.token_urlsafe(32),\n            user_id=user.id,\n            created_at=datetime.now(),\n            expires_at=datetime.now() + timedelta(hours=24)\n        )\n\n        self._sessions[session.token] = session\n        return session\n\n    def validate_session(self, token: str) -> User | None:\n        session = self._sessions.get(token)\n\n        if not session:\n            return None\n\n        if datetime.now() > session.expires_at:\n            del self._sessions[token]\n            return None\n\n        for user in self._users.values():\n            if user.id == session.user_id:\n                return user\n\n        return None\n\n    def logout(self, token: str) -> bool:\n        if token in self._sessions:\n            del self._sessions[token]\n            return True\n        return False\n\n    def verify_token(self, token: str, expected: str) -> bool:\n        if len(token) != len(expected):\n            return False\n\n        result = 0\n        for a, b in zip(token, expected):\n            result |= ord(a) ^ ord(b)\n\n        return result == 0\n\n    def change_password(self, username: str, old_password: str, new_password: str) -> bool:\n        user = self._users.get(username)\n        if not user:\n            return False\n\n        old_hash = self.hash_password(old_password, user.salt)\n        if old_hash != user.password_hash:\n            return False\n\n        user.password_hash = self.hash_password(new_password, user.salt)\n        return True\n\n\ndef generate_reset_token(user_id: str) -> str:\n    timestamp = int(time.time())\n    data = f\"{user_id}:{timestamp}\"\n    return hashlib.md5(data.encode()).hexdigest()\n",
      "patchWithLinesStr": "## file: 'src/auth/auth_service.py'\n\n@@ -0,0 +1,137 @@\n__new hunk__\n1 +import hashlib\n2 +import hmac\n3 +import secrets\n4 +import time\n5 +from dataclasses import dataclass\n6 +from datetime import datetime, timedelta\n7 +from typing import Optional\n8 +import logging\n9 +\n10 +logger = logging.getLogger(__name__)\n11 +\n12 +\n13 +@dataclass\n14 +class User:\n15 +    id: str\n16 +    username: str\n17 +    password_hash: str\n18 +    salt: str\n19 +    failed_attempts: int = 0\n20 +    locked_until: datetime | None = None\n21 +\n22 +\n23 +@dataclass\n24 +class Session:\n25 +    token: str\n26 +    user_id: str\n27 +    created_at: datetime\n28 +    expires_at: datetime\n29 +\n30 +\n31 +class AuthService:\n32 +    def __init__(self, secret_key: str, max_attempts: int = 5, lockout_minutes: int = 15):\n33 +        self.secret_key = secret_key\n34 +        self.max_attempts = max_attempts\n35 +        self.lockout_duration = timedelta(minutes=lockout_minutes)\n36 +        self._users: dict[str, User] = {}\n37 +        self._sessions: dict[str, Session] = {}\n38 +\n39 +    def hash_password(self, password: str, salt: str) -> str:\n40 +        return hashlib.sha256((password + salt).encode()).hexdigest()\n41 +\n42 +    def create_user(self, username: str, password: str) -> User:\n43 +        salt = secrets.token_hex(16)\n44 +        password_hash = self.hash_password(password, salt)\n45 +\n46 +        user = User(\n47 +            id=secrets.token_urlsafe(16),\n48 +            username=username,\n49 +            password_hash=password_hash,\n50 +            salt=salt\n51 +        )\n52 +\n53 +        self._users[username] = user\n54 +        return user\n55 +\n56 +    def authenticate(self, username: str, password: str) -> Session | None:\n57 +        user = self._users.get(username)\n58 +\n59 +        if not user:\n60 +            return None\n61 +\n62 +        if user.locked_until and datetime.now() < user.locked_until:\n63 +            logger.warning(f\"Account locked: {username}\")\n64 +            return None\n65 +\n66 +        password_hash = self.hash_password(password, user.salt)\n67 +\n68 +        if password_hash != user.password_hash:\n69 +            user.failed_attempts += 1\n70 +            if user.failed_attempts >= self.max_attempts:\n71 +                user.locked_until = datetime.now() + self.lockout_duration\n72 +                logger.warning(f\"Account locked due to failed attempts: {username}\")\n73 +            return None\n74 +\n75 +        user.failed_attempts = 0\n76 +        user.locked_until = None\n77 +\n78 +        session = Session(\n79 +            token=secrets.token_urlsafe(32),\n80 +            user_id=user.id,\n81 +            created_at=datetime.now(),\n82 +            expires_at=datetime.now() + timedelta(hours=24)\n83 +        )\n84 +\n85 +        self._sessions[session.token] = session\n86 +        return session\n87 +\n88 +    def validate_session(self, token: str) -> User | None:\n89 +        session = self._sessions.get(token)\n90 +\n91 +        if not session:\n92 +            return None\n93 +\n94 +        if datetime.now() > session.expires_at:\n95 +            del self._sessions[token]\n96 +            return None\n97 +\n98 +        for user in self._users.values():\n99 +            if user.id == session.user_id:\n100 +                return user\n101 +\n102 +        return None\n103 +\n104 +    def logout(self, token: str) -> bool:\n105 +        if token in self._sessions:\n106 +            del self._sessions[token]\n107 +            return True\n108 +        return False\n109 +\n110 +    def verify_token(self, token: str, expected: str) -> bool:\n111 +        if len(token) != len(expected):\n112 +            return False\n113 +\n114 +        result = 0\n115 +        for a, b in zip(token, expected):\n116 +            result |= ord(a) ^ ord(b)\n117 +\n118 +        return result == 0\n119 +\n120 +    def change_password(self, username: str, old_password: str, new_password: str) -> bool:\n121 +        user = self._users.get(username)\n122 +        if not user:\n123 +            return False\n124 +\n125 +        old_hash = self.hash_password(old_password, user.salt)\n126 +        if old_hash != user.password_hash:\n127 +            return False\n128 +\n129 +        user.password_hash = self.hash_password(new_password, user.salt)\n130 +        return True\n131 +\n132 +\n133 +def generate_reset_token(user_id: str) -> str:\n134 +    timestamp = int(time.time())\n135 +    data = f\"{user_id}:{timestamp}\"\n136 +    return hashlib.md5(data.encode()).hexdigest()\n137 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/auth/auth_service.py\",\"relevantLinesStart\":38,\"relevantLinesEnd\":39},{\"relevantFile\":\"src/auth/auth_service.py\",\"relevantLinesStart\":53,\"relevantLinesEnd\":56},{\"relevantFile\":\"src/auth/auth_service.py\",\"relevantLinesStart\":124,\"relevantLinesEnd\":127}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def hash_password(self, password: str, salt: str) -> str:\\n        return hashlib.sha256((password + salt).encode()).hexdigest()\",\n    \"improvedCode\": \"def hash_password(self, password: str, salt: str) -> str:\\n        import bcrypt\\n        return bcrypt.hashpw(password.encode(), salt.encode()).decode()\",\n    \"relevantFile\": \"src/auth/auth_service.py\",\n    \"relevantLinesEnd\": 39,\n    \"suggestionContent\": \"The `hash_password` method uses SHA-256 which is too fast for password hashing. Attackers can compute billions of hashes per second. Use a purpose-built password hashing algorithm like bcrypt, scrypt, or argon2 that has configurable work factors.\",\n    \"oneSentenceSummary\": \"Using SHA-256 for passwords is insecure - too fast, enables brute force attacks\",\n    \"relevantLinesStart\": 38\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"user = self._users.get(username)\\n\\n        if not user:\\n            return None\",\n    \"improvedCode\": \"user = self._users.get(username)\\n\\n        if not user:\\n            # Perform dummy hash to prevent timing attack\\n            self.hash_password(password, 'dummy_salt')\\n            return None\",\n    \"relevantFile\": \"src/auth/auth_service.py\",\n    \"relevantLinesEnd\": 56,\n    \"suggestionContent\": \"The `authenticate` method has a timing side-channel. When user doesn't exist, it returns immediately. When user exists but password is wrong, it performs a hash comparison. An attacker can enumerate valid usernames by measuring response times. Always perform the hash operation.\",\n    \"oneSentenceSummary\": \"Timing attack allows username enumeration via response time differences\",\n    \"relevantLinesStart\": 53\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def generate_reset_token(user_id: str) -> str:\\n    timestamp = int(time.time())\\n    data = f\\\"{user_id}:{timestamp}\\\"\\n    return hashlib.md5(data.encode()).hexdigest()\",\n    \"improvedCode\": \"def generate_reset_token(user_id: str) -> str:\\n    return secrets.token_urlsafe(32)\",\n    \"relevantFile\": \"src/auth/auth_service.py\",\n    \"relevantLinesEnd\": 127,\n    \"suggestionContent\": \"The `generate_reset_token` function uses MD5 and includes only the user_id and timestamp. MD5 is cryptographically broken, and the token is predictable if an attacker knows the user_id and approximate time. Use cryptographically secure random tokens instead.\",\n    \"oneSentenceSummary\": \"Reset token uses weak MD5 and is predictable from user_id and time\",\n    \"relevantLinesStart\": 124\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 36: src/config/config_loader.py",
    "vars": {
      "fileContent": "import os\nimport yaml\nimport json\nfrom pathlib import Path\nfrom typing import Any\nfrom dataclasses import dataclass\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass DatabaseConfig:\n    host: str\n    port: int\n    name: str\n    user: str\n    password: str\n\n\n@dataclass\nclass AppConfig:\n    debug: bool\n    secret_key: str\n    database: DatabaseConfig\n    allowed_hosts: list[str]\n\n\nclass ConfigLoader:\n    def __init__(self, config_dir: str = \"./config\"):\n        self.config_dir = Path(config_dir)\n        self._cache: dict[str, Any] = {}\n\n    def load_yaml(self, filename: str) -> dict:\n        filepath = self.config_dir / filename\n\n        if not filepath.exists():\n            raise FileNotFoundError(f\"Config file not found: {filepath}\")\n\n        with open(filepath, \"r\") as f:\n            return yaml.load(f, Loader=yaml.Loader)\n\n    def load_json(self, filename: str) -> dict:\n        filepath = self.config_dir / filename\n\n        if not filepath.exists():\n            raise FileNotFoundError(f\"Config file not found: {filepath}\")\n\n        with open(filepath, \"r\") as f:\n            return json.load(f)\n\n    def load_config(self, filename: str) -> dict:\n        cache_key = str(filename)\n\n        if cache_key in self._cache:\n            return self._cache[cache_key]\n\n        if filename.endswith(\".yaml\") or filename.endswith(\".yml\"):\n            config = self.load_yaml(filename)\n        elif filename.endswith(\".json\"):\n            config = self.load_json(filename)\n        else:\n            raise ValueError(f\"Unsupported config format: {filename}\")\n\n        config = self._apply_env_overrides(config)\n        self._cache[cache_key] = config\n\n        return config\n\n    def _apply_env_overrides(self, config: dict, prefix: str = \"APP\") -> dict:\n        result = config.copy()\n\n        for key, value in config.items():\n            env_key = f\"{prefix}_{key.upper()}\"\n            env_value = os.environ.get(env_key)\n\n            if env_value is not None:\n                if isinstance(value, bool):\n                    result[key] = env_value.lower() in (\"true\", \"1\", \"yes\")\n                elif isinstance(value, int):\n                    result[key] = int(env_value)\n                elif isinstance(value, float):\n                    result[key] = float(env_value)\n                else:\n                    result[key] = env_value\n            elif isinstance(value, dict):\n                result[key] = self._apply_env_overrides(value, f\"{prefix}_{key.upper()}\")\n\n        return result\n\n    def get_app_config(self) -> AppConfig:\n        config = self.load_config(\"app.yaml\")\n\n        db_config = DatabaseConfig(\n            host=config[\"database\"][\"host\"],\n            port=config[\"database\"][\"port\"],\n            name=config[\"database\"][\"name\"],\n            user=config[\"database\"][\"user\"],\n            password=config[\"database\"][\"password\"]\n        )\n\n        return AppConfig(\n            debug=config.get(\"debug\", False),\n            secret_key=config[\"secret_key\"],\n            database=db_config,\n            allowed_hosts=config.get(\"allowed_hosts\", [])\n        )\n\n    def clear_cache(self):\n        self._cache.clear()\n\n\ndef load_yaml_string(content: str) -> dict:\n    return yaml.load(content, Loader=yaml.Loader)\n\n\ndef merge_configs(*configs: dict) -> dict:\n    result = {}\n    for config in configs:\n        for key, value in config.items():\n            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n                result[key] = merge_configs(result[key], value)\n            else:\n                result[key] = value\n    return result\n",
      "patchWithLinesStr": "## file: 'src/config/config_loader.py'\n\n@@ -0,0 +1,126 @@\n__new hunk__\n1 +import os\n2 +import yaml\n3 +import json\n4 +from pathlib import Path\n5 +from typing import Any\n6 +from dataclasses import dataclass\n7 +import logging\n8 +\n9 +logger = logging.getLogger(__name__)\n10 +\n11 +\n12 +@dataclass\n13 +class DatabaseConfig:\n14 +    host: str\n15 +    port: int\n16 +    name: str\n17 +    user: str\n18 +    password: str\n19 +\n20 +\n21 +@dataclass\n22 +class AppConfig:\n23 +    debug: bool\n24 +    secret_key: str\n25 +    database: DatabaseConfig\n26 +    allowed_hosts: list[str]\n27 +\n28 +\n29 +class ConfigLoader:\n30 +    def __init__(self, config_dir: str = \"./config\"):\n31 +        self.config_dir = Path(config_dir)\n32 +        self._cache: dict[str, Any] = {}\n33 +\n34 +    def load_yaml(self, filename: str) -> dict:\n35 +        filepath = self.config_dir / filename\n36 +\n37 +        if not filepath.exists():\n38 +            raise FileNotFoundError(f\"Config file not found: {filepath}\")\n39 +\n40 +        with open(filepath, \"r\") as f:\n41 +            return yaml.load(f, Loader=yaml.Loader)\n42 +\n43 +    def load_json(self, filename: str) -> dict:\n44 +        filepath = self.config_dir / filename\n45 +\n46 +        if not filepath.exists():\n47 +            raise FileNotFoundError(f\"Config file not found: {filepath}\")\n48 +\n49 +        with open(filepath, \"r\") as f:\n50 +            return json.load(f)\n51 +\n52 +    def load_config(self, filename: str) -> dict:\n53 +        cache_key = str(filename)\n54 +\n55 +        if cache_key in self._cache:\n56 +            return self._cache[cache_key]\n57 +\n58 +        if filename.endswith(\".yaml\") or filename.endswith(\".yml\"):\n59 +            config = self.load_yaml(filename)\n60 +        elif filename.endswith(\".json\"):\n61 +            config = self.load_json(filename)\n62 +        else:\n63 +            raise ValueError(f\"Unsupported config format: {filename}\")\n64 +\n65 +        config = self._apply_env_overrides(config)\n66 +        self._cache[cache_key] = config\n67 +\n68 +        return config\n69 +\n70 +    def _apply_env_overrides(self, config: dict, prefix: str = \"APP\") -> dict:\n71 +        result = config.copy()\n72 +\n73 +        for key, value in config.items():\n74 +            env_key = f\"{prefix}_{key.upper()}\"\n75 +            env_value = os.environ.get(env_key)\n76 +\n77 +            if env_value is not None:\n78 +                if isinstance(value, bool):\n79 +                    result[key] = env_value.lower() in (\"true\", \"1\", \"yes\")\n80 +                elif isinstance(value, int):\n81 +                    result[key] = int(env_value)\n82 +                elif isinstance(value, float):\n83 +                    result[key] = float(env_value)\n84 +                else:\n85 +                    result[key] = env_value\n86 +            elif isinstance(value, dict):\n87 +                result[key] = self._apply_env_overrides(value, f\"{prefix}_{key.upper()}\")\n88 +\n89 +        return result\n90 +\n91 +    def get_app_config(self) -> AppConfig:\n92 +        config = self.load_config(\"app.yaml\")\n93 +\n94 +        db_config = DatabaseConfig(\n95 +            host=config[\"database\"][\"host\"],\n96 +            port=config[\"database\"][\"port\"],\n97 +            name=config[\"database\"][\"name\"],\n98 +            user=config[\"database\"][\"user\"],\n99 +            password=config[\"database\"][\"password\"]\n100 +        )\n101 +\n102 +        return AppConfig(\n103 +            debug=config.get(\"debug\", False),\n104 +            secret_key=config[\"secret_key\"],\n105 +            database=db_config,\n106 +            allowed_hosts=config.get(\"allowed_hosts\", [])\n107 +        )\n108 +\n109 +    def clear_cache(self):\n110 +        self._cache.clear()\n111 +\n112 +\n113 +def load_yaml_string(content: str) -> dict:\n114 +    return yaml.load(content, Loader=yaml.Loader)\n115 +\n116 +\n117 +def merge_configs(*configs: dict) -> dict:\n118 +    result = {}\n119 +    for config in configs:\n120 +        for key, value in config.items():\n121 +            if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n122 +                result[key] = merge_configs(result[key], value)\n123 +            else:\n124 +                result[key] = value\n125 +    return result\n126 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/config/config_loader.py\",\"relevantLinesStart\":40,\"relevantLinesEnd\":40}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"return yaml.load(f, Loader=yaml.Loader)\",\n    \"improvedCode\": \"return yaml.safe_load(f)\",\n    \"relevantFile\": \"src/config/config_loader.py\",\n    \"relevantLinesEnd\": 40,\n    \"suggestionContent\": \"Both `load_yaml` and `load_yaml_string` use `yaml.Loader` which is unsafe and allows arbitrary Python code execution. A malicious YAML file can use `!!python/object/apply:os.system` to execute shell commands. Use `yaml.safe_load()` or `yaml.SafeLoader` instead.\",\n    \"oneSentenceSummary\": \"Unsafe YAML loading allows arbitrary code execution via malicious config files\",\n    \"relevantLinesStart\": 40\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 37: src/expressions/expression_parser.py",
    "vars": {
      "fileContent": "from typing import Any, Callable\nfrom dataclasses import dataclass\nimport operator\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass ExpressionResult:\n    value: Any\n    error: str | None = None\n\n\nSAFE_OPERATORS = {\n    '+': operator.add,\n    '-': operator.sub,\n    '*': operator.mul,\n    '/': operator.truediv,\n    '//': operator.floordiv,\n    '%': operator.mod,\n    '**': operator.pow,\n}\n\n\nclass ExpressionParser:\n    def __init__(self):\n        self.variables: dict[str, Any] = {}\n        self.functions: dict[str, Callable] = {\n            'abs': abs,\n            'round': round,\n            'min': min,\n            'max': max,\n            'sum': sum,\n        }\n\n    def set_variable(self, name: str, value: Any):\n        self.variables[name] = value\n\n    def evaluate(self, expression: str) -> ExpressionResult:\n        try:\n            context = {**self.variables, **self.functions}\n            result = eval(expression, {\"__builtins__\": {} }, context)\n            return ExpressionResult(value=result)\n        except Exception as e:\n            return ExpressionResult(value=None, error=str(e))\n\n    def evaluate_template(self, template: str, data: dict) -> str:\n        try:\n            for key, value in data.items():\n                template = template.replace(f\"{ {{key} }}\", str(value))\n\n            if \"{\" in template and \"}\" in template:\n                import re\n                pattern = r\"\\{([^}]+)\\}\"\n                matches = re.findall(pattern, template)\n                for match in matches:\n                    result = eval(match, {\"__builtins__\": {} }, data)\n                    template = template.replace(f\"{ {{match} }}\", str(result))\n\n            return template\n        except Exception as e:\n            logger.error(f\"Template evaluation error: {e}\")\n            return template\n\n    def execute_script(self, script: str, context: dict = None) -> ExpressionResult:\n        try:\n            local_context = context or {}\n            exec(script, {\"__builtins__\": None}, local_context)\n            return ExpressionResult(value=local_context.get(\"result\"))\n        except Exception as e:\n            return ExpressionResult(value=None, error=str(e))\n\n\nclass FormulaCalculator:\n    def __init__(self):\n        self.formulas: dict[str, str] = {}\n\n    def register_formula(self, name: str, expression: str):\n        self.formulas[name] = expression\n\n    def calculate(self, name: str, **kwargs) -> Any:\n        formula = self.formulas.get(name)\n        if not formula:\n            raise ValueError(f\"Unknown formula: {name}\")\n\n        return eval(formula, {\"__builtins__\": {} }, kwargs)\n\n    def calculate_all(self, name: str, data_list: list[dict]) -> list[Any]:\n        return [self.calculate(name, **data) for data in data_list]\n",
      "patchWithLinesStr": "## file: 'src/expressions/expression_parser.py'\n\n@@ -0,0 +1,91 @@\n__new hunk__\n1 +from typing import Any, Callable\n2 +from dataclasses import dataclass\n3 +import operator\n4 +import logging\n5 +\n6 +logger = logging.getLogger(__name__)\n7 +\n8 +\n9 +@dataclass\n10 +class ExpressionResult:\n11 +    value: Any\n12 +    error: str | None = None\n13 +\n14 +\n15 +SAFE_OPERATORS = {\n16 +    '+': operator.add,\n17 +    '-': operator.sub,\n18 +    '*': operator.mul,\n19 +    '/': operator.truediv,\n20 +    '//': operator.floordiv,\n21 +    '%': operator.mod,\n22 +    '**': operator.pow,\n23 +}\n24 +\n25 +\n26 +class ExpressionParser:\n27 +    def __init__(self):\n28 +        self.variables: dict[str, Any] = {}\n29 +        self.functions: dict[str, Callable] = {\n30 +            'abs': abs,\n31 +            'round': round,\n32 +            'min': min,\n33 +            'max': max,\n34 +            'sum': sum,\n35 +        }\n36 +\n37 +    def set_variable(self, name: str, value: Any):\n38 +        self.variables[name] = value\n39 +\n40 +    def evaluate(self, expression: str) -> ExpressionResult:\n41 +        try:\n42 +            context = {**self.variables, **self.functions}\n43 +            result = eval(expression, {\"__builtins__\": {} }, context)\n44 +            return ExpressionResult(value=result)\n45 +        except Exception as e:\n46 +            return ExpressionResult(value=None, error=str(e))\n47 +\n48 +    def evaluate_template(self, template: str, data: dict) -> str:\n49 +        try:\n50 +            for key, value in data.items():\n51 +                template = template.replace(f\"{ {{key} }}\", str(value))\n52 +\n53 +            if \"{\" in template and \"}\" in template:\n54 +                import re\n55 +                pattern = r\"\\{([^}]+)\\}\"\n56 +                matches = re.findall(pattern, template)\n57 +                for match in matches:\n58 +                    result = eval(match, {\"__builtins__\": {} }, data)\n59 +                    template = template.replace(f\"{ {{match} }}\", str(result))\n60 +\n61 +            return template\n62 +        except Exception as e:\n63 +            logger.error(f\"Template evaluation error: {e}\")\n64 +            return template\n65 +\n66 +    def execute_script(self, script: str, context: dict = None) -> ExpressionResult:\n67 +        try:\n68 +            local_context = context or {}\n69 +            exec(script, {\"__builtins__\": None}, local_context)\n70 +            return ExpressionResult(value=local_context.get(\"result\"))\n71 +        except Exception as e:\n72 +            return ExpressionResult(value=None, error=str(e))\n73 +\n74 +\n75 +class FormulaCalculator:\n76 +    def __init__(self):\n77 +        self.formulas: dict[str, str] = {}\n78 +\n79 +    def register_formula(self, name: str, expression: str):\n80 +        self.formulas[name] = expression\n81 +\n82 +    def calculate(self, name: str, **kwargs) -> Any:\n83 +        formula = self.formulas.get(name)\n84 +        if not formula:\n85 +            raise ValueError(f\"Unknown formula: {name}\")\n86 +\n87 +        return eval(formula, {\"__builtins__\": {} }, kwargs)\n88 +\n89 +    def calculate_all(self, name: str, data_list: list[dict]) -> list[Any]:\n90 +        return [self.calculate(name, **data) for data in data_list]\n91 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/expressions/expression_parser.py\",\"relevantLinesStart\":38,\"relevantLinesEnd\":42},{\"relevantFile\":\"src/expressions/expression_parser.py\",\"relevantLinesStart\":62,\"relevantLinesEnd\":66}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def evaluate(self, expression: str) -> ExpressionResult:\\n        try:\\n            context = {**self.variables, **self.functions}\\n            result = eval(expression, {\\\"__builtins__\\\": {}}, context)\\n            return ExpressionResult(value=result)\",\n    \"improvedCode\": \"def evaluate(self, expression: str) -> ExpressionResult:\\n        # Use a proper expression parser like ast.literal_eval for literals\\n        # or a library like simpleeval for safe expression evaluation\\n        import ast\\n        try:\\n            result = ast.literal_eval(expression)\\n            return ExpressionResult(value=result)\\n        except ValueError:\\n            return ExpressionResult(value=None, error=\\\"Only literals allowed\\\")\",\n    \"relevantFile\": \"src/expressions/expression_parser.py\",\n    \"relevantLinesEnd\": 42,\n    \"suggestionContent\": \"The `evaluate` method uses `eval()` with a restricted `__builtins__` but this is not sufficient security. Attackers can still access dangerous functions via attribute access: `().__class__.__bases__[0].__subclasses__()` can find and call arbitrary classes including `os._wrap_close` to execute commands. Never use eval() on untrusted input.\",\n    \"oneSentenceSummary\": \"eval() with empty __builtins__ is bypassable - allows arbitrary code execution\",\n    \"relevantLinesStart\": 38\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def execute_script(self, script: str, context: dict = None) -> ExpressionResult:\\n        try:\\n            local_context = context or {}\\n            exec(script, {\\\"__builtins__\\\": None}, local_context)\\n            return ExpressionResult(value=local_context.get(\\\"result\\\"))\",\n    \"improvedCode\": \"def execute_script(self, script: str, context: dict = None) -> ExpressionResult:\\n        # Remove this method entirely or use a proper sandboxed execution environment\\n        raise NotImplementedError(\\\"Script execution is disabled for security reasons\\\")\",\n    \"relevantFile\": \"src/expressions/expression_parser.py\",\n    \"relevantLinesEnd\": 66,\n    \"suggestionContent\": \"The `execute_script` method uses `exec()` which executes arbitrary Python code. Even with `__builtins__` set to None, attackers can escape the sandbox using the same techniques as eval(). Never execute untrusted code with exec().\",\n    \"oneSentenceSummary\": \"exec() allows arbitrary code execution even with restricted builtins\",\n    \"relevantLinesStart\": 62\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 38: src/users/user_service.py",
    "vars": {
      "fileContent": "from dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Optional\nimport hashlib\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass User:\n    id: str\n    email: str\n    password_hash: str\n    api_key: str\n    created_at: datetime\n\n\n@dataclass\nclass LoginRequest:\n    email: str\n    password: str\n    remember_me: bool = False\n\n\n@dataclass\nclass CreateUserRequest:\n    email: str\n    password: str\n    api_key: str | None = None\n\n\nclass UserService:\n    def __init__(self):\n        self._users: dict[str, User] = {}\n\n    def create_user(self, request: CreateUserRequest) -> User:\n        logger.info(f\"Creating user with email={request.email}, password={request.password}\")\n\n        if request.email in [u.email for u in self._users.values()]:\n            raise ValueError(\"Email already exists\")\n\n        user_id = hashlib.sha256(request.email.encode()).hexdigest()[:16]\n        password_hash = hashlib.sha256(request.password.encode()).hexdigest()\n        api_key = request.api_key or hashlib.sha256(\n            f\"{request.email}:{datetime.now().isoformat()}\".encode()\n        ).hexdigest()\n\n        user = User(\n            id=user_id,\n            email=request.email,\n            password_hash=password_hash,\n            api_key=api_key,\n            created_at=datetime.now()\n        )\n\n        self._users[user_id] = user\n        logger.info(f\"Created user: {user}\")\n\n        return user\n\n    def authenticate(self, request: LoginRequest) -> User | None:\n        logger.debug(f\"Authentication attempt: {request}\")\n\n        for user in self._users.values():\n            if user.email == request.email:\n                password_hash = hashlib.sha256(request.password.encode()).hexdigest()\n                if user.password_hash == password_hash:\n                    logger.info(f\"User authenticated: {user.email}\")\n                    return user\n                else:\n                    logger.warning(f\"Invalid password for user {request.email}: {request.password}\")\n                    return None\n\n        logger.warning(f\"User not found: {request.email}\")\n        return None\n\n    def get_user_by_api_key(self, api_key: str) -> User | None:\n        logger.debug(f\"Looking up user by API key: {api_key}\")\n\n        for user in self._users.values():\n            if user.api_key == api_key:\n                return user\n        return None\n\n    def update_password(self, user_id: str, old_password: str, new_password: str) -> bool:\n        logger.info(f\"Password update request for user {user_id}: old={old_password}, new={new_password}\")\n\n        user = self._users.get(user_id)\n        if not user:\n            return False\n\n        old_hash = hashlib.sha256(old_password.encode()).hexdigest()\n        if user.password_hash != old_hash:\n            return False\n\n        user.password_hash = hashlib.sha256(new_password.encode()).hexdigest()\n        return True\n\n    def get_all_users(self) -> list[User]:\n        logger.info(f\"Returning all users: {list(self._users.values())}\")\n        return list(self._users.values())\n",
      "patchWithLinesStr": "## file: 'src/users/user_service.py'\n\n@@ -0,0 +1,103 @@\n__new hunk__\n1 +from dataclasses import dataclass\n2 +from datetime import datetime\n3 +from typing import Optional\n4 +import hashlib\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +\n10 +@dataclass\n11 +class User:\n12 +    id: str\n13 +    email: str\n14 +    password_hash: str\n15 +    api_key: str\n16 +    created_at: datetime\n17 +\n18 +\n19 +@dataclass\n20 +class LoginRequest:\n21 +    email: str\n22 +    password: str\n23 +    remember_me: bool = False\n24 +\n25 +\n26 +@dataclass\n27 +class CreateUserRequest:\n28 +    email: str\n29 +    password: str\n30 +    api_key: str | None = None\n31 +\n32 +\n33 +class UserService:\n34 +    def __init__(self):\n35 +        self._users: dict[str, User] = {}\n36 +\n37 +    def create_user(self, request: CreateUserRequest) -> User:\n38 +        logger.info(f\"Creating user with email={request.email}, password={request.password}\")\n39 +\n40 +        if request.email in [u.email for u in self._users.values()]:\n41 +            raise ValueError(\"Email already exists\")\n42 +\n43 +        user_id = hashlib.sha256(request.email.encode()).hexdigest()[:16]\n44 +        password_hash = hashlib.sha256(request.password.encode()).hexdigest()\n45 +        api_key = request.api_key or hashlib.sha256(\n46 +            f\"{request.email}:{datetime.now().isoformat()}\".encode()\n47 +        ).hexdigest()\n48 +\n49 +        user = User(\n50 +            id=user_id,\n51 +            email=request.email,\n52 +            password_hash=password_hash,\n53 +            api_key=api_key,\n54 +            created_at=datetime.now()\n55 +        )\n56 +\n57 +        self._users[user_id] = user\n58 +        logger.info(f\"Created user: {user}\")\n59 +\n60 +        return user\n61 +\n62 +    def authenticate(self, request: LoginRequest) -> User | None:\n63 +        logger.debug(f\"Authentication attempt: {request}\")\n64 +\n65 +        for user in self._users.values():\n66 +            if user.email == request.email:\n67 +                password_hash = hashlib.sha256(request.password.encode()).hexdigest()\n68 +                if user.password_hash == password_hash:\n69 +                    logger.info(f\"User authenticated: {user.email}\")\n70 +                    return user\n71 +                else:\n72 +                    logger.warning(f\"Invalid password for user {request.email}: {request.password}\")\n73 +                    return None\n74 +\n75 +        logger.warning(f\"User not found: {request.email}\")\n76 +        return None\n77 +\n78 +    def get_user_by_api_key(self, api_key: str) -> User | None:\n79 +        logger.debug(f\"Looking up user by API key: {api_key}\")\n80 +\n81 +        for user in self._users.values():\n82 +            if user.api_key == api_key:\n83 +                return user\n84 +        return None\n85 +\n86 +    def update_password(self, user_id: str, old_password: str, new_password: str) -> bool:\n87 +        logger.info(f\"Password update request for user {user_id}: old={old_password}, new={new_password}\")\n88 +\n89 +        user = self._users.get(user_id)\n90 +        if not user:\n91 +            return False\n92 +\n93 +        old_hash = hashlib.sha256(old_password.encode()).hexdigest()\n94 +        if user.password_hash != old_hash:\n95 +            return False\n96 +\n97 +        user.password_hash = hashlib.sha256(new_password.encode()).hexdigest()\n98 +        return True\n99 +\n100 +    def get_all_users(self) -> list[User]:\n101 +        logger.info(f\"Returning all users: {list(self._users.values())}\")\n102 +        return list(self._users.values())\n103 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/users/user_service.py\",\"relevantLinesStart\":38,\"relevantLinesEnd\":38},{\"relevantFile\":\"src/users/user_service.py\",\"relevantLinesStart\":70,\"relevantLinesEnd\":70},{\"relevantFile\":\"src/users/user_service.py\",\"relevantLinesStart\":97,\"relevantLinesEnd\":97}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"logger.info(f\\\"Creating user with email={request.email}, password={request.password}\\\")\",\n    \"improvedCode\": \"logger.info(f\\\"Creating user with email={request.email}\\\")\",\n    \"relevantFile\": \"src/users/user_service.py\",\n    \"relevantLinesEnd\": 38,\n    \"suggestionContent\": \"Multiple log statements expose sensitive data including plaintext passwords, API keys, and user objects containing password hashes. Log files are often stored with less security than databases and may be accessible to more personnel. Never log passwords, API keys, tokens, or other secrets.\",\n    \"oneSentenceSummary\": \"Logging sensitive data (passwords, API keys) exposes secrets in log files\",\n    \"relevantLinesStart\": 38\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"logger.warning(f\\\"Invalid password for user {request.email}: {request.password}\\\")\",\n    \"improvedCode\": \"logger.warning(f\\\"Invalid password for user {request.email}\\\")\",\n    \"relevantFile\": \"src/users/user_service.py\",\n    \"relevantLinesEnd\": 70,\n    \"suggestionContent\": \"The `authenticate` method logs the password when authentication fails. This exposes user passwords in plain text in log files. Combined with the email, an attacker with log access can obtain valid credentials.\",\n    \"oneSentenceSummary\": \"Failed login logs expose plaintext password in log files\",\n    \"relevantLinesStart\": 70\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"logger.info(f\\\"Returning all users: {list(self._users.values())}\\\")\",\n    \"improvedCode\": \"logger.info(f\\\"Returning {len(self._users)} users\\\")\",\n    \"relevantFile\": \"src/users/user_service.py\",\n    \"relevantLinesEnd\": 97,\n    \"suggestionContent\": \"The `get_all_users` method logs the complete list of User objects, which includes password hashes and API keys. Even hashed passwords shouldn't be logged as they can be subject to offline cracking attempts.\",\n    \"oneSentenceSummary\": \"Logging user objects exposes password hashes and API keys\",\n    \"relevantLinesStart\": 97\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 39: src/api/request_handler.py",
    "vars": {
      "fileContent": "import json\nimport traceback\nfrom typing import Any\nfrom dataclasses import dataclass\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass RequestError(Exception):\n    def __init__(self, message: str, status_code: int = 400):\n        super().__init__(message)\n        self.status_code = status_code\n\n\nclass ValidationError(RequestError):\n    def __init__(self, field: str, message: str):\n        super().__init__(f\"Validation error on {field}: {message}\", 422)\n        self.field = field\n\n\nclass AuthenticationError(RequestError):\n    def __init__(self, message: str = \"Authentication required\"):\n        super().__init__(message, 401)\n\n\n@dataclass\nclass Request:\n    method: str\n    path: str\n    headers: dict[str, str]\n    body: str | None = None\n\n\n@dataclass\nclass Response:\n    status_code: int\n    body: dict[str, Any]\n    headers: dict[str, str] = None\n\n    def __post_init__(self):\n        if self.headers is None:\n            self.headers = {}\n\n\nclass RequestHandler:\n    def __init__(self):\n        self.middleware = []\n\n    def add_middleware(self, middleware_fn):\n        self.middleware.append(middleware_fn)\n\n    def parse_json_body(self, request: Request) -> dict:\n        if not request.body:\n            return {}\n\n        try:\n            return json.loads(request.body)\n        except:\n            raise ValidationError(\"body\", \"Invalid JSON\")\n\n    def validate_required_fields(self, data: dict, required: list[str]):\n        for field in required:\n            if field not in data:\n                raise ValidationError(field, \"Field is required\")\n\n    def handle_request(self, request: Request) -> Response:\n        try:\n            for middleware in self.middleware:\n                request = middleware(request)\n\n            body = self.parse_json_body(request)\n\n            if request.method == \"POST\":\n                self.validate_required_fields(body, [\"name\", \"email\"])\n\n            return Response(\n                status_code=200,\n                body={\"success\": True, \"data\": body}\n            )\n\n        except ValidationError as e:\n            return Response(\n                status_code=e.status_code,\n                body={\"error\": str(e), \"field\": e.field}\n            )\n        except RequestError as e:\n            return Response(\n                status_code=e.status_code,\n                body={\"error\": str(e)}\n            )\n        except:\n            logger.error(f\"Unexpected error: {traceback.format_exc()}\")\n            return Response(\n                status_code=500,\n                body={\"error\": \"Internal server error\"}\n            )\n\n    def process_batch(self, requests: list[Request]) -> list[Response]:\n        responses = []\n        for request in requests:\n            try:\n                response = self.handle_request(request)\n                responses.append(response)\n            except Exception as e:\n                logger.error(f\"Batch request failed: {e}\")\n                responses.append(Response(500, {\"error\": \"Failed\"}))\n        return responses\n\n\ndef safe_divide(a: float, b: float) -> float:\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return 0.0\n    except:\n        return None\n\n\ndef parse_config(config_str: str) -> dict:\n    try:\n        config = json.loads(config_str)\n        return config\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"Invalid config: {e}\")\n    except Exception:\n        raise\n",
      "patchWithLinesStr": "## file: 'src/api/request_handler.py'\n\n@@ -0,0 +1,128 @@\n__new hunk__\n1 +import json\n2 +import traceback\n3 +from typing import Any\n4 +from dataclasses import dataclass\n5 +import logging\n6 +\n7 +logger = logging.getLogger(__name__)\n8 +\n9 +\n10 +class RequestError(Exception):\n11 +    def __init__(self, message: str, status_code: int = 400):\n12 +        super().__init__(message)\n13 +        self.status_code = status_code\n14 +\n15 +\n16 +class ValidationError(RequestError):\n17 +    def __init__(self, field: str, message: str):\n18 +        super().__init__(f\"Validation error on {field}: {message}\", 422)\n19 +        self.field = field\n20 +\n21 +\n22 +class AuthenticationError(RequestError):\n23 +    def __init__(self, message: str = \"Authentication required\"):\n24 +        super().__init__(message, 401)\n25 +\n26 +\n27 +@dataclass\n28 +class Request:\n29 +    method: str\n30 +    path: str\n31 +    headers: dict[str, str]\n32 +    body: str | None = None\n33 +\n34 +\n35 +@dataclass\n36 +class Response:\n37 +    status_code: int\n38 +    body: dict[str, Any]\n39 +    headers: dict[str, str] = None\n40 +\n41 +    def __post_init__(self):\n42 +        if self.headers is None:\n43 +            self.headers = {}\n44 +\n45 +\n46 +class RequestHandler:\n47 +    def __init__(self):\n48 +        self.middleware = []\n49 +\n50 +    def add_middleware(self, middleware_fn):\n51 +        self.middleware.append(middleware_fn)\n52 +\n53 +    def parse_json_body(self, request: Request) -> dict:\n54 +        if not request.body:\n55 +            return {}\n56 +\n57 +        try:\n58 +            return json.loads(request.body)\n59 +        except:\n60 +            raise ValidationError(\"body\", \"Invalid JSON\")\n61 +\n62 +    def validate_required_fields(self, data: dict, required: list[str]):\n63 +        for field in required:\n64 +            if field not in data:\n65 +                raise ValidationError(field, \"Field is required\")\n66 +\n67 +    def handle_request(self, request: Request) -> Response:\n68 +        try:\n69 +            for middleware in self.middleware:\n70 +                request = middleware(request)\n71 +\n72 +            body = self.parse_json_body(request)\n73 +\n74 +            if request.method == \"POST\":\n75 +                self.validate_required_fields(body, [\"name\", \"email\"])\n76 +\n77 +            return Response(\n78 +                status_code=200,\n79 +                body={\"success\": True, \"data\": body}\n80 +            )\n81 +\n82 +        except ValidationError as e:\n83 +            return Response(\n84 +                status_code=e.status_code,\n85 +                body={\"error\": str(e), \"field\": e.field}\n86 +            )\n87 +        except RequestError as e:\n88 +            return Response(\n89 +                status_code=e.status_code,\n90 +                body={\"error\": str(e)}\n91 +            )\n92 +        except:\n93 +            logger.error(f\"Unexpected error: {traceback.format_exc()}\")\n94 +            return Response(\n95 +                status_code=500,\n96 +                body={\"error\": \"Internal server error\"}\n97 +            )\n98 +\n99 +    def process_batch(self, requests: list[Request]) -> list[Response]:\n100 +        responses = []\n101 +        for request in requests:\n102 +            try:\n103 +                response = self.handle_request(request)\n104 +                responses.append(response)\n105 +            except Exception as e:\n106 +                logger.error(f\"Batch request failed: {e}\")\n107 +                responses.append(Response(500, {\"error\": \"Failed\"}))\n108 +        return responses\n109 +\n110 +\n111 +def safe_divide(a: float, b: float) -> float:\n112 +    try:\n113 +        return a / b\n114 +    except ZeroDivisionError:\n115 +        return 0.0\n116 +    except:\n117 +        return None\n118 +\n119 +\n120 +def parse_config(config_str: str) -> dict:\n121 +    try:\n122 +        config = json.loads(config_str)\n123 +        return config\n124 +    except json.JSONDecodeError as e:\n125 +        raise ValueError(f\"Invalid config: {e}\")\n126 +    except Exception:\n127 +        raise\n128 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/api/request_handler.py\",\"relevantLinesStart\":86,\"relevantLinesEnd\":91},{\"relevantFile\":\"src/api/request_handler.py\",\"relevantLinesStart\":56,\"relevantLinesEnd\":57}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"except:\\n            logger.error(f\\\"Unexpected error: {traceback.format_exc()}\\\")\\n            return Response(\\n                status_code=500,\\n                body={\\\"error\\\": \\\"Internal server error\\\"}\\n            )\",\n    \"improvedCode\": \"except Exception:\\n            logger.error(f\\\"Unexpected error: {traceback.format_exc()}\\\")\\n            return Response(\\n                status_code=500,\\n                body={\\\"error\\\": \\\"Internal server error\\\"}\\n            )\",\n    \"relevantFile\": \"src/api/request_handler.py\",\n    \"relevantLinesEnd\": 91,\n    \"suggestionContent\": \"Multiple bare `except:` clauses catch all exceptions including `KeyboardInterrupt`, `SystemExit`, and `GeneratorExit`. This prevents proper program termination and can mask critical errors. Use `except Exception:` to catch only regular exceptions, or catch specific exception types.\",\n    \"oneSentenceSummary\": \"Bare except clause catches KeyboardInterrupt and SystemExit preventing proper shutdown\",\n    \"relevantLinesStart\": 86\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"except:\\n            raise ValidationError(\\\"body\\\", \\\"Invalid JSON\\\")\",\n    \"improvedCode\": \"except json.JSONDecodeError:\\n            raise ValidationError(\\\"body\\\", \\\"Invalid JSON\\\")\",\n    \"relevantFile\": \"src/api/request_handler.py\",\n    \"relevantLinesEnd\": 57,\n    \"suggestionContent\": \"In `parse_json_body`, the bare `except:` clause catches all exceptions and raises `ValidationError`, losing the original exception context. Also in `safe_divide`, bare `except:` returns `None` which silently hides errors like `TypeError` from invalid inputs.\",\n    \"oneSentenceSummary\": \"Bare except hides original error context and catches unintended exceptions\",\n    \"relevantLinesStart\": 56\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 40: src/metrics/counter_service.py",
    "vars": {
      "fileContent": "import threading\nfrom typing import Dict\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nimport time\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass MetricPoint:\n    value: float\n    timestamp: datetime\n\n\n@dataclass\nclass Counter:\n    name: str\n    value: int = 0\n    last_updated: datetime = None\n\n    def increment(self, amount: int = 1):\n        self.value += amount\n        self.last_updated = datetime.now()\n\n    def decrement(self, amount: int = 1):\n        self.value -= amount\n        self.last_updated = datetime.now()\n\n    def reset(self):\n        self.value = 0\n        self.last_updated = datetime.now()\n\n\nclass CounterService:\n    def __init__(self):\n        self._counters: Dict[str, Counter] = {}\n        self._lock = threading.Lock()\n\n    def get_or_create(self, name: str) -> Counter:\n        if name not in self._counters:\n            with self._lock:\n                if name not in self._counters:\n                    self._counters[name] = Counter(name=name)\n        return self._counters[name]\n\n    def increment(self, name: str, amount: int = 1):\n        counter = self.get_or_create(name)\n        counter.increment(amount)\n\n    def decrement(self, name: str, amount: int = 1):\n        counter = self.get_or_create(name)\n        counter.decrement(amount)\n\n    def get_value(self, name: str) -> int:\n        counter = self._counters.get(name)\n        return counter.value if counter else 0\n\n    def get_all_values(self) -> Dict[str, int]:\n        return {name: c.value for name, c in self._counters.items()}\n\n    def reset(self, name: str):\n        counter = self._counters.get(name)\n        if counter:\n            counter.reset()\n\n    def reset_all(self):\n        for counter in self._counters.values():\n            counter.reset()\n\n\nclass RateLimiter:\n    def __init__(self, max_requests: int, window_seconds: int):\n        self.max_requests = max_requests\n        self.window_seconds = window_seconds\n        self._requests: Dict[str, list] = {}\n        self._lock = threading.Lock()\n\n    def is_allowed(self, key: str) -> bool:\n        now = time.time()\n        cutoff = now - self.window_seconds\n\n        if key not in self._requests:\n            self._requests[key] = []\n\n        requests = self._requests[key]\n        requests = [t for t in requests if t > cutoff]\n        self._requests[key] = requests\n\n        if len(requests) < self.max_requests:\n            requests.append(now)\n            return True\n\n        return False\n\n    def get_remaining(self, key: str) -> int:\n        now = time.time()\n        cutoff = now - self.window_seconds\n\n        requests = self._requests.get(key, [])\n        valid_requests = [t for t in requests if t > cutoff]\n\n        return max(0, self.max_requests - len(valid_requests))\n\n\nclass MetricsAggregator:\n    def __init__(self):\n        self.metrics: Dict[str, list[MetricPoint]] = {}\n\n    def record(self, name: str, value: float):\n        if name not in self.metrics:\n            self.metrics[name] = []\n\n        self.metrics[name].append(MetricPoint(\n            value=value,\n            timestamp=datetime.now()\n        ))\n\n    def get_average(self, name: str) -> float:\n        points = self.metrics.get(name, [])\n        if not points:\n            return 0.0\n        return sum(p.value for p in points) / len(points)\n",
      "patchWithLinesStr": "## file: 'src/metrics/counter_service.py'\n\n@@ -0,0 +1,125 @@\n__new hunk__\n1 +import threading\n2 +from typing import Dict\n3 +from datetime import datetime\n4 +from dataclasses import dataclass, field\n5 +import time\n6 +import logging\n7 +\n8 +logger = logging.getLogger(__name__)\n9 +\n10 +\n11 +@dataclass\n12 +class MetricPoint:\n13 +    value: float\n14 +    timestamp: datetime\n15 +\n16 +\n17 +@dataclass\n18 +class Counter:\n19 +    name: str\n20 +    value: int = 0\n21 +    last_updated: datetime = None\n22 +\n23 +    def increment(self, amount: int = 1):\n24 +        self.value += amount\n25 +        self.last_updated = datetime.now()\n26 +\n27 +    def decrement(self, amount: int = 1):\n28 +        self.value -= amount\n29 +        self.last_updated = datetime.now()\n30 +\n31 +    def reset(self):\n32 +        self.value = 0\n33 +        self.last_updated = datetime.now()\n34 +\n35 +\n36 +class CounterService:\n37 +    def __init__(self):\n38 +        self._counters: Dict[str, Counter] = {}\n39 +        self._lock = threading.Lock()\n40 +\n41 +    def get_or_create(self, name: str) -> Counter:\n42 +        if name not in self._counters:\n43 +            with self._lock:\n44 +                if name not in self._counters:\n45 +                    self._counters[name] = Counter(name=name)\n46 +        return self._counters[name]\n47 +\n48 +    def increment(self, name: str, amount: int = 1):\n49 +        counter = self.get_or_create(name)\n50 +        counter.increment(amount)\n51 +\n52 +    def decrement(self, name: str, amount: int = 1):\n53 +        counter = self.get_or_create(name)\n54 +        counter.decrement(amount)\n55 +\n56 +    def get_value(self, name: str) -> int:\n57 +        counter = self._counters.get(name)\n58 +        return counter.value if counter else 0\n59 +\n60 +    def get_all_values(self) -> Dict[str, int]:\n61 +        return {name: c.value for name, c in self._counters.items()}\n62 +\n63 +    def reset(self, name: str):\n64 +        counter = self._counters.get(name)\n65 +        if counter:\n66 +            counter.reset()\n67 +\n68 +    def reset_all(self):\n69 +        for counter in self._counters.values():\n70 +            counter.reset()\n71 +\n72 +\n73 +class RateLimiter:\n74 +    def __init__(self, max_requests: int, window_seconds: int):\n75 +        self.max_requests = max_requests\n76 +        self.window_seconds = window_seconds\n77 +        self._requests: Dict[str, list] = {}\n78 +        self._lock = threading.Lock()\n79 +\n80 +    def is_allowed(self, key: str) -> bool:\n81 +        now = time.time()\n82 +        cutoff = now - self.window_seconds\n83 +\n84 +        if key not in self._requests:\n85 +            self._requests[key] = []\n86 +\n87 +        requests = self._requests[key]\n88 +        requests = [t for t in requests if t > cutoff]\n89 +        self._requests[key] = requests\n90 +\n91 +        if len(requests) < self.max_requests:\n92 +            requests.append(now)\n93 +            return True\n94 +\n95 +        return False\n96 +\n97 +    def get_remaining(self, key: str) -> int:\n98 +        now = time.time()\n99 +        cutoff = now - self.window_seconds\n100 +\n101 +        requests = self._requests.get(key, [])\n102 +        valid_requests = [t for t in requests if t > cutoff]\n103 +\n104 +        return max(0, self.max_requests - len(valid_requests))\n105 +\n106 +\n107 +class MetricsAggregator:\n108 +    def __init__(self):\n109 +        self.metrics: Dict[str, list[MetricPoint]] = {}\n110 +\n111 +    def record(self, name: str, value: float):\n112 +        if name not in self.metrics:\n113 +            self.metrics[name] = []\n114 +\n115 +        self.metrics[name].append(MetricPoint(\n116 +            value=value,\n117 +            timestamp=datetime.now()\n118 +        ))\n119 +\n120 +    def get_average(self, name: str) -> float:\n121 +        points = self.metrics.get(name, [])\n122 +        if not points:\n123 +            return 0.0\n124 +        return sum(p.value for p in points) / len(points)\n125 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/metrics/counter_service.py\",\"relevantLinesStart\":47,\"relevantLinesEnd\":49},{\"relevantFile\":\"src/metrics/counter_service.py\",\"relevantLinesStart\":76,\"relevantLinesEnd\":92}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def increment(self, name: str, amount: int = 1):\\n        counter = self.get_or_create(name)\\n        counter.increment(amount)\",\n    \"improvedCode\": \"def increment(self, name: str, amount: int = 1):\\n        with self._lock:\\n            counter = self.get_or_create(name)\\n            counter.increment(amount)\",\n    \"relevantFile\": \"src/metrics/counter_service.py\",\n    \"relevantLinesEnd\": 49,\n    \"suggestionContent\": \"The `Counter.increment` and `Counter.decrement` methods have a race condition. The operation `self.value += amount` is not atomic - it reads the value, adds, then writes. Multiple threads incrementing simultaneously can lose updates. The `CounterService.increment` calls counter methods outside any lock protection.\",\n    \"oneSentenceSummary\": \"Race condition in counter increment - += is not atomic, updates can be lost\",\n    \"relevantLinesStart\": 47\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Python\",\n    \"existingCode\": \"def is_allowed(self, key: str) -> bool:\\n        now = time.time()\\n        cutoff = now - self.window_seconds\\n\\n        if key not in self._requests:\\n            self._requests[key] = []\\n\\n        requests = self._requests[key]\\n        requests = [t for t in requests if t > cutoff]\\n        self._requests[key] = requests\\n\\n        if len(requests) < self.max_requests:\\n            requests.append(now)\\n            return True\\n\\n        return False\",\n    \"improvedCode\": \"def is_allowed(self, key: str) -> bool:\\n        with self._lock:\\n            now = time.time()\\n            cutoff = now - self.window_seconds\\n\\n            if key not in self._requests:\\n                self._requests[key] = []\\n\\n            requests = self._requests[key]\\n            requests = [t for t in requests if t > cutoff]\\n            self._requests[key] = requests\\n\\n            if len(requests) < self.max_requests:\\n                requests.append(now)\\n                return True\\n\\n            return False\",\n    \"relevantFile\": \"src/metrics/counter_service.py\",\n    \"relevantLinesEnd\": 92,\n    \"suggestionContent\": \"The `RateLimiter.is_allowed` method has a race condition. The check-then-act sequence (check if under limit, then append) is not atomic. Multiple threads can pass the check simultaneously and all append, exceeding the rate limit. The lock is defined but never used in `is_allowed`.\",\n    \"oneSentenceSummary\": \"Race condition in rate limiter - lock defined but not used in is_allowed\",\n    \"relevantLinesStart\": 76\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 41: src/main/java/com/app/analytics/MetricsCalculator.java",
    "vars": {
      "fileContent": "package com.app.analytics;\n\nimport java.util.*;\n\npublic class MetricsCalculator {\n\n    public Long sumValues(List<Long> values) {\n        Long sum = 0L;\n        for (Long value : values) {\n            sum += value;\n        }\n        return sum;\n    }\n\n    public Double calculateAverage(List<Integer> numbers) {\n        if (numbers.isEmpty()) {\n            return 0.0;\n        }\n\n        Integer sum = 0;\n        for (Integer num : numbers) {\n            sum += num;\n        }\n\n        return sum.doubleValue() / numbers.size();\n    }\n\n    public Integer findMax(int[] values) {\n        Integer max = Integer.MIN_VALUE;\n        for (int i = 0; i < values.length; i++) {\n            if (values[i] > max) {\n                max = values[i];\n            }\n        }\n        return max;\n    }\n\n    public Map<String, Long> countOccurrences(List<String> items) {\n        Map<String, Long> counts = new HashMap<>();\n        for (String item : items) {\n            Long current = counts.getOrDefault(item, 0L);\n            counts.put(item, current + 1);\n        }\n        return counts;\n    }\n\n    public Double calculatePercentile(List<Double> values, int percentile) {\n        if (values.isEmpty()) {\n            return 0.0;\n        }\n\n        Collections.sort(values);\n        Integer index = (int) Math.ceil(percentile / 100.0 * values.size()) - 1;\n        return values.get(Math.max(0, index));\n    }\n\n    public List<Integer> filterAboveThreshold(List<Integer> values, Integer threshold) {\n        List<Integer> result = new ArrayList<>();\n        for (Integer value : values) {\n            if (value > threshold) {\n                result.add(value);\n            }\n        }\n        return result;\n    }\n\n    public Double standardDeviation(List<Double> values) {\n        Double avg = values.stream().mapToDouble(d -> d).average().orElse(0.0);\n        Double sumSquares = 0.0;\n\n        for (Double value : values) {\n            Double diff = value - avg;\n            sumSquares += diff * diff;\n        }\n\n        return Math.sqrt(sumSquares / values.size());\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/analytics/MetricsCalculator.java'\n\n@@ -0,0 +1,79 @@\n__new hunk__\n1 +package com.app.analytics;\n2 +\n3 +import java.util.*;\n4 +\n5 +public class MetricsCalculator {\n6 +\n7 +    public Long sumValues(List<Long> values) {\n8 +        Long sum = 0L;\n9 +        for (Long value : values) {\n10 +            sum += value;\n11 +        }\n12 +        return sum;\n13 +    }\n14 +\n15 +    public Double calculateAverage(List<Integer> numbers) {\n16 +        if (numbers.isEmpty()) {\n17 +            return 0.0;\n18 +        }\n19 +\n20 +        Integer sum = 0;\n21 +        for (Integer num : numbers) {\n22 +            sum += num;\n23 +        }\n24 +\n25 +        return sum.doubleValue() / numbers.size();\n26 +    }\n27 +\n28 +    public Integer findMax(int[] values) {\n29 +        Integer max = Integer.MIN_VALUE;\n30 +        for (int i = 0; i < values.length; i++) {\n31 +            if (values[i] > max) {\n32 +                max = values[i];\n33 +            }\n34 +        }\n35 +        return max;\n36 +    }\n37 +\n38 +    public Map<String, Long> countOccurrences(List<String> items) {\n39 +        Map<String, Long> counts = new HashMap<>();\n40 +        for (String item : items) {\n41 +            Long current = counts.getOrDefault(item, 0L);\n42 +            counts.put(item, current + 1);\n43 +        }\n44 +        return counts;\n45 +    }\n46 +\n47 +    public Double calculatePercentile(List<Double> values, int percentile) {\n48 +        if (values.isEmpty()) {\n49 +            return 0.0;\n50 +        }\n51 +\n52 +        Collections.sort(values);\n53 +        Integer index = (int) Math.ceil(percentile / 100.0 * values.size()) - 1;\n54 +        return values.get(Math.max(0, index));\n55 +    }\n56 +\n57 +    public List<Integer> filterAboveThreshold(List<Integer> values, Integer threshold) {\n58 +        List<Integer> result = new ArrayList<>();\n59 +        for (Integer value : values) {\n60 +            if (value > threshold) {\n61 +                result.add(value);\n62 +            }\n63 +        }\n64 +        return result;\n65 +    }\n66 +\n67 +    public Double standardDeviation(List<Double> values) {\n68 +        Double avg = values.stream().mapToDouble(d -> d).average().orElse(0.0);\n69 +        Double sumSquares = 0.0;\n70 +\n71 +        for (Double value : values) {\n72 +            Double diff = value - avg;\n73 +            sumSquares += diff * diff;\n74 +        }\n75 +\n76 +        return Math.sqrt(sumSquares / values.size());\n77 +    }\n78 +}\n79 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/analytics/MetricsCalculator.java\",\"relevantLinesStart\":7,\"relevantLinesEnd\":12}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public Long sumValues(List<Long> values) {\\n        Long sum = 0L;\\n        for (Long value : values) {\\n            sum += value;\\n        }\\n        return sum;\\n    }\",\n    \"improvedCode\": \"public Long sumValues(List<Long> values) {\\n        long sum = 0L;\\n        for (Long value : values) {\\n            sum += value;  // Only one unboxing per iteration\\n        }\\n        return sum;  // One boxing at return\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/analytics/MetricsCalculator.java\",\n    \"relevantLinesEnd\": 12,\n    \"suggestionContent\": \"Multiple methods use boxed types (`Long`, `Integer`, `Double`) for loop counters and accumulators. Each arithmetic operation causes auto-unboxing, computation, then auto-boxing back to objects, creating garbage. In `sumValues`, processing 1 million items creates 1 million temporary Long objects. Use primitive types (`long`, `int`, `double`) for local calculations.\",\n    \"oneSentenceSummary\": \"Auto-boxing in loops creates millions of temporary objects - use primitive types\",\n    \"relevantLinesStart\": 7\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 42: src/main/java/com/app/service/SessionManager.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport com.app.model.Session;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.time.Instant;\nimport java.util.*;\n\npublic class SessionManager {\n    private static final Logger logger = LoggerFactory.getLogger(SessionManager.class);\n\n    private final Map<String, Session> sessions = new HashMap<>();\n    private final long sessionTimeoutMs;\n\n    public SessionManager(long sessionTimeoutMs) {\n        this.sessionTimeoutMs = sessionTimeoutMs;\n    }\n\n    public Session createSession(String userId) {\n        String sessionId = UUID.randomUUID().toString();\n        Session session = new Session(sessionId, userId, Instant.now());\n        sessions.put(sessionId, session);\n        logger.info(\"Created session {} for user {}\", sessionId, userId);\n        return session;\n    }\n\n    public Optional<Session> getSession(String sessionId) {\n        Session session = sessions.get(sessionId);\n        if (session != null && !isExpired(session)) {\n            session.setLastAccessed(Instant.now());\n            return Optional.of(session);\n        }\n        return Optional.empty();\n    }\n\n    public void invalidateSession(String sessionId) {\n        sessions.remove(sessionId);\n        logger.info(\"Invalidated session {}\", sessionId);\n    }\n\n    public void cleanupExpiredSessions() {\n        for (String sessionId : sessions.keySet()) {\n            Session session = sessions.get(sessionId);\n            if (isExpired(session)) {\n                sessions.remove(sessionId);\n                logger.info(\"Removed expired session {}\", sessionId);\n            }\n        }\n    }\n\n    public void invalidateUserSessions(String userId) {\n        for (Map.Entry<String, Session> entry : sessions.entrySet()) {\n            if (entry.getValue().getUserId().equals(userId)) {\n                sessions.remove(entry.getKey());\n                logger.info(\"Invalidated session {} for user {}\", entry.getKey(), userId);\n            }\n        }\n    }\n\n    public List<Session> getActiveSessions() {\n        List<Session> active = new ArrayList<>();\n        for (Session session : sessions.values()) {\n            if (!isExpired(session)) {\n                active.add(session);\n            }\n        }\n        return active;\n    }\n\n    public int getActiveSessionCount() {\n        int count = 0;\n        for (Session session : sessions.values()) {\n            if (!isExpired(session)) {\n                count++;\n            }\n        }\n        return count;\n    }\n\n    private boolean isExpired(Session session) {\n        long elapsed = Instant.now().toEpochMilli() - session.getLastAccessed().toEpochMilli();\n        return elapsed > sessionTimeoutMs;\n    }\n\n    public Map<String, Integer> getSessionCountByUser() {\n        Map<String, Integer> counts = new HashMap<>();\n        for (Session session : sessions.values()) {\n            String userId = session.getUserId();\n            counts.put(userId, counts.getOrDefault(userId, 0) + 1);\n        }\n        return counts;\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/SessionManager.java'\n\n@@ -0,0 +1,95 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import com.app.model.Session;\n4 +import org.slf4j.Logger;\n5 +import org.slf4j.LoggerFactory;\n6 +\n7 +import java.time.Instant;\n8 +import java.util.*;\n9 +\n10 +public class SessionManager {\n11 +    private static final Logger logger = LoggerFactory.getLogger(SessionManager.class);\n12 +\n13 +    private final Map<String, Session> sessions = new HashMap<>();\n14 +    private final long sessionTimeoutMs;\n15 +\n16 +    public SessionManager(long sessionTimeoutMs) {\n17 +        this.sessionTimeoutMs = sessionTimeoutMs;\n18 +    }\n19 +\n20 +    public Session createSession(String userId) {\n21 +        String sessionId = UUID.randomUUID().toString();\n22 +        Session session = new Session(sessionId, userId, Instant.now());\n23 +        sessions.put(sessionId, session);\n24 +        logger.info(\"Created session {} for user {}\", sessionId, userId);\n25 +        return session;\n26 +    }\n27 +\n28 +    public Optional<Session> getSession(String sessionId) {\n29 +        Session session = sessions.get(sessionId);\n30 +        if (session != null && !isExpired(session)) {\n31 +            session.setLastAccessed(Instant.now());\n32 +            return Optional.of(session);\n33 +        }\n34 +        return Optional.empty();\n35 +    }\n36 +\n37 +    public void invalidateSession(String sessionId) {\n38 +        sessions.remove(sessionId);\n39 +        logger.info(\"Invalidated session {}\", sessionId);\n40 +    }\n41 +\n42 +    public void cleanupExpiredSessions() {\n43 +        for (String sessionId : sessions.keySet()) {\n44 +            Session session = sessions.get(sessionId);\n45 +            if (isExpired(session)) {\n46 +                sessions.remove(sessionId);\n47 +                logger.info(\"Removed expired session {}\", sessionId);\n48 +            }\n49 +        }\n50 +    }\n51 +\n52 +    public void invalidateUserSessions(String userId) {\n53 +        for (Map.Entry<String, Session> entry : sessions.entrySet()) {\n54 +            if (entry.getValue().getUserId().equals(userId)) {\n55 +                sessions.remove(entry.getKey());\n56 +                logger.info(\"Invalidated session {} for user {}\", entry.getKey(), userId);\n57 +            }\n58 +        }\n59 +    }\n60 +\n61 +    public List<Session> getActiveSessions() {\n62 +        List<Session> active = new ArrayList<>();\n63 +        for (Session session : sessions.values()) {\n64 +            if (!isExpired(session)) {\n65 +                active.add(session);\n66 +            }\n67 +        }\n68 +        return active;\n69 +    }\n70 +\n71 +    public int getActiveSessionCount() {\n72 +        int count = 0;\n73 +        for (Session session : sessions.values()) {\n74 +            if (!isExpired(session)) {\n75 +                count++;\n76 +            }\n77 +        }\n78 +        return count;\n79 +    }\n80 +\n81 +    private boolean isExpired(Session session) {\n82 +        long elapsed = Instant.now().toEpochMilli() - session.getLastAccessed().toEpochMilli();\n83 +        return elapsed > sessionTimeoutMs;\n84 +    }\n85 +\n86 +    public Map<String, Integer> getSessionCountByUser() {\n87 +        Map<String, Integer> counts = new HashMap<>();\n88 +        for (Session session : sessions.values()) {\n89 +            String userId = session.getUserId();\n90 +            counts.put(userId, counts.getOrDefault(userId, 0) + 1);\n91 +        }\n92 +        return counts;\n93 +    }\n94 +}\n95 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/SessionManager.java\",\"relevantLinesStart\":42,\"relevantLinesEnd\":48},{\"relevantFile\":\"src/main/java/com/app/service/SessionManager.java\",\"relevantLinesStart\":51,\"relevantLinesEnd\":55}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"for (String sessionId : sessions.keySet()) {\\n            Session session = sessions.get(sessionId);\\n            if (isExpired(session)) {\\n                sessions.remove(sessionId);\",\n    \"improvedCode\": \"Iterator<Map.Entry<String, Session>> iterator = sessions.entrySet().iterator();\\n        while (iterator.hasNext()) {\\n            Map.Entry<String, Session> entry = iterator.next();\\n            if (isExpired(entry.getValue())) {\\n                iterator.remove();\",\n    \"relevantFile\": \"src/main/java/com/app/service/SessionManager.java\",\n    \"relevantLinesEnd\": 48,\n    \"suggestionContent\": \"The `cleanupExpiredSessions` method iterates over `sessions.keySet()` and calls `sessions.remove()` inside the loop. This throws `ConcurrentModificationException` because you cannot modify a HashMap while iterating over it. Use an Iterator with `iterator.remove()` or collect keys to remove first.\",\n    \"oneSentenceSummary\": \"ConcurrentModificationException - removing from HashMap while iterating over keySet\",\n    \"relevantLinesStart\": 42\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"for (Map.Entry<String, Session> entry : sessions.entrySet()) {\\n            if (entry.getValue().getUserId().equals(userId)) {\\n                sessions.remove(entry.getKey());\",\n    \"improvedCode\": \"sessions.entrySet().removeIf(entry -> entry.getValue().getUserId().equals(userId));\",\n    \"relevantFile\": \"src/main/java/com/app/service/SessionManager.java\",\n    \"relevantLinesEnd\": 55,\n    \"suggestionContent\": \"The `invalidateUserSessions` method has the same issue - it iterates over `sessions.entrySet()` and calls `sessions.remove()` inside the loop, causing `ConcurrentModificationException`.\",\n    \"oneSentenceSummary\": \"ConcurrentModificationException - removing from HashMap while iterating over entrySet\",\n    \"relevantLinesStart\": 51\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 43: src/main/java/com/app/controller/FileController.java",
    "vars": {
      "fileContent": "package com.app.controller;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.*;\nimport java.nio.file.*;\n\npublic class FileController {\n    private static final Logger logger = LoggerFactory.getLogger(FileController.class);\n\n    private final String uploadDirectory;\n    private final String documentsDirectory;\n\n    public FileController(String uploadDirectory, String documentsDirectory) {\n        this.uploadDirectory = uploadDirectory;\n        this.documentsDirectory = documentsDirectory;\n    }\n\n    public byte[] downloadFile(String filename) throws IOException {\n        Path filePath = Paths.get(uploadDirectory, filename);\n        logger.info(\"Downloading file: {}\", filePath);\n\n        return Files.readAllBytes(filePath);\n    }\n\n    public void uploadFile(String filename, byte[] content) throws IOException {\n        Path filePath = Paths.get(uploadDirectory, filename);\n        Files.createDirectories(filePath.getParent());\n        Files.write(filePath, content);\n\n        logger.info(\"Uploaded file: {}\", filePath);\n    }\n\n    public void deleteFile(String filename) throws IOException {\n        Path filePath = Paths.get(uploadDirectory, filename);\n        Files.deleteIfExists(filePath);\n\n        logger.info(\"Deleted file: {}\", filePath);\n    }\n\n    public String readDocument(String docName) throws IOException {\n        String filePath = documentsDirectory + \"/\" + docName;\n        return new String(Files.readAllBytes(Paths.get(filePath)));\n    }\n\n    public boolean fileExists(String filename) {\n        Path filePath = Paths.get(uploadDirectory, filename);\n        return Files.exists(filePath);\n    }\n\n    public void moveFile(String source, String destination) throws IOException {\n        Path sourcePath = Paths.get(uploadDirectory, source);\n        Path destPath = Paths.get(uploadDirectory, destination);\n\n        Files.createDirectories(destPath.getParent());\n        Files.move(sourcePath, destPath);\n    }\n\n    public String[] listFiles(String directory) throws IOException {\n        Path dirPath = Paths.get(uploadDirectory, directory);\n\n        return Files.list(dirPath)\n            .map(path -> path.getFileName().toString())\n            .toArray(String[]::new);\n    }\n\n    public void copyToDocuments(String uploadedFile, String docName) throws IOException {\n        Path source = Paths.get(uploadDirectory, uploadedFile);\n        Path dest = Paths.get(documentsDirectory, docName);\n\n        Files.copy(source, dest, StandardCopyOption.REPLACE_EXISTING);\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/controller/FileController.java'\n\n@@ -0,0 +1,75 @@\n__new hunk__\n1 +package com.app.controller;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import java.io.*;\n7 +import java.nio.file.*;\n8 +\n9 +public class FileController {\n10 +    private static final Logger logger = LoggerFactory.getLogger(FileController.class);\n11 +\n12 +    private final String uploadDirectory;\n13 +    private final String documentsDirectory;\n14 +\n15 +    public FileController(String uploadDirectory, String documentsDirectory) {\n16 +        this.uploadDirectory = uploadDirectory;\n17 +        this.documentsDirectory = documentsDirectory;\n18 +    }\n19 +\n20 +    public byte[] downloadFile(String filename) throws IOException {\n21 +        Path filePath = Paths.get(uploadDirectory, filename);\n22 +        logger.info(\"Downloading file: {}\", filePath);\n23 +\n24 +        return Files.readAllBytes(filePath);\n25 +    }\n26 +\n27 +    public void uploadFile(String filename, byte[] content) throws IOException {\n28 +        Path filePath = Paths.get(uploadDirectory, filename);\n29 +        Files.createDirectories(filePath.getParent());\n30 +        Files.write(filePath, content);\n31 +\n32 +        logger.info(\"Uploaded file: {}\", filePath);\n33 +    }\n34 +\n35 +    public void deleteFile(String filename) throws IOException {\n36 +        Path filePath = Paths.get(uploadDirectory, filename);\n37 +        Files.deleteIfExists(filePath);\n38 +\n39 +        logger.info(\"Deleted file: {}\", filePath);\n40 +    }\n41 +\n42 +    public String readDocument(String docName) throws IOException {\n43 +        String filePath = documentsDirectory + \"/\" + docName;\n44 +        return new String(Files.readAllBytes(Paths.get(filePath)));\n45 +    }\n46 +\n47 +    public boolean fileExists(String filename) {\n48 +        Path filePath = Paths.get(uploadDirectory, filename);\n49 +        return Files.exists(filePath);\n50 +    }\n51 +\n52 +    public void moveFile(String source, String destination) throws IOException {\n53 +        Path sourcePath = Paths.get(uploadDirectory, source);\n54 +        Path destPath = Paths.get(uploadDirectory, destination);\n55 +\n56 +        Files.createDirectories(destPath.getParent());\n57 +        Files.move(sourcePath, destPath);\n58 +    }\n59 +\n60 +    public String[] listFiles(String directory) throws IOException {\n61 +        Path dirPath = Paths.get(uploadDirectory, directory);\n62 +\n63 +        return Files.list(dirPath)\n64 +            .map(path -> path.getFileName().toString())\n65 +            .toArray(String[]::new);\n66 +    }\n67 +\n68 +    public void copyToDocuments(String uploadedFile, String docName) throws IOException {\n69 +        Path source = Paths.get(uploadDirectory, uploadedFile);\n70 +        Path dest = Paths.get(documentsDirectory, docName);\n71 +\n72 +        Files.copy(source, dest, StandardCopyOption.REPLACE_EXISTING);\n73 +    }\n74 +}\n75 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/controller/FileController.java\",\"relevantLinesStart\":20,\"relevantLinesEnd\":25},{\"relevantFile\":\"src/main/java/com/app/controller/FileController.java\",\"relevantLinesStart\":35,\"relevantLinesEnd\":37}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public byte[] downloadFile(String filename) throws IOException {\\n        Path filePath = Paths.get(uploadDirectory, filename);\\n        logger.info(\\\"Downloading file: {}\\\", filePath);\\n        \\n        return Files.readAllBytes(filePath);\\n    }\",\n    \"improvedCode\": \"public byte[] downloadFile(String filename) throws IOException {\\n        Path basePath = Paths.get(uploadDirectory).toAbsolutePath().normalize();\\n        Path filePath = basePath.resolve(filename).normalize();\\n        \\n        if (!filePath.startsWith(basePath)) {\\n            throw new SecurityException(\\\"Invalid file path\\\");\\n        }\\n        \\n        logger.info(\\\"Downloading file: {}\\\", filePath);\\n        return Files.readAllBytes(filePath);\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/controller/FileController.java\",\n    \"relevantLinesEnd\": 25,\n    \"suggestionContent\": \"The `downloadFile` method concatenates user input `filename` to the upload directory without validation. An attacker can use `../../../etc/passwd` to read arbitrary files outside the upload directory. Validate that the resolved path is within the allowed directory.\",\n    \"oneSentenceSummary\": \"Path traversal in downloadFile allows reading arbitrary system files\",\n    \"relevantLinesStart\": 20\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public void deleteFile(String filename) throws IOException {\\n        Path filePath = Paths.get(uploadDirectory, filename);\\n        Files.deleteIfExists(filePath);\",\n    \"improvedCode\": \"public void deleteFile(String filename) throws IOException {\\n        Path basePath = Paths.get(uploadDirectory).toAbsolutePath().normalize();\\n        Path filePath = basePath.resolve(filename).normalize();\\n        \\n        if (!filePath.startsWith(basePath)) {\\n            throw new SecurityException(\\\"Invalid file path\\\");\\n        }\\n        \\n        Files.deleteIfExists(filePath);\",\n    \"relevantFile\": \"src/main/java/com/app/controller/FileController.java\",\n    \"relevantLinesEnd\": 37,\n    \"suggestionContent\": \"The `deleteFile` method is also vulnerable to path traversal. An attacker can delete arbitrary files on the system by providing `../../../important/file` as the filename.\",\n    \"oneSentenceSummary\": \"Path traversal in deleteFile allows deleting arbitrary system files\",\n    \"relevantLinesStart\": 35\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 44: src/main/java/com/app/service/UserService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport com.app.model.User;\nimport com.app.repository.UserRepository;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.List;\nimport java.util.Optional;\n\npublic class UserService {\n    private static final Logger logger = LoggerFactory.getLogger(UserService.class);\n\n    private final UserRepository userRepository;\n\n    public UserService(UserRepository userRepository) {\n        this.userRepository = userRepository;\n    }\n\n    public Optional<User> findByEmail(String email) {\n        return userRepository.findByEmail(email);\n    }\n\n    public boolean isAdmin(String userId) {\n        Optional<User> user = userRepository.findById(userId);\n        if (user.isPresent()) {\n            String role = user.get().getRole();\n            return role == \"ADMIN\";\n        }\n        return false;\n    }\n\n    public boolean validateUserStatus(User user, String expectedStatus) {\n        String currentStatus = user.getStatus();\n        if (currentStatus == expectedStatus) {\n            logger.info(\"User {} has expected status: {}\", user.getId(), expectedStatus);\n            return true;\n        }\n        return false;\n    }\n\n    public List<User> findUsersByRole(String role) {\n        return userRepository.findAll().stream()\n            .filter(user -> user.getRole().equals(role))\n            .toList();\n    }\n\n    public void updateUserRole(String userId, String newRole) {\n        Optional<User> user = userRepository.findById(userId);\n        if (user.isPresent()) {\n            User u = user.get();\n            String oldRole = u.getRole();\n            u.setRole(newRole);\n            userRepository.save(u);\n            logger.info(\"Updated user {} role from {} to {}\", userId, oldRole, newRole);\n        }\n    }\n\n    public boolean hasPermission(User user, String permission) {\n        List<String> permissions = user.getPermissions();\n        for (String p : permissions) {\n            if (p == permission) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    public int countActiveUsers() {\n        return (int) userRepository.findAll().stream()\n            .filter(user -> \"ACTIVE\".equals(user.getStatus()))\n            .count();\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/UserService.java'\n\n@@ -0,0 +1,75 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import com.app.model.User;\n4 +import com.app.repository.UserRepository;\n5 +import org.slf4j.Logger;\n6 +import org.slf4j.LoggerFactory;\n7 +\n8 +import java.util.List;\n9 +import java.util.Optional;\n10 +\n11 +public class UserService {\n12 +    private static final Logger logger = LoggerFactory.getLogger(UserService.class);\n13 +\n14 +    private final UserRepository userRepository;\n15 +\n16 +    public UserService(UserRepository userRepository) {\n17 +        this.userRepository = userRepository;\n18 +    }\n19 +\n20 +    public Optional<User> findByEmail(String email) {\n21 +        return userRepository.findByEmail(email);\n22 +    }\n23 +\n24 +    public boolean isAdmin(String userId) {\n25 +        Optional<User> user = userRepository.findById(userId);\n26 +        if (user.isPresent()) {\n27 +            String role = user.get().getRole();\n28 +            return role == \"ADMIN\";\n29 +        }\n30 +        return false;\n31 +    }\n32 +\n33 +    public boolean validateUserStatus(User user, String expectedStatus) {\n34 +        String currentStatus = user.getStatus();\n35 +        if (currentStatus == expectedStatus) {\n36 +            logger.info(\"User {} has expected status: {}\", user.getId(), expectedStatus);\n37 +            return true;\n38 +        }\n39 +        return false;\n40 +    }\n41 +\n42 +    public List<User> findUsersByRole(String role) {\n43 +        return userRepository.findAll().stream()\n44 +            .filter(user -> user.getRole().equals(role))\n45 +            .toList();\n46 +    }\n47 +\n48 +    public void updateUserRole(String userId, String newRole) {\n49 +        Optional<User> user = userRepository.findById(userId);\n50 +        if (user.isPresent()) {\n51 +            User u = user.get();\n52 +            String oldRole = u.getRole();\n53 +            u.setRole(newRole);\n54 +            userRepository.save(u);\n55 +            logger.info(\"Updated user {} role from {} to {}\", userId, oldRole, newRole);\n56 +        }\n57 +    }\n58 +\n59 +    public boolean hasPermission(User user, String permission) {\n60 +        List<String> permissions = user.getPermissions();\n61 +        for (String p : permissions) {\n62 +            if (p == permission) {\n63 +                return true;\n64 +            }\n65 +        }\n66 +        return false;\n67 +    }\n68 +\n69 +    public int countActiveUsers() {\n70 +        return (int) userRepository.findAll().stream()\n71 +            .filter(user -> \"ACTIVE\".equals(user.getStatus()))\n72 +            .count();\n73 +    }\n74 +}\n75 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/UserService.java\",\"relevantLinesStart\":26,\"relevantLinesEnd\":26},{\"relevantFile\":\"src/main/java/com/app/service/UserService.java\",\"relevantLinesStart\":32,\"relevantLinesEnd\":32},{\"relevantFile\":\"src/main/java/com/app/service/UserService.java\",\"relevantLinesStart\":57,\"relevantLinesEnd\":57}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"return role == \\\"ADMIN\\\";\",\n    \"improvedCode\": \"return \\\"ADMIN\\\".equals(role);\",\n    \"relevantFile\": \"src/main/java/com/app/service/UserService.java\",\n    \"relevantLinesEnd\": 26,\n    \"suggestionContent\": \"The `isAdmin` method compares strings using `==` operator (`role == \\\"ADMIN\\\"`). In Java, `==` compares object references, not content. Since `role` comes from the database/user object and `\\\"ADMIN\\\"` is a string literal, they are different objects in memory. This comparison will almost always return false even when the role is \\\"ADMIN\\\". Use `.equals()` for string content comparison.\",\n    \"oneSentenceSummary\": \"String comparison with == instead of .equals() - admin check always fails\",\n    \"relevantLinesStart\": 26\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"if (currentStatus == expectedStatus) {\",\n    \"improvedCode\": \"if (expectedStatus.equals(currentStatus)) {\",\n    \"relevantFile\": \"src/main/java/com/app/service/UserService.java\",\n    \"relevantLinesEnd\": 32,\n    \"suggestionContent\": \"The `validateUserStatus` method uses `==` to compare `currentStatus` with `expectedStatus`. Both are String parameters that may come from different sources, so they won't be the same object reference. This will return false even when the strings have the same content.\",\n    \"oneSentenceSummary\": \"String parameter comparison with == fails for equal string values\",\n    \"relevantLinesStart\": 32\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"if (p == permission) {\",\n    \"improvedCode\": \"if (permission.equals(p)) {\",\n    \"relevantFile\": \"src/main/java/com/app/service/UserService.java\",\n    \"relevantLinesEnd\": 57,\n    \"suggestionContent\": \"The `hasPermission` method uses `==` to compare permission strings in a loop. This will fail to match permissions even when the string content is identical, causing the method to incorrectly deny permissions.\",\n    \"oneSentenceSummary\": \"Permission check uses == for strings - always denies valid permissions\",\n    \"relevantLinesStart\": 57\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 45: src/main/java/com/app/finance/TaxCalculator.java",
    "vars": {
      "fileContent": "package com.app.finance;\n\nimport java.util.*;\n\npublic class TaxCalculator {\n\n    private static final double TAX_RATE_LOW = 0.10;\n    private static final double TAX_RATE_MED = 0.20;\n    private static final double TAX_RATE_HIGH = 0.30;\n\n    private static final double BRACKET_LOW = 10000.0;\n    private static final double BRACKET_MED = 50000.0;\n\n    public double calculateTax(double income) {\n        if (income <= BRACKET_LOW) {\n            return income * TAX_RATE_LOW;\n        } else if (income <= BRACKET_MED) {\n            return BRACKET_LOW * TAX_RATE_LOW + (income - BRACKET_LOW) * TAX_RATE_MED;\n        } else {\n            return BRACKET_LOW * TAX_RATE_LOW +\n                   (BRACKET_MED - BRACKET_LOW) * TAX_RATE_MED +\n                   (income - BRACKET_MED) * TAX_RATE_HIGH;\n        }\n    }\n\n    public boolean isEligibleForRefund(double paid, double owed) {\n        double difference = paid - owed;\n        if (difference == 0.0) {\n            return false;\n        }\n        return difference > 0;\n    }\n\n    public boolean verifyCalculation(double expected, double actual) {\n        return expected == actual;\n    }\n\n    public double roundToTwoDecimals(double value) {\n        return Math.round(value * 100.0) / 100.0;\n    }\n\n    public boolean hasZeroBalance(double balance) {\n        return balance == 0.0;\n    }\n\n    public List<Double> applyDiscounts(List<Double> prices, double discountPercent) {\n        List<Double> discounted = new ArrayList<>();\n        for (double price : prices) {\n            double discount = price * (discountPercent / 100.0);\n            double finalPrice = price - discount;\n            discounted.add(finalPrice);\n        }\n        return discounted;\n    }\n\n    public boolean isPriceMatch(double price1, double price2) {\n        double diff = price1 - price2;\n        return diff == 0.0;\n    }\n\n    public double calculateTotal(double[] amounts) {\n        double total = 0.0;\n        for (double amount : amounts) {\n            total += amount;\n        }\n        return total;\n    }\n\n    public boolean isWithinBudget(double spent, double budget) {\n        return spent <= budget || spent == budget;\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/finance/TaxCalculator.java'\n\n@@ -0,0 +1,73 @@\n__new hunk__\n1 +package com.app.finance;\n2 +\n3 +import java.util.*;\n4 +\n5 +public class TaxCalculator {\n6 +\n7 +    private static final double TAX_RATE_LOW = 0.10;\n8 +    private static final double TAX_RATE_MED = 0.20;\n9 +    private static final double TAX_RATE_HIGH = 0.30;\n10 +\n11 +    private static final double BRACKET_LOW = 10000.0;\n12 +    private static final double BRACKET_MED = 50000.0;\n13 +\n14 +    public double calculateTax(double income) {\n15 +        if (income <= BRACKET_LOW) {\n16 +            return income * TAX_RATE_LOW;\n17 +        } else if (income <= BRACKET_MED) {\n18 +            return BRACKET_LOW * TAX_RATE_LOW + (income - BRACKET_LOW) * TAX_RATE_MED;\n19 +        } else {\n20 +            return BRACKET_LOW * TAX_RATE_LOW +\n21 +                   (BRACKET_MED - BRACKET_LOW) * TAX_RATE_MED +\n22 +                   (income - BRACKET_MED) * TAX_RATE_HIGH;\n23 +        }\n24 +    }\n25 +\n26 +    public boolean isEligibleForRefund(double paid, double owed) {\n27 +        double difference = paid - owed;\n28 +        if (difference == 0.0) {\n29 +            return false;\n30 +        }\n31 +        return difference > 0;\n32 +    }\n33 +\n34 +    public boolean verifyCalculation(double expected, double actual) {\n35 +        return expected == actual;\n36 +    }\n37 +\n38 +    public double roundToTwoDecimals(double value) {\n39 +        return Math.round(value * 100.0) / 100.0;\n40 +    }\n41 +\n42 +    public boolean hasZeroBalance(double balance) {\n43 +        return balance == 0.0;\n44 +    }\n45 +\n46 +    public List<Double> applyDiscounts(List<Double> prices, double discountPercent) {\n47 +        List<Double> discounted = new ArrayList<>();\n48 +        for (double price : prices) {\n49 +            double discount = price * (discountPercent / 100.0);\n50 +            double finalPrice = price - discount;\n51 +            discounted.add(finalPrice);\n52 +        }\n53 +        return discounted;\n54 +    }\n55 +\n56 +    public boolean isPriceMatch(double price1, double price2) {\n57 +        double diff = price1 - price2;\n58 +        return diff == 0.0;\n59 +    }\n60 +\n61 +    public double calculateTotal(double[] amounts) {\n62 +        double total = 0.0;\n63 +        for (double amount : amounts) {\n64 +            total += amount;\n65 +        }\n66 +        return total;\n67 +    }\n68 +\n69 +    public boolean isWithinBudget(double spent, double budget) {\n70 +        return spent <= budget || spent == budget;\n71 +    }\n72 +}\n73 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/finance/TaxCalculator.java\",\"relevantLinesStart\":35,\"relevantLinesEnd\":37},{\"relevantFile\":\"src/main/java/com/app/finance/TaxCalculator.java\",\"relevantLinesStart\":28,\"relevantLinesEnd\":31}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public boolean verifyCalculation(double expected, double actual) {\\n        return expected == actual;\\n    }\",\n    \"improvedCode\": \"private static final double EPSILON = 0.0001;\\n\\npublic boolean verifyCalculation(double expected, double actual) {\\n        return Math.abs(expected - actual) < EPSILON;\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/finance/TaxCalculator.java\",\n    \"relevantLinesEnd\": 37,\n    \"suggestionContent\": \"Multiple methods compare floating point numbers using `==` (`verifyCalculation`, `hasZeroBalance`, `isPriceMatch`). Due to floating point representation, `0.1 + 0.2 != 0.3` in Java. Financial calculations accumulate rounding errors, so two numbers that should be equal may differ by tiny amounts like 0.0000001. Use epsilon comparison or BigDecimal.\",\n    \"oneSentenceSummary\": \"Floating point == comparison fails due to precision errors - use epsilon\",\n    \"relevantLinesStart\": 35\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"double difference = paid - owed;\\n        if (difference == 0.0) {\\n            return false;\\n        }\",\n    \"improvedCode\": \"double difference = paid - owed;\\n        if (Math.abs(difference) < 0.0001) {\\n            return false;\\n        }\",\n    \"relevantFile\": \"src/main/java/com/app/finance/TaxCalculator.java\",\n    \"relevantLinesEnd\": 31,\n    \"suggestionContent\": \"The `isEligibleForRefund` method compares `difference == 0.0` which may incorrectly pass when the difference is a tiny non-zero value like 1e-15 due to floating point arithmetic. It should use epsilon comparison.\",\n    \"oneSentenceSummary\": \"Zero comparison with floating point fails for near-zero differences\",\n    \"relevantLinesStart\": 28\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 46: src/main/java/com/app/service/SchedulerService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.text.SimpleDateFormat;\nimport java.time.*;\nimport java.time.format.DateTimeFormatter;\nimport java.util.*;\n\npublic class SchedulerService {\n    private static final Logger logger = LoggerFactory.getLogger(SchedulerService.class);\n\n    private static final SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n    private static final DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\");\n\n    public String formatDate(Date date) {\n        return dateFormat.format(date);\n    }\n\n    public Date parseDate(String dateStr) throws Exception {\n        return dateFormat.parse(dateStr);\n    }\n\n    public boolean isBusinessHours(LocalDateTime dateTime) {\n        int hour = dateTime.getHour();\n        DayOfWeek day = dateTime.getDayOfWeek();\n\n        if (day == DayOfWeek.SATURDAY || day == DayOfWeek.SUNDAY) {\n            return false;\n        }\n\n        return hour >= 9 && hour < 17;\n    }\n\n    public long calculateDaysBetween(Date start, Date end) {\n        long diffMs = end.getTime() - start.getTime();\n        return diffMs / (1000 * 60 * 60 * 24);\n    }\n\n    public LocalDate addBusinessDays(LocalDate date, int days) {\n        LocalDate result = date;\n        int addedDays = 0;\n\n        while (addedDays < days) {\n            result = result.plusDays(1);\n            if (result.getDayOfWeek() != DayOfWeek.SATURDAY &&\n                result.getDayOfWeek() != DayOfWeek.SUNDAY) {\n                addedDays++;\n            }\n        }\n\n        return result;\n    }\n\n    public boolean isSameDay(Date date1, Date date2) {\n        Calendar cal1 = Calendar.getInstance();\n        Calendar cal2 = Calendar.getInstance();\n        cal1.setTime(date1);\n        cal2.setTime(date2);\n\n        return cal1.get(Calendar.YEAR) == cal2.get(Calendar.YEAR) &&\n               cal1.get(Calendar.DAY_OF_YEAR) == cal2.get(Calendar.DAY_OF_YEAR);\n    }\n\n    public List<String> generateDailySlots(LocalDate date) {\n        List<String> slots = new ArrayList<>();\n        LocalDateTime startOfDay = date.atStartOfDay();\n\n        for (int hour = 9; hour < 17; hour++) {\n            LocalDateTime slotTime = startOfDay.plusHours(hour);\n            slots.add(formatter.format(slotTime));\n        }\n\n        return slots;\n    }\n\n    public Date getNextMonday(Date from) {\n        Calendar cal = Calendar.getInstance();\n        cal.setTime(from);\n\n        while (cal.get(Calendar.DAY_OF_WEEK) != Calendar.MONDAY) {\n            cal.add(Calendar.DAY_OF_MONTH, 1);\n        }\n\n        return cal.getTime();\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/SchedulerService.java'\n\n@@ -0,0 +1,89 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import java.text.SimpleDateFormat;\n7 +import java.time.*;\n8 +import java.time.format.DateTimeFormatter;\n9 +import java.util.*;\n10 +\n11 +public class SchedulerService {\n12 +    private static final Logger logger = LoggerFactory.getLogger(SchedulerService.class);\n13 +\n14 +    private static final SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n15 +    private static final DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\");\n16 +\n17 +    public String formatDate(Date date) {\n18 +        return dateFormat.format(date);\n19 +    }\n20 +\n21 +    public Date parseDate(String dateStr) throws Exception {\n22 +        return dateFormat.parse(dateStr);\n23 +    }\n24 +\n25 +    public boolean isBusinessHours(LocalDateTime dateTime) {\n26 +        int hour = dateTime.getHour();\n27 +        DayOfWeek day = dateTime.getDayOfWeek();\n28 +\n29 +        if (day == DayOfWeek.SATURDAY || day == DayOfWeek.SUNDAY) {\n30 +            return false;\n31 +        }\n32 +\n33 +        return hour >= 9 && hour < 17;\n34 +    }\n35 +\n36 +    public long calculateDaysBetween(Date start, Date end) {\n37 +        long diffMs = end.getTime() - start.getTime();\n38 +        return diffMs / (1000 * 60 * 60 * 24);\n39 +    }\n40 +\n41 +    public LocalDate addBusinessDays(LocalDate date, int days) {\n42 +        LocalDate result = date;\n43 +        int addedDays = 0;\n44 +\n45 +        while (addedDays < days) {\n46 +            result = result.plusDays(1);\n47 +            if (result.getDayOfWeek() != DayOfWeek.SATURDAY &&\n48 +                result.getDayOfWeek() != DayOfWeek.SUNDAY) {\n49 +                addedDays++;\n50 +            }\n51 +        }\n52 +\n53 +        return result;\n54 +    }\n55 +\n56 +    public boolean isSameDay(Date date1, Date date2) {\n57 +        Calendar cal1 = Calendar.getInstance();\n58 +        Calendar cal2 = Calendar.getInstance();\n59 +        cal1.setTime(date1);\n60 +        cal2.setTime(date2);\n61 +\n62 +        return cal1.get(Calendar.YEAR) == cal2.get(Calendar.YEAR) &&\n63 +               cal1.get(Calendar.DAY_OF_YEAR) == cal2.get(Calendar.DAY_OF_YEAR);\n64 +    }\n65 +\n66 +    public List<String> generateDailySlots(LocalDate date) {\n67 +        List<String> slots = new ArrayList<>();\n68 +        LocalDateTime startOfDay = date.atStartOfDay();\n69 +\n70 +        for (int hour = 9; hour < 17; hour++) {\n71 +            LocalDateTime slotTime = startOfDay.plusHours(hour);\n72 +            slots.add(formatter.format(slotTime));\n73 +        }\n74 +\n75 +        return slots;\n76 +    }\n77 +\n78 +    public Date getNextMonday(Date from) {\n79 +        Calendar cal = Calendar.getInstance();\n80 +        cal.setTime(from);\n81 +\n82 +        while (cal.get(Calendar.DAY_OF_WEEK) != Calendar.MONDAY) {\n83 +            cal.add(Calendar.DAY_OF_MONTH, 1);\n84 +        }\n85 +\n86 +        return cal.getTime();\n87 +    }\n88 +}\n89 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/SchedulerService.java\",\"relevantLinesStart\":14,\"relevantLinesEnd\":14},{\"relevantFile\":\"src/main/java/com/app/service/SchedulerService.java\",\"relevantLinesStart\":35,\"relevantLinesEnd\":38}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"private static final SimpleDateFormat dateFormat = new SimpleDateFormat(\\\"yyyy-MM-dd HH:mm:ss\\\");\",\n    \"improvedCode\": \"private static final DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(\\\"yyyy-MM-dd HH:mm:ss\\\");\\n\\npublic String formatDate(Date date) {\\n    return dateTimeFormatter.format(date.toInstant().atZone(ZoneId.systemDefault()));\\n}\",\n    \"relevantFile\": \"src/main/java/com/app/service/SchedulerService.java\",\n    \"relevantLinesEnd\": 14,\n    \"suggestionContent\": \"The `SimpleDateFormat` instance is stored as a static field but `SimpleDateFormat` is not thread-safe. Multiple threads calling `formatDate` or `parseDate` concurrently will corrupt internal state, causing wrong dates or exceptions. Create a new instance per call or use `DateTimeFormatter` which is thread-safe.\",\n    \"oneSentenceSummary\": \"SimpleDateFormat is not thread-safe - concurrent access corrupts dates\",\n    \"relevantLinesStart\": 14\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public long calculateDaysBetween(Date start, Date end) {\\n        long diffMs = end.getTime() - start.getTime();\\n        return diffMs / (1000 * 60 * 60 * 24);\\n    }\",\n    \"improvedCode\": \"public long calculateDaysBetween(Date start, Date end) {\\n        LocalDate startDate = start.toInstant().atZone(ZoneId.systemDefault()).toLocalDate();\\n        LocalDate endDate = end.toInstant().atZone(ZoneId.systemDefault()).toLocalDate();\\n        return ChronoUnit.DAYS.between(startDate, endDate);\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/service/SchedulerService.java\",\n    \"relevantLinesEnd\": 38,\n    \"suggestionContent\": \"The `calculateDaysBetween` method divides milliseconds by a fixed day length, but this doesn't account for daylight saving time transitions. A day with DST change is 23 or 25 hours, causing off-by-one errors. Use `java.time` classes like `ChronoUnit.DAYS.between()`.\",\n    \"oneSentenceSummary\": \"Days calculation ignores DST - returns wrong count across timezone transitions\",\n    \"relevantLinesStart\": 35\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 47: src/main/java/com/app/security/CryptoService.java",
    "vars": {
      "fileContent": "package com.app.security;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.crypto.*;\nimport javax.crypto.spec.*;\nimport java.security.*;\nimport java.util.Base64;\n\npublic class CryptoService {\n    private static final Logger logger = LoggerFactory.getLogger(CryptoService.class);\n\n    private static final String ALGORITHM = \"DES\";\n    private static final String TRANSFORMATION = \"DES/ECB/PKCS5Padding\";\n    private static final byte[] KEY_BYTES = \"12345678\".getBytes();\n\n    public String encrypt(String plaintext) throws Exception {\n        SecretKeySpec keySpec = new SecretKeySpec(KEY_BYTES, ALGORITHM);\n        Cipher cipher = Cipher.getInstance(TRANSFORMATION);\n        cipher.init(Cipher.ENCRYPT_MODE, keySpec);\n\n        byte[] encrypted = cipher.doFinal(plaintext.getBytes());\n        return Base64.getEncoder().encodeToString(encrypted);\n    }\n\n    public String decrypt(String ciphertext) throws Exception {\n        SecretKeySpec keySpec = new SecretKeySpec(KEY_BYTES, ALGORITHM);\n        Cipher cipher = Cipher.getInstance(TRANSFORMATION);\n        cipher.init(Cipher.DECRYPT_MODE, keySpec);\n\n        byte[] decrypted = cipher.doFinal(Base64.getDecoder().decode(ciphertext));\n        return new String(decrypted);\n    }\n\n    public String hashPassword(String password) throws Exception {\n        MessageDigest md = MessageDigest.getInstance(\"MD5\");\n        byte[] hash = md.digest(password.getBytes());\n\n        StringBuilder sb = new StringBuilder();\n        for (byte b : hash) {\n            sb.append(String.format(\"%02x\", b));\n        }\n        return sb.toString();\n    }\n\n    public String generateToken() {\n        return String.valueOf(System.currentTimeMillis());\n    }\n\n    public boolean verifyPassword(String password, String hash) throws Exception {\n        String computed = hashPassword(password);\n        return computed.equals(hash);\n    }\n\n    public String sign(String data) throws Exception {\n        MessageDigest md = MessageDigest.getInstance(\"SHA-1\");\n        byte[] hash = md.digest((data + KEY_BYTES).getBytes());\n        return Base64.getEncoder().encodeToString(hash);\n    }\n\n    public SecureRandom getSecureRandom() {\n        return new SecureRandom();\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/security/CryptoService.java'\n\n@@ -0,0 +1,66 @@\n__new hunk__\n1 +package com.app.security;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import javax.crypto.*;\n7 +import javax.crypto.spec.*;\n8 +import java.security.*;\n9 +import java.util.Base64;\n10 +\n11 +public class CryptoService {\n12 +    private static final Logger logger = LoggerFactory.getLogger(CryptoService.class);\n13 +\n14 +    private static final String ALGORITHM = \"DES\";\n15 +    private static final String TRANSFORMATION = \"DES/ECB/PKCS5Padding\";\n16 +    private static final byte[] KEY_BYTES = \"12345678\".getBytes();\n17 +\n18 +    public String encrypt(String plaintext) throws Exception {\n19 +        SecretKeySpec keySpec = new SecretKeySpec(KEY_BYTES, ALGORITHM);\n20 +        Cipher cipher = Cipher.getInstance(TRANSFORMATION);\n21 +        cipher.init(Cipher.ENCRYPT_MODE, keySpec);\n22 +\n23 +        byte[] encrypted = cipher.doFinal(plaintext.getBytes());\n24 +        return Base64.getEncoder().encodeToString(encrypted);\n25 +    }\n26 +\n27 +    public String decrypt(String ciphertext) throws Exception {\n28 +        SecretKeySpec keySpec = new SecretKeySpec(KEY_BYTES, ALGORITHM);\n29 +        Cipher cipher = Cipher.getInstance(TRANSFORMATION);\n30 +        cipher.init(Cipher.DECRYPT_MODE, keySpec);\n31 +\n32 +        byte[] decrypted = cipher.doFinal(Base64.getDecoder().decode(ciphertext));\n33 +        return new String(decrypted);\n34 +    }\n35 +\n36 +    public String hashPassword(String password) throws Exception {\n37 +        MessageDigest md = MessageDigest.getInstance(\"MD5\");\n38 +        byte[] hash = md.digest(password.getBytes());\n39 +\n40 +        StringBuilder sb = new StringBuilder();\n41 +        for (byte b : hash) {\n42 +            sb.append(String.format(\"%02x\", b));\n43 +        }\n44 +        return sb.toString();\n45 +    }\n46 +\n47 +    public String generateToken() {\n48 +        return String.valueOf(System.currentTimeMillis());\n49 +    }\n50 +\n51 +    public boolean verifyPassword(String password, String hash) throws Exception {\n52 +        String computed = hashPassword(password);\n53 +        return computed.equals(hash);\n54 +    }\n55 +\n56 +    public String sign(String data) throws Exception {\n57 +        MessageDigest md = MessageDigest.getInstance(\"SHA-1\");\n58 +        byte[] hash = md.digest((data + KEY_BYTES).getBytes());\n59 +        return Base64.getEncoder().encodeToString(hash);\n60 +    }\n61 +\n62 +    public SecureRandom getSecureRandom() {\n63 +        return new SecureRandom();\n64 +    }\n65 +}\n66 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/security/CryptoService.java\",\"relevantLinesStart\":14,\"relevantLinesEnd\":15},{\"relevantFile\":\"src/main/java/com/app/security/CryptoService.java\",\"relevantLinesStart\":37,\"relevantLinesEnd\":37},{\"relevantFile\":\"src/main/java/com/app/security/CryptoService.java\",\"relevantLinesStart\":46,\"relevantLinesEnd\":48}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"private static final String ALGORITHM = \\\"DES\\\";\\n    private static final String TRANSFORMATION = \\\"DES/ECB/PKCS5Padding\\\";\",\n    \"improvedCode\": \"private static final String ALGORITHM = \\\"AES\\\";\\n    private static final String TRANSFORMATION = \\\"AES/GCM/NoPadding\\\";\",\n    \"relevantFile\": \"src/main/java/com/app/security/CryptoService.java\",\n    \"relevantLinesEnd\": 15,\n    \"suggestionContent\": \"The encryption uses DES algorithm which is deprecated and cryptographically broken. DES has a 56-bit key that can be brute-forced in hours. Also uses ECB mode which reveals patterns in encrypted data. Use AES with GCM mode instead.\",\n    \"oneSentenceSummary\": \"DES encryption is broken and ECB mode reveals data patterns\",\n    \"relevantLinesStart\": 14\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"MessageDigest md = MessageDigest.getInstance(\\\"MD5\\\");\",\n    \"improvedCode\": \"// Use BCrypt or Argon2 for password hashing\\n// String hash = BCrypt.hashpw(password, BCrypt.gensalt(12));\",\n    \"relevantFile\": \"src/main/java/com/app/security/CryptoService.java\",\n    \"relevantLinesEnd\": 37,\n    \"suggestionContent\": \"The `hashPassword` method uses MD5 which is cryptographically broken and too fast for password hashing. Attackers can compute billions of MD5 hashes per second. Use bcrypt, scrypt, or Argon2 for password hashing.\",\n    \"oneSentenceSummary\": \"MD5 for passwords is insecure - too fast and cryptographically broken\",\n    \"relevantLinesStart\": 37\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public String generateToken() {\\n        return String.valueOf(System.currentTimeMillis());\\n    }\",\n    \"improvedCode\": \"public String generateToken() {\\n        byte[] bytes = new byte[32];\\n        new SecureRandom().nextBytes(bytes);\\n        return Base64.getUrlEncoder().withoutPadding().encodeToString(bytes);\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/security/CryptoService.java\",\n    \"relevantLinesEnd\": 48,\n    \"suggestionContent\": \"The `generateToken` method uses `System.currentTimeMillis()` which is predictable. An attacker who knows approximately when a token was generated can guess it. Use `SecureRandom` to generate tokens.\",\n    \"oneSentenceSummary\": \"Token generation using timestamp is predictable and insecure\",\n    \"relevantLinesStart\": 46\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 48: src/main/java/com/app/service/XmlParserService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.w3c.dom.*;\nimport org.xml.sax.InputSource;\n\nimport javax.xml.parsers.*;\nimport javax.xml.transform.*;\nimport javax.xml.transform.dom.DOMSource;\nimport javax.xml.transform.stream.StreamResult;\nimport java.io.*;\nimport java.util.*;\n\npublic class XmlParserService {\n    private static final Logger logger = LoggerFactory.getLogger(XmlParserService.class);\n\n    public Document parseXml(String xmlContent) throws Exception {\n        DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n        DocumentBuilder builder = factory.newDocumentBuilder();\n\n        InputSource inputSource = new InputSource(new StringReader(xmlContent));\n        return builder.parse(inputSource);\n    }\n\n    public Document parseXmlFile(String filePath) throws Exception {\n        DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n        DocumentBuilder builder = factory.newDocumentBuilder();\n\n        return builder.parse(new File(filePath));\n    }\n\n    public Map<String, String> extractData(Document doc) {\n        Map<String, String> data = new HashMap<>();\n\n        NodeList nodes = doc.getElementsByTagName(\"*\");\n        for (int i = 0; i < nodes.getLength(); i++) {\n            Node node = nodes.item(i);\n            if (node.getNodeType() == Node.ELEMENT_NODE) {\n                Element element = (Element) node;\n                if (element.getChildNodes().getLength() == 1 &&\n                    element.getFirstChild().getNodeType() == Node.TEXT_NODE) {\n                    data.put(element.getTagName(), element.getTextContent());\n                }\n            }\n        }\n\n        return data;\n    }\n\n    public String extractValue(Document doc, String tagName) {\n        NodeList nodes = doc.getElementsByTagName(tagName);\n        if (nodes.getLength() > 0) {\n            return nodes.item(0).getTextContent();\n        }\n        return null;\n    }\n\n    public List<String> extractAllValues(Document doc, String tagName) {\n        List<String> values = new ArrayList<>();\n        NodeList nodes = doc.getElementsByTagName(tagName);\n\n        for (int i = 0; i < nodes.getLength(); i++) {\n            values.add(nodes.item(i).getTextContent());\n        }\n\n        return values;\n    }\n\n    public String documentToString(Document doc) throws Exception {\n        TransformerFactory tf = TransformerFactory.newInstance();\n        Transformer transformer = tf.newTransformer();\n        StringWriter writer = new StringWriter();\n        transformer.transform(new DOMSource(doc), new StreamResult(writer));\n        return writer.toString();\n    }\n\n    public Document createDocument(String rootElement) throws Exception {\n        DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n        DocumentBuilder builder = factory.newDocumentBuilder();\n        Document doc = builder.newDocument();\n\n        Element root = doc.createElement(rootElement);\n        doc.appendChild(root);\n\n        return doc;\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/XmlParserService.java'\n\n@@ -0,0 +1,89 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +import org.w3c.dom.*;\n6 +import org.xml.sax.InputSource;\n7 +\n8 +import javax.xml.parsers.*;\n9 +import javax.xml.transform.*;\n10 +import javax.xml.transform.dom.DOMSource;\n11 +import javax.xml.transform.stream.StreamResult;\n12 +import java.io.*;\n13 +import java.util.*;\n14 +\n15 +public class XmlParserService {\n16 +    private static final Logger logger = LoggerFactory.getLogger(XmlParserService.class);\n17 +\n18 +    public Document parseXml(String xmlContent) throws Exception {\n19 +        DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n20 +        DocumentBuilder builder = factory.newDocumentBuilder();\n21 +\n22 +        InputSource inputSource = new InputSource(new StringReader(xmlContent));\n23 +        return builder.parse(inputSource);\n24 +    }\n25 +\n26 +    public Document parseXmlFile(String filePath) throws Exception {\n27 +        DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n28 +        DocumentBuilder builder = factory.newDocumentBuilder();\n29 +\n30 +        return builder.parse(new File(filePath));\n31 +    }\n32 +\n33 +    public Map<String, String> extractData(Document doc) {\n34 +        Map<String, String> data = new HashMap<>();\n35 +\n36 +        NodeList nodes = doc.getElementsByTagName(\"*\");\n37 +        for (int i = 0; i < nodes.getLength(); i++) {\n38 +            Node node = nodes.item(i);\n39 +            if (node.getNodeType() == Node.ELEMENT_NODE) {\n40 +                Element element = (Element) node;\n41 +                if (element.getChildNodes().getLength() == 1 &&\n42 +                    element.getFirstChild().getNodeType() == Node.TEXT_NODE) {\n43 +                    data.put(element.getTagName(), element.getTextContent());\n44 +                }\n45 +            }\n46 +        }\n47 +\n48 +        return data;\n49 +    }\n50 +\n51 +    public String extractValue(Document doc, String tagName) {\n52 +        NodeList nodes = doc.getElementsByTagName(tagName);\n53 +        if (nodes.getLength() > 0) {\n54 +            return nodes.item(0).getTextContent();\n55 +        }\n56 +        return null;\n57 +    }\n58 +\n59 +    public List<String> extractAllValues(Document doc, String tagName) {\n60 +        List<String> values = new ArrayList<>();\n61 +        NodeList nodes = doc.getElementsByTagName(tagName);\n62 +\n63 +        for (int i = 0; i < nodes.getLength(); i++) {\n64 +            values.add(nodes.item(i).getTextContent());\n65 +        }\n66 +\n67 +        return values;\n68 +    }\n69 +\n70 +    public String documentToString(Document doc) throws Exception {\n71 +        TransformerFactory tf = TransformerFactory.newInstance();\n72 +        Transformer transformer = tf.newTransformer();\n73 +        StringWriter writer = new StringWriter();\n74 +        transformer.transform(new DOMSource(doc), new StreamResult(writer));\n75 +        return writer.toString();\n76 +    }\n77 +\n78 +    public Document createDocument(String rootElement) throws Exception {\n79 +        DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n80 +        DocumentBuilder builder = factory.newDocumentBuilder();\n81 +        Document doc = builder.newDocument();\n82 +\n83 +        Element root = doc.createElement(rootElement);\n84 +        doc.appendChild(root);\n85 +\n86 +        return doc;\n87 +    }\n88 +}\n89 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/XmlParserService.java\",\"relevantLinesStart\":19,\"relevantLinesEnd\":20}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\\n        DocumentBuilder builder = factory.newDocumentBuilder();\",\n    \"improvedCode\": \"DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\\n        factory.setFeature(\\\"http://apache.org/xml/features/disallow-doctype-decl\\\", true);\\n        factory.setFeature(\\\"http://xml.org/sax/features/external-general-entities\\\", false);\\n        factory.setFeature(\\\"http://xml.org/sax/features/external-parameter-entities\\\", false);\\n        DocumentBuilder builder = factory.newDocumentBuilder();\",\n    \"relevantFile\": \"src/main/java/com/app/service/XmlParserService.java\",\n    \"relevantLinesEnd\": 20,\n    \"suggestionContent\": \"The `parseXml` and `parseXmlFile` methods create `DocumentBuilderFactory` without disabling external entity processing. This allows XXE attacks where malicious XML like `<!DOCTYPE foo [<!ENTITY xxe SYSTEM \\\"file:///etc/passwd\\\">]>` can read local files or make network requests. Disable DTDs and external entities.\",\n    \"oneSentenceSummary\": \"XXE vulnerability - external entities not disabled allows file disclosure\",\n    \"relevantLinesStart\": 19\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 49: src/main/java/com/app/config/ConfigurationManager.java",
    "vars": {
      "fileContent": "package com.app.config;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.*;\nimport java.util.*;\n\npublic class ConfigurationManager {\n    private static final Logger logger = LoggerFactory.getLogger(ConfigurationManager.class);\n\n    private static ConfigurationManager instance;\n    private Properties config;\n    private long lastLoadTime;\n    private final String configPath;\n\n    private ConfigurationManager(String configPath) {\n        this.configPath = configPath;\n        this.config = new Properties();\n        loadConfig();\n    }\n\n    public static ConfigurationManager getInstance(String configPath) {\n        if (instance == null) {\n            synchronized (ConfigurationManager.class) {\n                if (instance == null) {\n                    instance = new ConfigurationManager(configPath);\n                }\n            }\n        }\n        return instance;\n    }\n\n    private void loadConfig() {\n        try (FileInputStream fis = new FileInputStream(configPath)) {\n            config.load(fis);\n            lastLoadTime = System.currentTimeMillis();\n            logger.info(\"Configuration loaded from {}\", configPath);\n        } catch (IOException e) {\n            logger.error(\"Failed to load configuration\", e);\n        }\n    }\n\n    public String get(String key) {\n        return config.getProperty(key);\n    }\n\n    public String get(String key, String defaultValue) {\n        return config.getProperty(key, defaultValue);\n    }\n\n    public int getInt(String key, int defaultValue) {\n        String value = config.getProperty(key);\n        if (value != null) {\n            try {\n                return Integer.parseInt(value);\n            } catch (NumberFormatException e) {\n                logger.warn(\"Invalid integer value for key {}: {}\", key, value);\n            }\n        }\n        return defaultValue;\n    }\n\n    public boolean getBoolean(String key, boolean defaultValue) {\n        String value = config.getProperty(key);\n        if (value != null) {\n            return Boolean.parseBoolean(value);\n        }\n        return defaultValue;\n    }\n\n    public void reload() {\n        loadConfig();\n    }\n\n    public long getLastLoadTime() {\n        return lastLoadTime;\n    }\n\n    public Set<String> getKeys() {\n        return config.stringPropertyNames();\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/config/ConfigurationManager.java'\n\n@@ -0,0 +1,84 @@\n__new hunk__\n1 +package com.app.config;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import java.io.*;\n7 +import java.util.*;\n8 +\n9 +public class ConfigurationManager {\n10 +    private static final Logger logger = LoggerFactory.getLogger(ConfigurationManager.class);\n11 +\n12 +    private static ConfigurationManager instance;\n13 +    private Properties config;\n14 +    private long lastLoadTime;\n15 +    private final String configPath;\n16 +\n17 +    private ConfigurationManager(String configPath) {\n18 +        this.configPath = configPath;\n19 +        this.config = new Properties();\n20 +        loadConfig();\n21 +    }\n22 +\n23 +    public static ConfigurationManager getInstance(String configPath) {\n24 +        if (instance == null) {\n25 +            synchronized (ConfigurationManager.class) {\n26 +                if (instance == null) {\n27 +                    instance = new ConfigurationManager(configPath);\n28 +                }\n29 +            }\n30 +        }\n31 +        return instance;\n32 +    }\n33 +\n34 +    private void loadConfig() {\n35 +        try (FileInputStream fis = new FileInputStream(configPath)) {\n36 +            config.load(fis);\n37 +            lastLoadTime = System.currentTimeMillis();\n38 +            logger.info(\"Configuration loaded from {}\", configPath);\n39 +        } catch (IOException e) {\n40 +            logger.error(\"Failed to load configuration\", e);\n41 +        }\n42 +    }\n43 +\n44 +    public String get(String key) {\n45 +        return config.getProperty(key);\n46 +    }\n47 +\n48 +    public String get(String key, String defaultValue) {\n49 +        return config.getProperty(key, defaultValue);\n50 +    }\n51 +\n52 +    public int getInt(String key, int defaultValue) {\n53 +        String value = config.getProperty(key);\n54 +        if (value != null) {\n55 +            try {\n56 +                return Integer.parseInt(value);\n57 +            } catch (NumberFormatException e) {\n58 +                logger.warn(\"Invalid integer value for key {}: {}\", key, value);\n59 +            }\n60 +        }\n61 +        return defaultValue;\n62 +    }\n63 +\n64 +    public boolean getBoolean(String key, boolean defaultValue) {\n65 +        String value = config.getProperty(key);\n66 +        if (value != null) {\n67 +            return Boolean.parseBoolean(value);\n68 +        }\n69 +        return defaultValue;\n70 +    }\n71 +\n72 +    public void reload() {\n73 +        loadConfig();\n74 +    }\n75 +\n76 +    public long getLastLoadTime() {\n77 +        return lastLoadTime;\n78 +    }\n79 +\n80 +    public Set<String> getKeys() {\n81 +        return config.stringPropertyNames();\n82 +    }\n83 +}\n84 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/config/ConfigurationManager.java\",\"relevantLinesStart\":12,\"relevantLinesEnd\":12}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"private static ConfigurationManager instance;\",\n    \"improvedCode\": \"private static volatile ConfigurationManager instance;\",\n    \"relevantFile\": \"src/main/java/com/app/config/ConfigurationManager.java\",\n    \"relevantLinesEnd\": 12,\n    \"suggestionContent\": \"The double-checked locking pattern is broken without `volatile` keyword on the `instance` field. Without volatile, a thread may see a partially constructed object due to instruction reordering. Thread A may publish the reference before the constructor finishes, and Thread B may use an incompletely initialized object. Add `volatile` to the instance field.\",\n    \"oneSentenceSummary\": \"Double-checked locking without volatile - threads may see partially constructed object\",\n    \"relevantLinesStart\": 12\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 50: src/main/java/com/app/service/FileService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.*;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.*;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Properties;\n\npublic class FileService {\n    private static final Logger logger = LoggerFactory.getLogger(FileService.class);\n\n    private final Path baseDirectory;\n\n    public FileService(String baseDirectory) {\n        this.baseDirectory = Paths.get(baseDirectory);\n    }\n\n    public String readFile(String filename) throws IOException {\n        Path filePath = baseDirectory.resolve(filename);\n        FileInputStream fis = new FileInputStream(filePath.toFile());\n        InputStreamReader isr = new InputStreamReader(fis, StandardCharsets.UTF_8);\n        BufferedReader reader = new BufferedReader(isr);\n\n        StringBuilder content = new StringBuilder();\n        String line;\n        while ((line = reader.readLine()) != null) {\n            content.append(line).append(\"\\n\");\n        }\n\n        return content.toString();\n    }\n\n    public void writeFile(String filename, String content) throws IOException {\n        Path filePath = baseDirectory.resolve(filename);\n        FileOutputStream fos = new FileOutputStream(filePath.toFile());\n        OutputStreamWriter osw = new OutputStreamWriter(fos, StandardCharsets.UTF_8);\n        BufferedWriter writer = new BufferedWriter(osw);\n\n        writer.write(content);\n        writer.flush();\n    }\n\n    public Properties loadProperties(String filename) throws IOException {\n        Path filePath = baseDirectory.resolve(filename);\n        FileInputStream fis = new FileInputStream(filePath.toFile());\n\n        Properties props = new Properties();\n        props.load(fis);\n\n        return props;\n    }\n\n    public List<String> readLines(String filename) throws IOException {\n        Path filePath = baseDirectory.resolve(filename);\n        BufferedReader reader = Files.newBufferedReader(filePath);\n\n        List<String> lines = new ArrayList<>();\n        String line;\n        while ((line = reader.readLine()) != null) {\n            lines.add(line);\n        }\n\n        return lines;\n    }\n\n    public void copyFile(String source, String destination) throws IOException {\n        Path sourcePath = baseDirectory.resolve(source);\n        Path destPath = baseDirectory.resolve(destination);\n\n        FileInputStream fis = new FileInputStream(sourcePath.toFile());\n        FileOutputStream fos = new FileOutputStream(destPath.toFile());\n\n        byte[] buffer = new byte[8192];\n        int bytesRead;\n        while ((bytesRead = fis.read(buffer)) != -1) {\n            fos.write(buffer, 0, bytesRead);\n        }\n\n        fos.flush();\n    }\n\n    public byte[] readBinaryFile(String filename) throws IOException {\n        Path filePath = baseDirectory.resolve(filename);\n        return Files.readAllBytes(filePath);\n    }\n\n    public long getFileSize(String filename) throws IOException {\n        Path filePath = baseDirectory.resolve(filename);\n        return Files.size(filePath);\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/FileService.java'\n\n@@ -0,0 +1,96 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import java.io.*;\n7 +import java.nio.charset.StandardCharsets;\n8 +import java.nio.file.*;\n9 +import java.util.ArrayList;\n10 +import java.util.List;\n11 +import java.util.Properties;\n12 +\n13 +public class FileService {\n14 +    private static final Logger logger = LoggerFactory.getLogger(FileService.class);\n15 +\n16 +    private final Path baseDirectory;\n17 +\n18 +    public FileService(String baseDirectory) {\n19 +        this.baseDirectory = Paths.get(baseDirectory);\n20 +    }\n21 +\n22 +    public String readFile(String filename) throws IOException {\n23 +        Path filePath = baseDirectory.resolve(filename);\n24 +        FileInputStream fis = new FileInputStream(filePath.toFile());\n25 +        InputStreamReader isr = new InputStreamReader(fis, StandardCharsets.UTF_8);\n26 +        BufferedReader reader = new BufferedReader(isr);\n27 +\n28 +        StringBuilder content = new StringBuilder();\n29 +        String line;\n30 +        while ((line = reader.readLine()) != null) {\n31 +            content.append(line).append(\"\\n\");\n32 +        }\n33 +\n34 +        return content.toString();\n35 +    }\n36 +\n37 +    public void writeFile(String filename, String content) throws IOException {\n38 +        Path filePath = baseDirectory.resolve(filename);\n39 +        FileOutputStream fos = new FileOutputStream(filePath.toFile());\n40 +        OutputStreamWriter osw = new OutputStreamWriter(fos, StandardCharsets.UTF_8);\n41 +        BufferedWriter writer = new BufferedWriter(osw);\n42 +\n43 +        writer.write(content);\n44 +        writer.flush();\n45 +    }\n46 +\n47 +    public Properties loadProperties(String filename) throws IOException {\n48 +        Path filePath = baseDirectory.resolve(filename);\n49 +        FileInputStream fis = new FileInputStream(filePath.toFile());\n50 +\n51 +        Properties props = new Properties();\n52 +        props.load(fis);\n53 +\n54 +        return props;\n55 +    }\n56 +\n57 +    public List<String> readLines(String filename) throws IOException {\n58 +        Path filePath = baseDirectory.resolve(filename);\n59 +        BufferedReader reader = Files.newBufferedReader(filePath);\n60 +\n61 +        List<String> lines = new ArrayList<>();\n62 +        String line;\n63 +        while ((line = reader.readLine()) != null) {\n64 +            lines.add(line);\n65 +        }\n66 +\n67 +        return lines;\n68 +    }\n69 +\n70 +    public void copyFile(String source, String destination) throws IOException {\n71 +        Path sourcePath = baseDirectory.resolve(source);\n72 +        Path destPath = baseDirectory.resolve(destination);\n73 +\n74 +        FileInputStream fis = new FileInputStream(sourcePath.toFile());\n75 +        FileOutputStream fos = new FileOutputStream(destPath.toFile());\n76 +\n77 +        byte[] buffer = new byte[8192];\n78 +        int bytesRead;\n79 +        while ((bytesRead = fis.read(buffer)) != -1) {\n80 +            fos.write(buffer, 0, bytesRead);\n81 +        }\n82 +\n83 +        fos.flush();\n84 +    }\n85 +\n86 +    public byte[] readBinaryFile(String filename) throws IOException {\n87 +        Path filePath = baseDirectory.resolve(filename);\n88 +        return Files.readAllBytes(filePath);\n89 +    }\n90 +\n91 +    public long getFileSize(String filename) throws IOException {\n92 +        Path filePath = baseDirectory.resolve(filename);\n93 +        return Files.size(filePath);\n94 +    }\n95 +}\n96 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/FileService.java\",\"relevantLinesStart\":23,\"relevantLinesEnd\":25},{\"relevantFile\":\"src/main/java/com/app/service/FileService.java\",\"relevantLinesStart\":38,\"relevantLinesEnd\":43},{\"relevantFile\":\"src/main/java/com/app/service/FileService.java\",\"relevantLinesStart\":71,\"relevantLinesEnd\":72}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"FileInputStream fis = new FileInputStream(filePath.toFile());\\n        InputStreamReader isr = new InputStreamReader(fis, StandardCharsets.UTF_8);\\n        BufferedReader reader = new BufferedReader(isr);\",\n    \"improvedCode\": \"try (FileInputStream fis = new FileInputStream(filePath.toFile());\\n             InputStreamReader isr = new InputStreamReader(fis, StandardCharsets.UTF_8);\\n             BufferedReader reader = new BufferedReader(isr)) {\",\n    \"relevantFile\": \"src/main/java/com/app/service/FileService.java\",\n    \"relevantLinesEnd\": 25,\n    \"suggestionContent\": \"The `readFile` method opens `FileInputStream`, `InputStreamReader`, and `BufferedReader` but never closes them. If an exception occurs or even in normal execution, these resources leak. Use try-with-resources to ensure streams are closed.\",\n    \"oneSentenceSummary\": \"Resource leak - FileInputStream and readers never closed in readFile\",\n    \"relevantLinesStart\": 23\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"FileOutputStream fos = new FileOutputStream(filePath.toFile());\\n        OutputStreamWriter osw = new OutputStreamWriter(fos, StandardCharsets.UTF_8);\\n        BufferedWriter writer = new BufferedWriter(osw);\\n        \\n        writer.write(content);\\n        writer.flush();\",\n    \"improvedCode\": \"try (FileOutputStream fos = new FileOutputStream(filePath.toFile());\\n             OutputStreamWriter osw = new OutputStreamWriter(fos, StandardCharsets.UTF_8);\\n             BufferedWriter writer = new BufferedWriter(osw)) {\\n            writer.write(content);\\n        }\",\n    \"relevantFile\": \"src/main/java/com/app/service/FileService.java\",\n    \"relevantLinesEnd\": 43,\n    \"suggestionContent\": \"The `writeFile` method creates streams but never closes them. The `flush()` is called but not `close()`. This leaks file handles and data may not be fully written to disk.\",\n    \"oneSentenceSummary\": \"Resource leak - output streams never closed in writeFile\",\n    \"relevantLinesStart\": 38\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"FileInputStream fis = new FileInputStream(sourcePath.toFile());\\n        FileOutputStream fos = new FileOutputStream(destPath.toFile());\",\n    \"improvedCode\": \"try (FileInputStream fis = new FileInputStream(sourcePath.toFile());\\n             FileOutputStream fos = new FileOutputStream(destPath.toFile())) {\",\n    \"relevantFile\": \"src/main/java/com/app/service/FileService.java\",\n    \"relevantLinesEnd\": 72,\n    \"suggestionContent\": \"The `copyFile` method opens both input and output streams but never closes them. This causes file handle leaks and the destination file may not be fully written.\",\n    \"oneSentenceSummary\": \"Resource leak - streams never closed in copyFile method\",\n    \"relevantLinesStart\": 71\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 51: src/main/java/com/app/auth/LdapAuthService.java",
    "vars": {
      "fileContent": "package com.app.auth;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.naming.*;\nimport javax.naming.directory.*;\nimport java.util.*;\n\npublic class LdapAuthService {\n    private static final Logger logger = LoggerFactory.getLogger(LdapAuthService.class);\n\n    private final String ldapUrl;\n    private final String baseDn;\n    private final String adminDn;\n    private final String adminPassword;\n\n    public LdapAuthService(String ldapUrl, String baseDn, String adminDn, String adminPassword) {\n        this.ldapUrl = ldapUrl;\n        this.baseDn = baseDn;\n        this.adminDn = adminDn;\n        this.adminPassword = adminPassword;\n    }\n\n    public boolean authenticate(String username, String password) {\n        try {\n            DirContext ctx = getAdminContext();\n            String filter = \"(uid=\" + username + \")\";\n\n            SearchControls controls = new SearchControls();\n            controls.setSearchScope(SearchControls.SUBTREE_SCOPE);\n\n            NamingEnumeration<SearchResult> results = ctx.search(baseDn, filter, controls);\n\n            if (results.hasMore()) {\n                SearchResult result = results.next();\n                String userDn = result.getNameInNamespace();\n\n                try {\n                    DirContext userCtx = getUserContext(userDn, password);\n                    userCtx.close();\n                    return true;\n                } catch (AuthenticationException e) {\n                    logger.warn(\"Authentication failed for user: {}\", username);\n                    return false;\n                }\n            }\n\n            ctx.close();\n            return false;\n        } catch (NamingException e) {\n            logger.error(\"LDAP error during authentication\", e);\n            return false;\n        }\n    }\n\n    public Map<String, String> getUserAttributes(String username) {\n        Map<String, String> attributes = new HashMap<>();\n\n        try {\n            DirContext ctx = getAdminContext();\n            String filter = \"(&(objectClass=person)(uid=\" + username + \"))\";\n\n            SearchControls controls = new SearchControls();\n            controls.setSearchScope(SearchControls.SUBTREE_SCOPE);\n\n            NamingEnumeration<SearchResult> results = ctx.search(baseDn, filter, controls);\n\n            if (results.hasMore()) {\n                SearchResult result = results.next();\n                Attributes attrs = result.getAttributes();\n\n                NamingEnumeration<? extends Attribute> allAttrs = attrs.getAll();\n                while (allAttrs.hasMore()) {\n                    Attribute attr = allAttrs.next();\n                    attributes.put(attr.getID(), attr.get().toString());\n                }\n            }\n\n            ctx.close();\n        } catch (NamingException e) {\n            logger.error(\"Error fetching user attributes\", e);\n        }\n\n        return attributes;\n    }\n\n    public List<String> searchUsers(String searchTerm) {\n        List<String> users = new ArrayList<>();\n\n        try {\n            DirContext ctx = getAdminContext();\n            String filter = \"(|(uid=*\" + searchTerm + \"*)(cn=*\" + searchTerm + \"*))\";\n\n            SearchControls controls = new SearchControls();\n            controls.setSearchScope(SearchControls.SUBTREE_SCOPE);\n            controls.setReturningAttributes(new String[]{\"uid\"});\n\n            NamingEnumeration<SearchResult> results = ctx.search(baseDn, filter, controls);\n\n            while (results.hasMore()) {\n                SearchResult result = results.next();\n                users.add(result.getAttributes().get(\"uid\").get().toString());\n            }\n\n            ctx.close();\n        } catch (NamingException e) {\n            logger.error(\"Error searching users\", e);\n        }\n\n        return users;\n    }\n\n    private DirContext getAdminContext() throws NamingException {\n        Hashtable<String, String> env = new Hashtable<>();\n        env.put(Context.INITIAL_CONTEXT_FACTORY, \"com.sun.jndi.ldap.LdapCtxFactory\");\n        env.put(Context.PROVIDER_URL, ldapUrl);\n        env.put(Context.SECURITY_AUTHENTICATION, \"simple\");\n        env.put(Context.SECURITY_PRINCIPAL, adminDn);\n        env.put(Context.SECURITY_CREDENTIALS, adminPassword);\n        return new InitialDirContext(env);\n    }\n\n    private DirContext getUserContext(String userDn, String password) throws NamingException {\n        Hashtable<String, String> env = new Hashtable<>();\n        env.put(Context.INITIAL_CONTEXT_FACTORY, \"com.sun.jndi.ldap.LdapCtxFactory\");\n        env.put(Context.PROVIDER_URL, ldapUrl);\n        env.put(Context.SECURITY_AUTHENTICATION, \"simple\");\n        env.put(Context.SECURITY_PRINCIPAL, userDn);\n        env.put(Context.SECURITY_CREDENTIALS, password);\n        return new InitialDirContext(env);\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/auth/LdapAuthService.java'\n\n@@ -0,0 +1,134 @@\n__new hunk__\n1 +package com.app.auth;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import javax.naming.*;\n7 +import javax.naming.directory.*;\n8 +import java.util.*;\n9 +\n10 +public class LdapAuthService {\n11 +    private static final Logger logger = LoggerFactory.getLogger(LdapAuthService.class);\n12 +\n13 +    private final String ldapUrl;\n14 +    private final String baseDn;\n15 +    private final String adminDn;\n16 +    private final String adminPassword;\n17 +\n18 +    public LdapAuthService(String ldapUrl, String baseDn, String adminDn, String adminPassword) {\n19 +        this.ldapUrl = ldapUrl;\n20 +        this.baseDn = baseDn;\n21 +        this.adminDn = adminDn;\n22 +        this.adminPassword = adminPassword;\n23 +    }\n24 +\n25 +    public boolean authenticate(String username, String password) {\n26 +        try {\n27 +            DirContext ctx = getAdminContext();\n28 +            String filter = \"(uid=\" + username + \")\";\n29 +\n30 +            SearchControls controls = new SearchControls();\n31 +            controls.setSearchScope(SearchControls.SUBTREE_SCOPE);\n32 +\n33 +            NamingEnumeration<SearchResult> results = ctx.search(baseDn, filter, controls);\n34 +\n35 +            if (results.hasMore()) {\n36 +                SearchResult result = results.next();\n37 +                String userDn = result.getNameInNamespace();\n38 +\n39 +                try {\n40 +                    DirContext userCtx = getUserContext(userDn, password);\n41 +                    userCtx.close();\n42 +                    return true;\n43 +                } catch (AuthenticationException e) {\n44 +                    logger.warn(\"Authentication failed for user: {}\", username);\n45 +                    return false;\n46 +                }\n47 +            }\n48 +\n49 +            ctx.close();\n50 +            return false;\n51 +        } catch (NamingException e) {\n52 +            logger.error(\"LDAP error during authentication\", e);\n53 +            return false;\n54 +        }\n55 +    }\n56 +\n57 +    public Map<String, String> getUserAttributes(String username) {\n58 +        Map<String, String> attributes = new HashMap<>();\n59 +\n60 +        try {\n61 +            DirContext ctx = getAdminContext();\n62 +            String filter = \"(&(objectClass=person)(uid=\" + username + \"))\";\n63 +\n64 +            SearchControls controls = new SearchControls();\n65 +            controls.setSearchScope(SearchControls.SUBTREE_SCOPE);\n66 +\n67 +            NamingEnumeration<SearchResult> results = ctx.search(baseDn, filter, controls);\n68 +\n69 +            if (results.hasMore()) {\n70 +                SearchResult result = results.next();\n71 +                Attributes attrs = result.getAttributes();\n72 +\n73 +                NamingEnumeration<? extends Attribute> allAttrs = attrs.getAll();\n74 +                while (allAttrs.hasMore()) {\n75 +                    Attribute attr = allAttrs.next();\n76 +                    attributes.put(attr.getID(), attr.get().toString());\n77 +                }\n78 +            }\n79 +\n80 +            ctx.close();\n81 +        } catch (NamingException e) {\n82 +            logger.error(\"Error fetching user attributes\", e);\n83 +        }\n84 +\n85 +        return attributes;\n86 +    }\n87 +\n88 +    public List<String> searchUsers(String searchTerm) {\n89 +        List<String> users = new ArrayList<>();\n90 +\n91 +        try {\n92 +            DirContext ctx = getAdminContext();\n93 +            String filter = \"(|(uid=*\" + searchTerm + \"*)(cn=*\" + searchTerm + \"*))\";\n94 +\n95 +            SearchControls controls = new SearchControls();\n96 +            controls.setSearchScope(SearchControls.SUBTREE_SCOPE);\n97 +            controls.setReturningAttributes(new String[]{\"uid\"});\n98 +\n99 +            NamingEnumeration<SearchResult> results = ctx.search(baseDn, filter, controls);\n100 +\n101 +            while (results.hasMore()) {\n102 +                SearchResult result = results.next();\n103 +                users.add(result.getAttributes().get(\"uid\").get().toString());\n104 +            }\n105 +\n106 +            ctx.close();\n107 +        } catch (NamingException e) {\n108 +            logger.error(\"Error searching users\", e);\n109 +        }\n110 +\n111 +        return users;\n112 +    }\n113 +\n114 +    private DirContext getAdminContext() throws NamingException {\n115 +        Hashtable<String, String> env = new Hashtable<>();\n116 +        env.put(Context.INITIAL_CONTEXT_FACTORY, \"com.sun.jndi.ldap.LdapCtxFactory\");\n117 +        env.put(Context.PROVIDER_URL, ldapUrl);\n118 +        env.put(Context.SECURITY_AUTHENTICATION, \"simple\");\n119 +        env.put(Context.SECURITY_PRINCIPAL, adminDn);\n120 +        env.put(Context.SECURITY_CREDENTIALS, adminPassword);\n121 +        return new InitialDirContext(env);\n122 +    }\n123 +\n124 +    private DirContext getUserContext(String userDn, String password) throws NamingException {\n125 +        Hashtable<String, String> env = new Hashtable<>();\n126 +        env.put(Context.INITIAL_CONTEXT_FACTORY, \"com.sun.jndi.ldap.LdapCtxFactory\");\n127 +        env.put(Context.PROVIDER_URL, ldapUrl);\n128 +        env.put(Context.SECURITY_AUTHENTICATION, \"simple\");\n129 +        env.put(Context.SECURITY_PRINCIPAL, userDn);\n130 +        env.put(Context.SECURITY_CREDENTIALS, password);\n131 +        return new InitialDirContext(env);\n132 +    }\n133 +}\n134 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/auth/LdapAuthService.java\",\"relevantLinesStart\":27,\"relevantLinesEnd\":27},{\"relevantFile\":\"src/main/java/com/app/auth/LdapAuthService.java\",\"relevantLinesStart\":88,\"relevantLinesEnd\":88}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"String filter = \\\"(uid=\\\" + username + \\\")\\\";\",\n    \"improvedCode\": \"String sanitizedUsername = sanitizeLdapInput(username);\\nString filter = \\\"(uid=\\\" + sanitizedUsername + \\\")\\\";\\n\\n// Add helper method:\\nprivate String sanitizeLdapInput(String input) {\\n    return input.replace(\\\"\\\\\\\\\\\", \\\"\\\\\\\\5c\\\")\\n                .replace(\\\"*\\\", \\\"\\\\\\\\2a\\\")\\n                .replace(\\\"(\\\", \\\"\\\\\\\\28\\\")\\n                .replace(\\\")\\\", \\\"\\\\\\\\29\\\")\\n                .replace(\\\"\\\\0\\\", \\\"\\\\\\\\00\\\");\\n}\",\n    \"relevantFile\": \"src/main/java/com/app/auth/LdapAuthService.java\",\n    \"relevantLinesEnd\": 27,\n    \"suggestionContent\": \"The `authenticate` method concatenates `username` directly into the LDAP filter string without sanitization. An attacker can input `*)(uid=*))(|(uid=*` to modify the filter logic, potentially bypassing authentication or extracting data. Escape special LDAP characters or use parameterized searches.\",\n    \"oneSentenceSummary\": \"LDAP injection in authentication - user input in filter allows authentication bypass\",\n    \"relevantLinesStart\": 27\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"String filter = \\\"(|(uid=*\\\" + searchTerm + \\\"*)(cn=*\\\" + searchTerm + \\\"*))\\\";\",\n    \"improvedCode\": \"String sanitized = sanitizeLdapInput(searchTerm);\\nString filter = \\\"(|(uid=*\\\" + sanitized + \\\"*)(cn=*\\\" + sanitized + \\\"*))\\\";\",\n    \"relevantFile\": \"src/main/java/com/app/auth/LdapAuthService.java\",\n    \"relevantLinesEnd\": 88,\n    \"suggestionContent\": \"The `searchUsers` method has the same LDAP injection vulnerability. An attacker can inject `*)(objectClass=*` to retrieve all objects in the directory, potentially exposing sensitive information.\",\n    \"oneSentenceSummary\": \"LDAP injection in search allows extracting entire directory contents\",\n    \"relevantLinesStart\": 88\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 52: src/main/java/com/app/service/InventoryService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport com.app.model.Product;\nimport com.app.model.InventoryItem;\nimport com.app.repository.InventoryRepository;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Optional;\n\npublic class InventoryService {\n    private static final Logger logger = LoggerFactory.getLogger(InventoryService.class);\n\n    private final InventoryRepository repository;\n    private final Map<Integer, InventoryItem> cache = new HashMap<>();\n\n    public InventoryService(InventoryRepository repository) {\n        this.repository = repository;\n    }\n\n    public void addStock(Integer productId, Integer quantity) {\n        InventoryItem item = cache.get(productId);\n        if (item == null) {\n            item = repository.findByProductId(productId)\n                .orElse(new InventoryItem(productId, 0));\n        }\n        item.setQuantity(item.getQuantity() + quantity);\n        cache.put(productId, item);\n        repository.save(item);\n    }\n\n    public boolean checkQuantityMatch(Integer requested, Integer available) {\n        if (requested == available) {\n            return true;\n        }\n        return requested <= available;\n    }\n\n    public boolean isLowStock(Integer productId, Integer threshold) {\n        InventoryItem item = cache.get(productId);\n        if (item == null) {\n            return false;\n        }\n        Integer currentStock = item.getQuantity();\n        return currentStock == threshold || currentStock < threshold;\n    }\n\n    public Map<Integer, String> categorizeStock(Map<Integer, Integer> stockLevels) {\n        Map<Integer, String> categories = new HashMap<>();\n        Integer lowThreshold = 10;\n        Integer mediumThreshold = 50;\n        Integer highThreshold = 200;\n\n        for (Map.Entry<Integer, Integer> entry : stockLevels.entrySet()) {\n            Integer level = entry.getValue();\n            String category;\n\n            if (level == lowThreshold) {\n                category = \"LOW_BOUNDARY\";\n            } else if (level < lowThreshold) {\n                category = \"CRITICAL\";\n            } else if (level == mediumThreshold) {\n                category = \"MEDIUM_BOUNDARY\";\n            } else if (level < mediumThreshold) {\n                category = \"LOW\";\n            } else if (level == highThreshold) {\n                category = \"HIGH_BOUNDARY\";\n            } else if (level < highThreshold) {\n                category = \"MEDIUM\";\n            } else {\n                category = \"HIGH\";\n            }\n\n            categories.put(entry.getKey(), category);\n        }\n\n        return categories;\n    }\n\n    public void processReorder(Integer productId, Integer reorderPoint) {\n        InventoryItem item = cache.get(productId);\n        if (item != null && item.getQuantity() == reorderPoint) {\n            logger.info(\"Triggering reorder for product {}\", productId);\n            triggerReorder(productId);\n        }\n    }\n\n    private void triggerReorder(Integer productId) {\n        // Reorder logic\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/InventoryService.java'\n\n@@ -0,0 +1,94 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import com.app.model.Product;\n4 +import com.app.model.InventoryItem;\n5 +import com.app.repository.InventoryRepository;\n6 +import org.slf4j.Logger;\n7 +import org.slf4j.LoggerFactory;\n8 +\n9 +import java.util.HashMap;\n10 +import java.util.Map;\n11 +import java.util.Optional;\n12 +\n13 +public class InventoryService {\n14 +    private static final Logger logger = LoggerFactory.getLogger(InventoryService.class);\n15 +\n16 +    private final InventoryRepository repository;\n17 +    private final Map<Integer, InventoryItem> cache = new HashMap<>();\n18 +\n19 +    public InventoryService(InventoryRepository repository) {\n20 +        this.repository = repository;\n21 +    }\n22 +\n23 +    public void addStock(Integer productId, Integer quantity) {\n24 +        InventoryItem item = cache.get(productId);\n25 +        if (item == null) {\n26 +            item = repository.findByProductId(productId)\n27 +                .orElse(new InventoryItem(productId, 0));\n28 +        }\n29 +        item.setQuantity(item.getQuantity() + quantity);\n30 +        cache.put(productId, item);\n31 +        repository.save(item);\n32 +    }\n33 +\n34 +    public boolean checkQuantityMatch(Integer requested, Integer available) {\n35 +        if (requested == available) {\n36 +            return true;\n37 +        }\n38 +        return requested <= available;\n39 +    }\n40 +\n41 +    public boolean isLowStock(Integer productId, Integer threshold) {\n42 +        InventoryItem item = cache.get(productId);\n43 +        if (item == null) {\n44 +            return false;\n45 +        }\n46 +        Integer currentStock = item.getQuantity();\n47 +        return currentStock == threshold || currentStock < threshold;\n48 +    }\n49 +\n50 +    public Map<Integer, String> categorizeStock(Map<Integer, Integer> stockLevels) {\n51 +        Map<Integer, String> categories = new HashMap<>();\n52 +        Integer lowThreshold = 10;\n53 +        Integer mediumThreshold = 50;\n54 +        Integer highThreshold = 200;\n55 +\n56 +        for (Map.Entry<Integer, Integer> entry : stockLevels.entrySet()) {\n57 +            Integer level = entry.getValue();\n58 +            String category;\n59 +\n60 +            if (level == lowThreshold) {\n61 +                category = \"LOW_BOUNDARY\";\n62 +            } else if (level < lowThreshold) {\n63 +                category = \"CRITICAL\";\n64 +            } else if (level == mediumThreshold) {\n65 +                category = \"MEDIUM_BOUNDARY\";\n66 +            } else if (level < mediumThreshold) {\n67 +                category = \"LOW\";\n68 +            } else if (level == highThreshold) {\n69 +                category = \"HIGH_BOUNDARY\";\n70 +            } else if (level < highThreshold) {\n71 +                category = \"MEDIUM\";\n72 +            } else {\n73 +                category = \"HIGH\";\n74 +            }\n75 +\n76 +            categories.put(entry.getKey(), category);\n77 +        }\n78 +\n79 +        return categories;\n80 +    }\n81 +\n82 +    public void processReorder(Integer productId, Integer reorderPoint) {\n83 +        InventoryItem item = cache.get(productId);\n84 +        if (item != null && item.getQuantity() == reorderPoint) {\n85 +            logger.info(\"Triggering reorder for product {}\", productId);\n86 +            triggerReorder(productId);\n87 +        }\n88 +    }\n89 +\n90 +    private void triggerReorder(Integer productId) {\n91 +        // Reorder logic\n92 +    }\n93 +}\n94 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/InventoryService.java\",\"relevantLinesStart\":34,\"relevantLinesEnd\":34}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"if (requested == available) {\",\n    \"improvedCode\": \"if (requested.equals(available)) {\",\n    \"relevantFile\": \"src/main/java/com/app/service/InventoryService.java\",\n    \"relevantLinesEnd\": 34,\n    \"suggestionContent\": \"Multiple methods compare `Integer` objects using `==` operator. Java caches Integer values from -128 to 127, so `==` works for small numbers but fails for larger values. For example, `Integer a = 200; Integer b = 200; a == b` is `false` because they're different objects. The `checkQuantityMatch`, `isLowStock`, `categorizeStock`, and `processReorder` methods all have this bug. Use `.equals()` or unbox to primitive `int` for comparison.\",\n    \"oneSentenceSummary\": \"Integer comparison with == fails for values outside -128 to 127 cache range\",\n    \"relevantLinesStart\": 34\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 53: src/main/java/com/app/service/PaymentService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport com.app.model.Payment;\nimport com.app.model.Order;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.math.BigDecimal;\nimport java.math.RoundingMode;\nimport java.util.List;\n\npublic class PaymentService {\n    private static final Logger logger = LoggerFactory.getLogger(PaymentService.class);\n\n    private static final BigDecimal TAX_RATE = new BigDecimal(\"0.08\");\n    private static final BigDecimal DISCOUNT_THRESHOLD = new BigDecimal(\"100.00\");\n    private static final BigDecimal DISCOUNT_RATE = new BigDecimal(\"0.10\");\n\n    public BigDecimal calculateTotal(List<BigDecimal> itemPrices) {\n        BigDecimal total = BigDecimal.ZERO;\n        for (BigDecimal price : itemPrices) {\n            total = total.add(price);\n        }\n        return total;\n    }\n\n    public BigDecimal applyDiscount(BigDecimal total) {\n        if (total.equals(DISCOUNT_THRESHOLD) || total.compareTo(DISCOUNT_THRESHOLD) > 0) {\n            BigDecimal discount = total.multiply(DISCOUNT_RATE);\n            return total.subtract(discount);\n        }\n        return total;\n    }\n\n    public BigDecimal calculateTax(BigDecimal amount) {\n        return amount.multiply(TAX_RATE).setScale(2, RoundingMode.HALF_UP);\n    }\n\n    public boolean isRefundEligible(BigDecimal paidAmount, BigDecimal refundAmount) {\n        return refundAmount.compareTo(paidAmount) <= 0;\n    }\n\n    public boolean verifyPayment(BigDecimal expected, BigDecimal actual) {\n        if (expected.equals(actual)) {\n            return true;\n        }\n        logger.warn(\"Payment mismatch: expected {}, actual {}\", expected, actual);\n        return false;\n    }\n\n    public BigDecimal splitPayment(BigDecimal total, int numberOfPeople) {\n        return total.divide(new BigDecimal(numberOfPeople), 2, RoundingMode.HALF_UP);\n    }\n\n    public boolean isZeroBalance(BigDecimal balance) {\n        return balance.equals(BigDecimal.ZERO);\n    }\n\n    public BigDecimal calculateChange(BigDecimal paid, BigDecimal owed) {\n        BigDecimal change = paid.subtract(owed);\n        if (change.equals(new BigDecimal(\"0.00\"))) {\n            return BigDecimal.ZERO;\n        }\n        return change;\n    }\n\n    public int compareAmounts(BigDecimal a, BigDecimal b) {\n        if (a.equals(b)) {\n            return 0;\n        }\n        return a.compareTo(b);\n    }\n\n    public void processPayment(Order order, BigDecimal paymentAmount) {\n        BigDecimal orderTotal = order.getTotal();\n\n        if (paymentAmount.equals(orderTotal)) {\n            logger.info(\"Exact payment received\");\n            order.setStatus(\"PAID\");\n        } else if (paymentAmount.compareTo(orderTotal) > 0) {\n            BigDecimal change = paymentAmount.subtract(orderTotal);\n            logger.info(\"Change due: {}\", change);\n            order.setStatus(\"PAID\");\n        } else {\n            logger.warn(\"Insufficient payment\");\n        }\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/PaymentService.java'\n\n@@ -0,0 +1,89 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import com.app.model.Payment;\n4 +import com.app.model.Order;\n5 +import org.slf4j.Logger;\n6 +import org.slf4j.LoggerFactory;\n7 +\n8 +import java.math.BigDecimal;\n9 +import java.math.RoundingMode;\n10 +import java.util.List;\n11 +\n12 +public class PaymentService {\n13 +    private static final Logger logger = LoggerFactory.getLogger(PaymentService.class);\n14 +\n15 +    private static final BigDecimal TAX_RATE = new BigDecimal(\"0.08\");\n16 +    private static final BigDecimal DISCOUNT_THRESHOLD = new BigDecimal(\"100.00\");\n17 +    private static final BigDecimal DISCOUNT_RATE = new BigDecimal(\"0.10\");\n18 +\n19 +    public BigDecimal calculateTotal(List<BigDecimal> itemPrices) {\n20 +        BigDecimal total = BigDecimal.ZERO;\n21 +        for (BigDecimal price : itemPrices) {\n22 +            total = total.add(price);\n23 +        }\n24 +        return total;\n25 +    }\n26 +\n27 +    public BigDecimal applyDiscount(BigDecimal total) {\n28 +        if (total.equals(DISCOUNT_THRESHOLD) || total.compareTo(DISCOUNT_THRESHOLD) > 0) {\n29 +            BigDecimal discount = total.multiply(DISCOUNT_RATE);\n30 +            return total.subtract(discount);\n31 +        }\n32 +        return total;\n33 +    }\n34 +\n35 +    public BigDecimal calculateTax(BigDecimal amount) {\n36 +        return amount.multiply(TAX_RATE).setScale(2, RoundingMode.HALF_UP);\n37 +    }\n38 +\n39 +    public boolean isRefundEligible(BigDecimal paidAmount, BigDecimal refundAmount) {\n40 +        return refundAmount.compareTo(paidAmount) <= 0;\n41 +    }\n42 +\n43 +    public boolean verifyPayment(BigDecimal expected, BigDecimal actual) {\n44 +        if (expected.equals(actual)) {\n45 +            return true;\n46 +        }\n47 +        logger.warn(\"Payment mismatch: expected {}, actual {}\", expected, actual);\n48 +        return false;\n49 +    }\n50 +\n51 +    public BigDecimal splitPayment(BigDecimal total, int numberOfPeople) {\n52 +        return total.divide(new BigDecimal(numberOfPeople), 2, RoundingMode.HALF_UP);\n53 +    }\n54 +\n55 +    public boolean isZeroBalance(BigDecimal balance) {\n56 +        return balance.equals(BigDecimal.ZERO);\n57 +    }\n58 +\n59 +    public BigDecimal calculateChange(BigDecimal paid, BigDecimal owed) {\n60 +        BigDecimal change = paid.subtract(owed);\n61 +        if (change.equals(new BigDecimal(\"0.00\"))) {\n62 +            return BigDecimal.ZERO;\n63 +        }\n64 +        return change;\n65 +    }\n66 +\n67 +    public int compareAmounts(BigDecimal a, BigDecimal b) {\n68 +        if (a.equals(b)) {\n69 +            return 0;\n70 +        }\n71 +        return a.compareTo(b);\n72 +    }\n73 +\n74 +    public void processPayment(Order order, BigDecimal paymentAmount) {\n75 +        BigDecimal orderTotal = order.getTotal();\n76 +\n77 +        if (paymentAmount.equals(orderTotal)) {\n78 +            logger.info(\"Exact payment received\");\n79 +            order.setStatus(\"PAID\");\n80 +        } else if (paymentAmount.compareTo(orderTotal) > 0) {\n81 +            BigDecimal change = paymentAmount.subtract(orderTotal);\n82 +            logger.info(\"Change due: {}\", change);\n83 +            order.setStatus(\"PAID\");\n84 +        } else {\n85 +            logger.warn(\"Insufficient payment\");\n86 +        }\n87 +    }\n88 +}\n89 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/PaymentService.java\",\"relevantLinesStart\":43,\"relevantLinesEnd\":45},{\"relevantFile\":\"src/main/java/com/app/service/PaymentService.java\",\"relevantLinesStart\":54,\"relevantLinesEnd\":54},{\"relevantFile\":\"src/main/java/com/app/service/PaymentService.java\",\"relevantLinesStart\":73,\"relevantLinesEnd\":73}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"if (expected.equals(actual)) {\\n            return true;\\n        }\",\n    \"improvedCode\": \"if (expected.compareTo(actual) == 0) {\\n            return true;\\n        }\",\n    \"relevantFile\": \"src/main/java/com/app/service/PaymentService.java\",\n    \"relevantLinesEnd\": 45,\n    \"suggestionContent\": \"The `verifyPayment` method uses `equals()` to compare BigDecimal values. However, BigDecimal's `equals()` considers scale, so `new BigDecimal(\\\"10.0\\\").equals(new BigDecimal(\\\"10.00\\\"))` is `false`. Use `compareTo() == 0` for numeric equality.\",\n    \"oneSentenceSummary\": \"BigDecimal.equals() compares scale - 10.0 and 10.00 are considered not equal\",\n    \"relevantLinesStart\": 43\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"return balance.equals(BigDecimal.ZERO);\",\n    \"improvedCode\": \"return balance.compareTo(BigDecimal.ZERO) == 0;\",\n    \"relevantFile\": \"src/main/java/com/app/service/PaymentService.java\",\n    \"relevantLinesEnd\": 54,\n    \"suggestionContent\": \"The `isZeroBalance` method uses `equals(BigDecimal.ZERO)` which fails for zero values with different scales like `0.00`. A balance of `new BigDecimal(\\\"0.00\\\")` would incorrectly be considered non-zero.\",\n    \"oneSentenceSummary\": \"Zero check fails for BigDecimal with scale - 0.00 not equal to ZERO\",\n    \"relevantLinesStart\": 54\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"if (paymentAmount.equals(orderTotal)) {\",\n    \"improvedCode\": \"if (paymentAmount.compareTo(orderTotal) == 0) {\",\n    \"relevantFile\": \"src/main/java/com/app/service/PaymentService.java\",\n    \"relevantLinesEnd\": 73,\n    \"suggestionContent\": \"The `processPayment` method uses `equals()` to compare payment amount with order total. If one has scale 2 (e.g., 100.00) and other has scale 1 (e.g., 100.0), exact payments will be rejected as insufficient.\",\n    \"oneSentenceSummary\": \"Payment verification fails due to BigDecimal scale mismatch\",\n    \"relevantLinesStart\": 73\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 54: src/main/java/com/app/service/DataService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport com.app.model.DataRecord;\nimport com.app.repository.DataRepository;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.*;\n\npublic class DataService {\n    private static final Logger logger = LoggerFactory.getLogger(DataService.class);\n\n    private final DataRepository repository;\n\n    public DataService(DataRepository repository) {\n        this.repository = repository;\n    }\n\n    public DataRecord findById(String id) {\n        try {\n            return repository.findById(id).orElse(null);\n        } catch (Exception e) {\n            return null;\n        }\n    }\n\n    public List<DataRecord> findAll() {\n        try {\n            return repository.findAll();\n        } catch (Throwable t) {\n            logger.error(\"Error fetching data\");\n            return Collections.emptyList();\n        }\n    }\n\n    public void saveRecord(DataRecord record) {\n        try {\n            validateRecord(record);\n            repository.save(record);\n        } catch (Exception e) {\n            // Log and continue\n            e.printStackTrace();\n        }\n    }\n\n    public void deleteRecord(String id) {\n        try {\n            repository.deleteById(id);\n        } catch (Exception e) {\n            throw new RuntimeException(e.getMessage());\n        }\n    }\n\n    public void processRecords(List<DataRecord> records) {\n        for (DataRecord record : records) {\n            try {\n                repository.save(record);\n            } catch (Exception e) {\n                // Ignore and continue with next record\n            }\n        }\n    }\n\n    public boolean updateRecord(DataRecord record) {\n        try {\n            repository.save(record);\n            return true;\n        } catch (Exception e) {\n            return false;\n        }\n    }\n\n    private void validateRecord(DataRecord record) throws Exception {\n        if (record.getId() == null) {\n            throw new Exception(\"ID is required\");\n        }\n        if (record.getName() == null || record.getName().isEmpty()) {\n            throw new Exception(\"Name is required\");\n        }\n    }\n\n    public DataRecord findOrCreate(String id, DataRecord defaultRecord) {\n        try {\n            Optional<DataRecord> existing = repository.findById(id);\n            if (existing.isPresent()) {\n                return existing.get();\n            }\n            return repository.save(defaultRecord);\n        } catch (Exception e) {\n            logger.error(\"Error in findOrCreate\", e);\n            return defaultRecord;\n        }\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/DataService.java'\n\n@@ -0,0 +1,95 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import com.app.model.DataRecord;\n4 +import com.app.repository.DataRepository;\n5 +import org.slf4j.Logger;\n6 +import org.slf4j.LoggerFactory;\n7 +\n8 +import java.util.*;\n9 +\n10 +public class DataService {\n11 +    private static final Logger logger = LoggerFactory.getLogger(DataService.class);\n12 +\n13 +    private final DataRepository repository;\n14 +\n15 +    public DataService(DataRepository repository) {\n16 +        this.repository = repository;\n17 +    }\n18 +\n19 +    public DataRecord findById(String id) {\n20 +        try {\n21 +            return repository.findById(id).orElse(null);\n22 +        } catch (Exception e) {\n23 +            return null;\n24 +        }\n25 +    }\n26 +\n27 +    public List<DataRecord> findAll() {\n28 +        try {\n29 +            return repository.findAll();\n30 +        } catch (Throwable t) {\n31 +            logger.error(\"Error fetching data\");\n32 +            return Collections.emptyList();\n33 +        }\n34 +    }\n35 +\n36 +    public void saveRecord(DataRecord record) {\n37 +        try {\n38 +            validateRecord(record);\n39 +            repository.save(record);\n40 +        } catch (Exception e) {\n41 +            // Log and continue\n42 +            e.printStackTrace();\n43 +        }\n44 +    }\n45 +\n46 +    public void deleteRecord(String id) {\n47 +        try {\n48 +            repository.deleteById(id);\n49 +        } catch (Exception e) {\n50 +            throw new RuntimeException(e.getMessage());\n51 +        }\n52 +    }\n53 +\n54 +    public void processRecords(List<DataRecord> records) {\n55 +        for (DataRecord record : records) {\n56 +            try {\n57 +                repository.save(record);\n58 +            } catch (Exception e) {\n59 +                // Ignore and continue with next record\n60 +            }\n61 +        }\n62 +    }\n63 +\n64 +    public boolean updateRecord(DataRecord record) {\n65 +        try {\n66 +            repository.save(record);\n67 +            return true;\n68 +        } catch (Exception e) {\n69 +            return false;\n70 +        }\n71 +    }\n72 +\n73 +    private void validateRecord(DataRecord record) throws Exception {\n74 +        if (record.getId() == null) {\n75 +            throw new Exception(\"ID is required\");\n76 +        }\n77 +        if (record.getName() == null || record.getName().isEmpty()) {\n78 +            throw new Exception(\"Name is required\");\n79 +        }\n80 +    }\n81 +\n82 +    public DataRecord findOrCreate(String id, DataRecord defaultRecord) {\n83 +        try {\n84 +            Optional<DataRecord> existing = repository.findById(id);\n85 +            if (existing.isPresent()) {\n86 +                return existing.get();\n87 +            }\n88 +            return repository.save(defaultRecord);\n89 +        } catch (Exception e) {\n90 +            logger.error(\"Error in findOrCreate\", e);\n91 +            return defaultRecord;\n92 +        }\n93 +    }\n94 +}\n95 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/DataService.java\",\"relevantLinesStart\":30,\"relevantLinesEnd\":32},{\"relevantFile\":\"src/main/java/com/app/service/DataService.java\",\"relevantLinesStart\":40,\"relevantLinesEnd\":43},{\"relevantFile\":\"src/main/java/com/app/service/DataService.java\",\"relevantLinesStart\":49,\"relevantLinesEnd\":49}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"} catch (Throwable t) {\\n            logger.error(\\\"Error fetching data\\\");\\n            return Collections.emptyList();\\n        }\",\n    \"improvedCode\": \"} catch (Exception e) {\\n            logger.error(\\\"Error fetching data\\\", e);\\n            return Collections.emptyList();\\n        }\",\n    \"relevantFile\": \"src/main/java/com/app/service/DataService.java\",\n    \"relevantLinesEnd\": 32,\n    \"suggestionContent\": \"The `findAll` method catches `Throwable` which includes `Error` types like `OutOfMemoryError` and `StackOverflowError`. These should not be caught as they indicate serious JVM problems. Also, the error message doesn't include the exception details. Catch `Exception` and include the cause in logs.\",\n    \"oneSentenceSummary\": \"Catching Throwable swallows critical JVM errors - should only catch Exception\",\n    \"relevantLinesStart\": 30\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"} catch (Exception e) {\\n            // Log and continue\\n            e.printStackTrace();\\n        }\",\n    \"improvedCode\": \"} catch (Exception e) {\\n            logger.error(\\\"Failed to save record: {}\\\", record.getId(), e);\\n            throw new ServiceException(\\\"Failed to save record\\\", e);\\n        }\",\n    \"relevantFile\": \"src/main/java/com/app/service/DataService.java\",\n    \"relevantLinesEnd\": 43,\n    \"suggestionContent\": \"The `saveRecord` method uses `e.printStackTrace()` which writes to stderr without any context and isn't captured by logging frameworks. Silent failures make debugging impossible. Also catches generic Exception and swallows it.\",\n    \"oneSentenceSummary\": \"printStackTrace() instead of logging and swallowing exception hides failures\",\n    \"relevantLinesStart\": 40\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"throw new RuntimeException(e.getMessage());\",\n    \"improvedCode\": \"throw new RuntimeException(\\\"Failed to delete record: \\\" + id, e);\",\n    \"relevantFile\": \"src/main/java/com/app/service/DataService.java\",\n    \"relevantLinesEnd\": 49,\n    \"suggestionContent\": \"The `deleteRecord` method creates a new `RuntimeException` with only the message, losing the original exception's stack trace. This makes debugging the root cause impossible. Use exception chaining: `new RuntimeException(message, cause)`.\",\n    \"oneSentenceSummary\": \"Exception wrapping loses original stack trace - root cause untraceable\",\n    \"relevantLinesStart\": 49\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 55: src/main/java/com/app/service/CounterService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\npublic class CounterService {\n    private static final Logger logger = LoggerFactory.getLogger(CounterService.class);\n\n    private int globalCounter = 0;\n    private final Map<String, Integer> namedCounters = new HashMap<>();\n    private final Map<String, Long> timestamps = new ConcurrentHashMap<>();\n\n    private static CounterService instance;\n\n    private CounterService() {}\n\n    public static CounterService getInstance() {\n        if (instance == null) {\n            instance = new CounterService();\n        }\n        return instance;\n    }\n\n    public int incrementGlobal() {\n        globalCounter++;\n        return globalCounter;\n    }\n\n    public int getGlobalCount() {\n        return globalCounter;\n    }\n\n    public void increment(String name) {\n        Integer current = namedCounters.get(name);\n        if (current == null) {\n            current = 0;\n        }\n        namedCounters.put(name, current + 1);\n        timestamps.put(name, System.currentTimeMillis());\n    }\n\n    public int getCount(String name) {\n        Integer count = namedCounters.get(name);\n        return count != null ? count : 0;\n    }\n\n    public void reset(String name) {\n        namedCounters.remove(name);\n        timestamps.remove(name);\n    }\n\n    public void resetAll() {\n        namedCounters.clear();\n        timestamps.clear();\n        globalCounter = 0;\n    }\n\n    public Map<String, Integer> getAllCounts() {\n        return new HashMap<>(namedCounters);\n    }\n\n    public boolean checkAndIncrement(String name, int threshold) {\n        int current = getCount(name);\n        if (current < threshold) {\n            increment(name);\n            return true;\n        }\n        return false;\n    }\n\n    public void transferCount(String from, String to) {\n        int fromCount = getCount(from);\n        int toCount = getCount(to);\n\n        namedCounters.put(to, toCount + fromCount);\n        namedCounters.remove(from);\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/CounterService.java'\n\n@@ -0,0 +1,83 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import java.util.HashMap;\n7 +import java.util.Map;\n8 +import java.util.concurrent.ConcurrentHashMap;\n9 +\n10 +public class CounterService {\n11 +    private static final Logger logger = LoggerFactory.getLogger(CounterService.class);\n12 +\n13 +    private int globalCounter = 0;\n14 +    private final Map<String, Integer> namedCounters = new HashMap<>();\n15 +    private final Map<String, Long> timestamps = new ConcurrentHashMap<>();\n16 +\n17 +    private static CounterService instance;\n18 +\n19 +    private CounterService() {}\n20 +\n21 +    public static CounterService getInstance() {\n22 +        if (instance == null) {\n23 +            instance = new CounterService();\n24 +        }\n25 +        return instance;\n26 +    }\n27 +\n28 +    public int incrementGlobal() {\n29 +        globalCounter++;\n30 +        return globalCounter;\n31 +    }\n32 +\n33 +    public int getGlobalCount() {\n34 +        return globalCounter;\n35 +    }\n36 +\n37 +    public void increment(String name) {\n38 +        Integer current = namedCounters.get(name);\n39 +        if (current == null) {\n40 +            current = 0;\n41 +        }\n42 +        namedCounters.put(name, current + 1);\n43 +        timestamps.put(name, System.currentTimeMillis());\n44 +    }\n45 +\n46 +    public int getCount(String name) {\n47 +        Integer count = namedCounters.get(name);\n48 +        return count != null ? count : 0;\n49 +    }\n50 +\n51 +    public void reset(String name) {\n52 +        namedCounters.remove(name);\n53 +        timestamps.remove(name);\n54 +    }\n55 +\n56 +    public void resetAll() {\n57 +        namedCounters.clear();\n58 +        timestamps.clear();\n59 +        globalCounter = 0;\n60 +    }\n61 +\n62 +    public Map<String, Integer> getAllCounts() {\n63 +        return new HashMap<>(namedCounters);\n64 +    }\n65 +\n66 +    public boolean checkAndIncrement(String name, int threshold) {\n67 +        int current = getCount(name);\n68 +        if (current < threshold) {\n69 +            increment(name);\n70 +            return true;\n71 +        }\n72 +        return false;\n73 +    }\n74 +\n75 +    public void transferCount(String from, String to) {\n76 +        int fromCount = getCount(from);\n77 +        int toCount = getCount(to);\n78 +\n79 +        namedCounters.put(to, toCount + fromCount);\n80 +        namedCounters.remove(from);\n81 +    }\n82 +}\n83 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/CounterService.java\",\"relevantLinesStart\":21,\"relevantLinesEnd\":26},{\"relevantFile\":\"src/main/java/com/app/service/CounterService.java\",\"relevantLinesStart\":28,\"relevantLinesEnd\":31},{\"relevantFile\":\"src/main/java/com/app/service/CounterService.java\",\"relevantLinesStart\":14,\"relevantLinesEnd\":14}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public static CounterService getInstance() {\\n        if (instance == null) {\\n            instance = new CounterService();\\n        }\\n        return instance;\\n    }\",\n    \"improvedCode\": \"public static synchronized CounterService getInstance() {\\n        if (instance == null) {\\n            instance = new CounterService();\\n        }\\n        return instance;\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/service/CounterService.java\",\n    \"relevantLinesEnd\": 26,\n    \"suggestionContent\": \"The `getInstance` method has a race condition (broken double-checked locking). Two threads can both see `instance == null`, both create instances, and one instance is lost. Either use synchronized, volatile with proper double-checked locking, or an enum singleton.\",\n    \"oneSentenceSummary\": \"Race condition in singleton - multiple instances can be created\",\n    \"relevantLinesStart\": 21\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public int incrementGlobal() {\\n        globalCounter++;\\n        return globalCounter;\\n    }\",\n    \"improvedCode\": \"private final AtomicInteger globalCounter = new AtomicInteger(0);\\n\\npublic int incrementGlobal() {\\n        return globalCounter.incrementAndGet();\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/service/CounterService.java\",\n    \"relevantLinesEnd\": 31,\n    \"suggestionContent\": \"The `incrementGlobal` method performs non-atomic `globalCounter++`. With multiple threads, increments can be lost due to read-modify-write race condition. Use `AtomicInteger` or synchronization.\",\n    \"oneSentenceSummary\": \"Race condition in counter increment - increments can be lost\",\n    \"relevantLinesStart\": 28\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"private final Map<String, Integer> namedCounters = new HashMap<>();\",\n    \"improvedCode\": \"private final ConcurrentHashMap<String, Integer> namedCounters = new ConcurrentHashMap<>();\\n\\npublic void increment(String name) {\\n    namedCounters.merge(name, 1, Integer::sum);\\n    timestamps.put(name, System.currentTimeMillis());\\n}\",\n    \"relevantFile\": \"src/main/java/com/app/service/CounterService.java\",\n    \"relevantLinesEnd\": 14,\n    \"suggestionContent\": \"The `namedCounters` HashMap is not thread-safe, but methods like `increment` and `checkAndIncrement` can be called from multiple threads. The read-then-write pattern in `increment` is also not atomic. Use `ConcurrentHashMap` with `compute` or `merge`.\",\n    \"oneSentenceSummary\": \"HashMap not thread-safe - concurrent access causes data corruption\",\n    \"relevantLinesStart\": 14\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 56: src/main/java/com/app/model/CacheKey.java",
    "vars": {
      "fileContent": "package com.app.model;\n\nimport java.util.Objects;\n\npublic class CacheKey {\n    private String namespace;\n    private String key;\n    private long version;\n    private boolean caseSensitive;\n\n    public CacheKey(String namespace, String key) {\n        this.namespace = namespace;\n        this.key = key;\n        this.version = 1;\n        this.caseSensitive = true;\n    }\n\n    public CacheKey(String namespace, String key, long version) {\n        this.namespace = namespace;\n        this.key = key;\n        this.version = version;\n        this.caseSensitive = true;\n    }\n\n    public String getNamespace() {\n        return namespace;\n    }\n\n    public void setNamespace(String namespace) {\n        this.namespace = namespace;\n    }\n\n    public String getKey() {\n        return key;\n    }\n\n    public void setKey(String key) {\n        this.key = key;\n    }\n\n    public long getVersion() {\n        return version;\n    }\n\n    public void setVersion(long version) {\n        this.version = version;\n    }\n\n    public boolean isCaseSensitive() {\n        return caseSensitive;\n    }\n\n    public void setCaseSensitive(boolean caseSensitive) {\n        this.caseSensitive = caseSensitive;\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (o == null || getClass() != o.getClass()) return false;\n        CacheKey cacheKey = (CacheKey) o;\n        return Objects.equals(namespace, cacheKey.namespace) &&\n               Objects.equals(key, cacheKey.key);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(namespace, key, version);\n    }\n\n    public String toKeyString() {\n        return namespace + \":\" + key + \":\" + version;\n    }\n\n    public static CacheKey parse(String keyString) {\n        String[] parts = keyString.split(\":\");\n        if (parts.length >= 2) {\n            CacheKey cacheKey = new CacheKey(parts[0], parts[1]);\n            if (parts.length >= 3) {\n                cacheKey.setVersion(Long.parseLong(parts[2]));\n            }\n            return cacheKey;\n        }\n        throw new IllegalArgumentException(\"Invalid key string: \" + keyString);\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/model/CacheKey.java'\n\n@@ -0,0 +1,87 @@\n__new hunk__\n1 +package com.app.model;\n2 +\n3 +import java.util.Objects;\n4 +\n5 +public class CacheKey {\n6 +    private String namespace;\n7 +    private String key;\n8 +    private long version;\n9 +    private boolean caseSensitive;\n10 +\n11 +    public CacheKey(String namespace, String key) {\n12 +        this.namespace = namespace;\n13 +        this.key = key;\n14 +        this.version = 1;\n15 +        this.caseSensitive = true;\n16 +    }\n17 +\n18 +    public CacheKey(String namespace, String key, long version) {\n19 +        this.namespace = namespace;\n20 +        this.key = key;\n21 +        this.version = version;\n22 +        this.caseSensitive = true;\n23 +    }\n24 +\n25 +    public String getNamespace() {\n26 +        return namespace;\n27 +    }\n28 +\n29 +    public void setNamespace(String namespace) {\n30 +        this.namespace = namespace;\n31 +    }\n32 +\n33 +    public String getKey() {\n34 +        return key;\n35 +    }\n36 +\n37 +    public void setKey(String key) {\n38 +        this.key = key;\n39 +    }\n40 +\n41 +    public long getVersion() {\n42 +        return version;\n43 +    }\n44 +\n45 +    public void setVersion(long version) {\n46 +        this.version = version;\n47 +    }\n48 +\n49 +    public boolean isCaseSensitive() {\n50 +        return caseSensitive;\n51 +    }\n52 +\n53 +    public void setCaseSensitive(boolean caseSensitive) {\n54 +        this.caseSensitive = caseSensitive;\n55 +    }\n56 +\n57 +    @Override\n58 +    public boolean equals(Object o) {\n59 +        if (this == o) return true;\n60 +        if (o == null || getClass() != o.getClass()) return false;\n61 +        CacheKey cacheKey = (CacheKey) o;\n62 +        return Objects.equals(namespace, cacheKey.namespace) &&\n63 +               Objects.equals(key, cacheKey.key);\n64 +    }\n65 +\n66 +    @Override\n67 +    public int hashCode() {\n68 +        return Objects.hash(namespace, key, version);\n69 +    }\n70 +\n71 +    public String toKeyString() {\n72 +        return namespace + \":\" + key + \":\" + version;\n73 +    }\n74 +\n75 +    public static CacheKey parse(String keyString) {\n76 +        String[] parts = keyString.split(\":\");\n77 +        if (parts.length >= 2) {\n78 +            CacheKey cacheKey = new CacheKey(parts[0], parts[1]);\n79 +            if (parts.length >= 3) {\n80 +                cacheKey.setVersion(Long.parseLong(parts[2]));\n81 +            }\n82 +            return cacheKey;\n83 +        }\n84 +        throw new IllegalArgumentException(\"Invalid key string: \" + keyString);\n85 +    }\n86 +}\n87 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/model/CacheKey.java\",\"relevantLinesStart\":57,\"relevantLinesEnd\":68}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"@Override\\n    public boolean equals(Object o) {\\n        if (this == o) return true;\\n        if (o == null || getClass() != o.getClass()) return false;\\n        CacheKey cacheKey = (CacheKey) o;\\n        return Objects.equals(namespace, cacheKey.namespace) &&\\n               Objects.equals(key, cacheKey.key);\\n    }\\n    \\n    @Override\\n    public int hashCode() {\\n        return Objects.hash(namespace, key, version);\\n    }\",\n    \"improvedCode\": \"@Override\\n    public boolean equals(Object o) {\\n        if (this == o) return true;\\n        if (o == null || getClass() != o.getClass()) return false;\\n        CacheKey cacheKey = (CacheKey) o;\\n        return Objects.equals(namespace, cacheKey.namespace) &&\\n               Objects.equals(key, cacheKey.key);\\n    }\\n    \\n    @Override\\n    public int hashCode() {\\n        return Objects.hash(namespace, key);  // Must match fields used in equals\\n    }\",\n    \"relevantFile\": \"src/main/java/com/app/model/CacheKey.java\",\n    \"relevantLinesEnd\": 68,\n    \"suggestionContent\": \"The `equals` and `hashCode` methods violate their contract. `equals` compares only `namespace` and `key`, but `hashCode` includes `version`. Two CacheKey objects can be equal (same namespace/key) but have different hash codes (different version). This breaks HashMap/HashSet: objects may not be found even when they exist in the collection.\",\n    \"oneSentenceSummary\": \"equals/hashCode contract violation - equal objects have different hash codes\",\n    \"relevantLinesStart\": 57\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 57: src/main/java/com/app/repository/ProductRepository.java",
    "vars": {
      "fileContent": "package com.app.repository;\n\nimport com.app.model.Product;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.sql.*;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Optional;\n\npublic class ProductRepository {\n    private static final Logger logger = LoggerFactory.getLogger(ProductRepository.class);\n\n    private final Connection connection;\n\n    public ProductRepository(Connection connection) {\n        this.connection = connection;\n    }\n\n    public Optional<Product> findById(Long id) throws SQLException {\n        String sql = \"SELECT * FROM products WHERE id = ?\";\n        try (PreparedStatement stmt = connection.prepareStatement(sql)) {\n            stmt.setLong(1, id);\n            ResultSet rs = stmt.executeQuery();\n            if (rs.next()) {\n                return Optional.of(mapResultSetToProduct(rs));\n            }\n        }\n        return Optional.empty();\n    }\n\n    public List<Product> findByName(String name) throws SQLException {\n        String sql = \"SELECT * FROM products WHERE name LIKE '%\" + name + \"%'\";\n        List<Product> products = new ArrayList<>();\n\n        try (Statement stmt = connection.createStatement()) {\n            ResultSet rs = stmt.executeQuery(sql);\n            while (rs.next()) {\n                products.add(mapResultSetToProduct(rs));\n            }\n        }\n\n        return products;\n    }\n\n    public List<Product> findByCategory(String category) throws SQLException {\n        String sql = \"SELECT * FROM products WHERE category = '\" + category + \"'\";\n        List<Product> products = new ArrayList<>();\n\n        try (Statement stmt = connection.createStatement()) {\n            ResultSet rs = stmt.executeQuery(sql);\n            while (rs.next()) {\n                products.add(mapResultSetToProduct(rs));\n            }\n        }\n\n        return products;\n    }\n\n    public List<Product> searchProducts(String searchTerm, String sortBy) throws SQLException {\n        String sql = \"SELECT * FROM products WHERE name LIKE '%\" + searchTerm + \"%' ORDER BY \" + sortBy;\n        List<Product> products = new ArrayList<>();\n\n        try (Statement stmt = connection.createStatement()) {\n            ResultSet rs = stmt.executeQuery(sql);\n            while (rs.next()) {\n                products.add(mapResultSetToProduct(rs));\n            }\n        }\n\n        return products;\n    }\n\n    public void updatePrice(Long productId, double newPrice) throws SQLException {\n        String sql = \"UPDATE products SET price = ? WHERE id = ?\";\n        try (PreparedStatement stmt = connection.prepareStatement(sql)) {\n            stmt.setDouble(1, newPrice);\n            stmt.setLong(2, productId);\n            stmt.executeUpdate();\n        }\n    }\n\n    public void deleteByCategory(String category) throws SQLException {\n        String sql = \"DELETE FROM products WHERE category = '\" + category + \"'\";\n        try (Statement stmt = connection.createStatement()) {\n            stmt.executeUpdate(sql);\n        }\n    }\n\n    private Product mapResultSetToProduct(ResultSet rs) throws SQLException {\n        return new Product(\n            rs.getLong(\"id\"),\n            rs.getString(\"name\"),\n            rs.getString(\"category\"),\n            rs.getDouble(\"price\"),\n            rs.getInt(\"quantity\")\n        );\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/repository/ProductRepository.java'\n\n@@ -0,0 +1,101 @@\n__new hunk__\n1 +package com.app.repository;\n2 +\n3 +import com.app.model.Product;\n4 +import org.slf4j.Logger;\n5 +import org.slf4j.LoggerFactory;\n6 +\n7 +import java.sql.*;\n8 +import java.util.ArrayList;\n9 +import java.util.List;\n10 +import java.util.Optional;\n11 +\n12 +public class ProductRepository {\n13 +    private static final Logger logger = LoggerFactory.getLogger(ProductRepository.class);\n14 +\n15 +    private final Connection connection;\n16 +\n17 +    public ProductRepository(Connection connection) {\n18 +        this.connection = connection;\n19 +    }\n20 +\n21 +    public Optional<Product> findById(Long id) throws SQLException {\n22 +        String sql = \"SELECT * FROM products WHERE id = ?\";\n23 +        try (PreparedStatement stmt = connection.prepareStatement(sql)) {\n24 +            stmt.setLong(1, id);\n25 +            ResultSet rs = stmt.executeQuery();\n26 +            if (rs.next()) {\n27 +                return Optional.of(mapResultSetToProduct(rs));\n28 +            }\n29 +        }\n30 +        return Optional.empty();\n31 +    }\n32 +\n33 +    public List<Product> findByName(String name) throws SQLException {\n34 +        String sql = \"SELECT * FROM products WHERE name LIKE '%\" + name + \"%'\";\n35 +        List<Product> products = new ArrayList<>();\n36 +\n37 +        try (Statement stmt = connection.createStatement()) {\n38 +            ResultSet rs = stmt.executeQuery(sql);\n39 +            while (rs.next()) {\n40 +                products.add(mapResultSetToProduct(rs));\n41 +            }\n42 +        }\n43 +\n44 +        return products;\n45 +    }\n46 +\n47 +    public List<Product> findByCategory(String category) throws SQLException {\n48 +        String sql = \"SELECT * FROM products WHERE category = '\" + category + \"'\";\n49 +        List<Product> products = new ArrayList<>();\n50 +\n51 +        try (Statement stmt = connection.createStatement()) {\n52 +            ResultSet rs = stmt.executeQuery(sql);\n53 +            while (rs.next()) {\n54 +                products.add(mapResultSetToProduct(rs));\n55 +            }\n56 +        }\n57 +\n58 +        return products;\n59 +    }\n60 +\n61 +    public List<Product> searchProducts(String searchTerm, String sortBy) throws SQLException {\n62 +        String sql = \"SELECT * FROM products WHERE name LIKE '%\" + searchTerm + \"%' ORDER BY \" + sortBy;\n63 +        List<Product> products = new ArrayList<>();\n64 +\n65 +        try (Statement stmt = connection.createStatement()) {\n66 +            ResultSet rs = stmt.executeQuery(sql);\n67 +            while (rs.next()) {\n68 +                products.add(mapResultSetToProduct(rs));\n69 +            }\n70 +        }\n71 +\n72 +        return products;\n73 +    }\n74 +\n75 +    public void updatePrice(Long productId, double newPrice) throws SQLException {\n76 +        String sql = \"UPDATE products SET price = ? WHERE id = ?\";\n77 +        try (PreparedStatement stmt = connection.prepareStatement(sql)) {\n78 +            stmt.setDouble(1, newPrice);\n79 +            stmt.setLong(2, productId);\n80 +            stmt.executeUpdate();\n81 +        }\n82 +    }\n83 +\n84 +    public void deleteByCategory(String category) throws SQLException {\n85 +        String sql = \"DELETE FROM products WHERE category = '\" + category + \"'\";\n86 +        try (Statement stmt = connection.createStatement()) {\n87 +            stmt.executeUpdate(sql);\n88 +        }\n89 +    }\n90 +\n91 +    private Product mapResultSetToProduct(ResultSet rs) throws SQLException {\n92 +        return new Product(\n93 +            rs.getLong(\"id\"),\n94 +            rs.getString(\"name\"),\n95 +            rs.getString(\"category\"),\n96 +            rs.getDouble(\"price\"),\n97 +            rs.getInt(\"quantity\")\n98 +        );\n99 +    }\n100 +}\n101 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/repository/ProductRepository.java\",\"relevantLinesStart\":33,\"relevantLinesEnd\":33},{\"relevantFile\":\"src/main/java/com/app/repository/ProductRepository.java\",\"relevantLinesStart\":60,\"relevantLinesEnd\":60},{\"relevantFile\":\"src/main/java/com/app/repository/ProductRepository.java\",\"relevantLinesStart\":82,\"relevantLinesEnd\":82}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"String sql = \\\"SELECT * FROM products WHERE name LIKE '%\\\" + name + \\\"%'\\\";\",\n    \"improvedCode\": \"String sql = \\\"SELECT * FROM products WHERE name LIKE ?\\\";\\ntry (PreparedStatement stmt = connection.prepareStatement(sql)) {\\n    stmt.setString(1, \\\"%\\\" + name + \\\"%\\\");\",\n    \"relevantFile\": \"src/main/java/com/app/repository/ProductRepository.java\",\n    \"relevantLinesEnd\": 33,\n    \"suggestionContent\": \"The `findByName` method concatenates user input directly into SQL query, enabling SQL injection. An attacker can input `%' OR '1'='1' --` to retrieve all products or `%'; DROP TABLE products; --` to delete the table. Use PreparedStatement with parameters.\",\n    \"oneSentenceSummary\": \"SQL injection in findByName - user input concatenated into query\",\n    \"relevantLinesStart\": 33\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"String sql = \\\"SELECT * FROM products WHERE name LIKE '%\\\" + searchTerm + \\\"%' ORDER BY \\\" + sortBy;\",\n    \"improvedCode\": \"Set<String> allowedSortColumns = Set.of(\\\"name\\\", \\\"price\\\", \\\"category\\\");\\nif (!allowedSortColumns.contains(sortBy)) {\\n    throw new IllegalArgumentException(\\\"Invalid sort column\\\");\\n}\\nString sql = \\\"SELECT * FROM products WHERE name LIKE ? ORDER BY \\\" + sortBy;\",\n    \"relevantFile\": \"src/main/java/com/app/repository/ProductRepository.java\",\n    \"relevantLinesEnd\": 60,\n    \"suggestionContent\": \"The `searchProducts` method has two SQL injection vulnerabilities: the `searchTerm` and `sortBy` parameters are both concatenated into the query. The `sortBy` injection is particularly dangerous as ORDER BY cannot be parameterized - it needs allowlist validation.\",\n    \"oneSentenceSummary\": \"SQL injection in searchProducts - both searchTerm and sortBy are injectable\",\n    \"relevantLinesStart\": 60\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"String sql = \\\"DELETE FROM products WHERE category = '\\\" + category + \\\"'\\\";\",\n    \"improvedCode\": \"String sql = \\\"DELETE FROM products WHERE category = ?\\\";\\ntry (PreparedStatement stmt = connection.prepareStatement(sql)) {\\n    stmt.setString(1, category);\",\n    \"relevantFile\": \"src/main/java/com/app/repository/ProductRepository.java\",\n    \"relevantLinesEnd\": 82,\n    \"suggestionContent\": \"The `deleteByCategory` method concatenates the category parameter directly into a DELETE statement. An attacker can inject `'; DELETE FROM users; --` to delete data from other tables.\",\n    \"oneSentenceSummary\": \"SQL injection in DELETE statement allows deleting arbitrary data\",\n    \"relevantLinesStart\": 82\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 58: src/main/java/com/app/util/StringUtils.java",
    "vars": {
      "fileContent": "package com.app.util;\n\nimport java.util.*;\nimport java.util.regex.Pattern;\n\npublic class StringUtils {\n\n    private static final Pattern EMAIL_PATTERN = Pattern.compile(\"^[A-Za-z0-9+_.-]+@(.+)$\");\n\n    public static String joinWithSeparator(List<String> items, String separator) {\n        String result = \"\";\n        for (int i = 0; i < items.size(); i++) {\n            result += items.get(i);\n            if (i < items.size() - 1) {\n                result += separator;\n            }\n        }\n        return result;\n    }\n\n    public static String repeat(String str, int times) {\n        String result = \"\";\n        for (int i = 0; i < times; i++) {\n            result = result + str;\n        }\n        return result;\n    }\n\n    public static String buildQuery(Map<String, String> params) {\n        String query = \"\";\n        for (Map.Entry<String, String> entry : params.entrySet()) {\n            if (!query.isEmpty()) {\n                query += \"&\";\n            }\n            query += entry.getKey() + \"=\" + entry.getValue();\n        }\n        return query;\n    }\n\n    public static boolean isValidEmail(String email) {\n        return email != null && EMAIL_PATTERN.matcher(email).matches();\n    }\n\n    public static String capitalize(String str) {\n        if (str == null || str.isEmpty()) {\n            return str;\n        }\n        return Character.toUpperCase(str.charAt(0)) + str.substring(1).toLowerCase();\n    }\n\n    public static String truncate(String str, int maxLength) {\n        if (str == null || str.length() <= maxLength) {\n            return str;\n        }\n        return str.substring(0, maxLength) + \"...\";\n    }\n\n    public static List<String> splitByLength(String str, int chunkSize) {\n        List<String> chunks = new ArrayList<>();\n        for (int i = 0; i < str.length(); i += chunkSize) {\n            chunks.add(str.substring(i, Math.min(i + chunkSize, str.length())));\n        }\n        return chunks;\n    }\n\n    public static String reverse(String str) {\n        String result = \"\";\n        for (int i = str.length() - 1; i >= 0; i--) {\n            result += str.charAt(i);\n        }\n        return result;\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/util/StringUtils.java'\n\n@@ -0,0 +1,74 @@\n__new hunk__\n1 +package com.app.util;\n2 +\n3 +import java.util.*;\n4 +import java.util.regex.Pattern;\n5 +\n6 +public class StringUtils {\n7 +\n8 +    private static final Pattern EMAIL_PATTERN = Pattern.compile(\"^[A-Za-z0-9+_.-]+@(.+)$\");\n9 +\n10 +    public static String joinWithSeparator(List<String> items, String separator) {\n11 +        String result = \"\";\n12 +        for (int i = 0; i < items.size(); i++) {\n13 +            result += items.get(i);\n14 +            if (i < items.size() - 1) {\n15 +                result += separator;\n16 +            }\n17 +        }\n18 +        return result;\n19 +    }\n20 +\n21 +    public static String repeat(String str, int times) {\n22 +        String result = \"\";\n23 +        for (int i = 0; i < times; i++) {\n24 +            result = result + str;\n25 +        }\n26 +        return result;\n27 +    }\n28 +\n29 +    public static String buildQuery(Map<String, String> params) {\n30 +        String query = \"\";\n31 +        for (Map.Entry<String, String> entry : params.entrySet()) {\n32 +            if (!query.isEmpty()) {\n33 +                query += \"&\";\n34 +            }\n35 +            query += entry.getKey() + \"=\" + entry.getValue();\n36 +        }\n37 +        return query;\n38 +    }\n39 +\n40 +    public static boolean isValidEmail(String email) {\n41 +        return email != null && EMAIL_PATTERN.matcher(email).matches();\n42 +    }\n43 +\n44 +    public static String capitalize(String str) {\n45 +        if (str == null || str.isEmpty()) {\n46 +            return str;\n47 +        }\n48 +        return Character.toUpperCase(str.charAt(0)) + str.substring(1).toLowerCase();\n49 +    }\n50 +\n51 +    public static String truncate(String str, int maxLength) {\n52 +        if (str == null || str.length() <= maxLength) {\n53 +            return str;\n54 +        }\n55 +        return str.substring(0, maxLength) + \"...\";\n56 +    }\n57 +\n58 +    public static List<String> splitByLength(String str, int chunkSize) {\n59 +        List<String> chunks = new ArrayList<>();\n60 +        for (int i = 0; i < str.length(); i += chunkSize) {\n61 +            chunks.add(str.substring(i, Math.min(i + chunkSize, str.length())));\n62 +        }\n63 +        return chunks;\n64 +    }\n65 +\n66 +    public static String reverse(String str) {\n67 +        String result = \"\";\n68 +        for (int i = str.length() - 1; i >= 0; i--) {\n69 +            result += str.charAt(i);\n70 +        }\n71 +        return result;\n72 +    }\n73 +}\n74 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/util/StringUtils.java\",\"relevantLinesStart\":11,\"relevantLinesEnd\":17}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public static String joinWithSeparator(List<String> items, String separator) {\\n        String result = \\\"\\\";\\n        for (int i = 0; i < items.size(); i++) {\\n            result += items.get(i);\",\n    \"improvedCode\": \"public static String joinWithSeparator(List<String> items, String separator) {\\n        StringBuilder result = new StringBuilder();\\n        for (int i = 0; i < items.size(); i++) {\\n            result.append(items.get(i));\",\n    \"relevantFile\": \"src/main/java/com/app/util/StringUtils.java\",\n    \"relevantLinesEnd\": 17,\n    \"suggestionContent\": \"Multiple methods use String concatenation with `+=` in loops (`joinWithSeparator`, `repeat`, `buildQuery`, `reverse`). In Java, strings are immutable, so each `+=` creates a new String object and copies all previous characters. For n iterations, this is O(nÂ²) time complexity and creates n garbage objects. Use StringBuilder instead.\",\n    \"oneSentenceSummary\": \"String concatenation in loop is O(nÂ²) - creates n String objects per iteration\",\n    \"relevantLinesStart\": 11\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 59: src/main/java/com/app/service/OrderService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport com.app.model.Order;\nimport com.app.model.OrderItem;\nimport com.app.model.Customer;\nimport com.app.repository.OrderRepository;\nimport com.app.repository.CustomerRepository;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.math.BigDecimal;\nimport java.time.LocalDateTime;\nimport java.util.List;\nimport java.util.Optional;\n\npublic class OrderService {\n    private static final Logger logger = LoggerFactory.getLogger(OrderService.class);\n\n    private final OrderRepository orderRepository;\n    private final CustomerRepository customerRepository;\n\n    public OrderService(OrderRepository orderRepository, CustomerRepository customerRepository) {\n        this.orderRepository = orderRepository;\n        this.customerRepository = customerRepository;\n    }\n\n    public Order createOrder(String customerId, List<OrderItem> items) {\n        Customer customer = customerRepository.findById(customerId).orElse(null);\n\n        Order order = new Order();\n        order.setCustomerId(customerId);\n        order.setCustomerEmail(customer.getEmail());\n        order.setItems(items);\n        order.setStatus(\"PENDING\");\n        order.setCreatedAt(LocalDateTime.now());\n        order.setTotal(calculateTotal(items));\n\n        return orderRepository.save(order);\n    }\n\n    public BigDecimal calculateTotal(List<OrderItem> items) {\n        BigDecimal total = BigDecimal.ZERO;\n        for (OrderItem item : items) {\n            BigDecimal itemTotal = item.getPrice().multiply(new BigDecimal(item.getQuantity()));\n            total = total.add(itemTotal);\n        }\n        return total;\n    }\n\n    public void processOrder(String orderId) {\n        Order order = orderRepository.findById(orderId).orElse(null);\n\n        logger.info(\"Processing order {} for customer {}\", order.getId(), order.getCustomerId());\n\n        if (order.getStatus().equals(\"PENDING\")) {\n            order.setStatus(\"PROCESSING\");\n            orderRepository.save(order);\n        }\n    }\n\n    public String getOrderSummary(String orderId) {\n        Order order = orderRepository.findById(orderId).orElse(null);\n        Customer customer = customerRepository.findById(order.getCustomerId()).orElse(null);\n\n        StringBuilder summary = new StringBuilder();\n        summary.append(\"Order: \").append(order.getId()).append(\"\\n\");\n        summary.append(\"Customer: \").append(customer.getName()).append(\"\\n\");\n        summary.append(\"Email: \").append(customer.getEmail()).append(\"\\n\");\n        summary.append(\"Total: \").append(order.getTotal()).append(\"\\n\");\n\n        return summary.toString();\n    }\n\n    public void applyDiscount(String orderId, String couponCode) {\n        Order order = orderRepository.findById(orderId).orElse(null);\n\n        if (order != null && couponCode != null) {\n            BigDecimal discount = calculateDiscount(couponCode, order.getTotal());\n            order.setDiscount(discount);\n            order.setTotal(order.getTotal().subtract(discount));\n            orderRepository.save(order);\n        }\n    }\n\n    private BigDecimal calculateDiscount(String couponCode, BigDecimal total) {\n        if (couponCode.startsWith(\"PERCENT\")) {\n            int percent = Integer.parseInt(couponCode.substring(7));\n            return total.multiply(new BigDecimal(percent)).divide(new BigDecimal(100));\n        }\n        return BigDecimal.ZERO;\n    }\n\n    public boolean cancelOrder(String orderId) {\n        Optional<Order> orderOpt = orderRepository.findById(orderId);\n        if (orderOpt.isPresent()) {\n            Order order = orderOpt.get();\n            if (!\"SHIPPED\".equals(order.getStatus())) {\n                order.setStatus(\"CANCELLED\");\n                orderRepository.save(order);\n                return true;\n            }\n        }\n        return false;\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/OrderService.java'\n\n@@ -0,0 +1,106 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import com.app.model.Order;\n4 +import com.app.model.OrderItem;\n5 +import com.app.model.Customer;\n6 +import com.app.repository.OrderRepository;\n7 +import com.app.repository.CustomerRepository;\n8 +import org.slf4j.Logger;\n9 +import org.slf4j.LoggerFactory;\n10 +\n11 +import java.math.BigDecimal;\n12 +import java.time.LocalDateTime;\n13 +import java.util.List;\n14 +import java.util.Optional;\n15 +\n16 +public class OrderService {\n17 +    private static final Logger logger = LoggerFactory.getLogger(OrderService.class);\n18 +\n19 +    private final OrderRepository orderRepository;\n20 +    private final CustomerRepository customerRepository;\n21 +\n22 +    public OrderService(OrderRepository orderRepository, CustomerRepository customerRepository) {\n23 +        this.orderRepository = orderRepository;\n24 +        this.customerRepository = customerRepository;\n25 +    }\n26 +\n27 +    public Order createOrder(String customerId, List<OrderItem> items) {\n28 +        Customer customer = customerRepository.findById(customerId).orElse(null);\n29 +\n30 +        Order order = new Order();\n31 +        order.setCustomerId(customerId);\n32 +        order.setCustomerEmail(customer.getEmail());\n33 +        order.setItems(items);\n34 +        order.setStatus(\"PENDING\");\n35 +        order.setCreatedAt(LocalDateTime.now());\n36 +        order.setTotal(calculateTotal(items));\n37 +\n38 +        return orderRepository.save(order);\n39 +    }\n40 +\n41 +    public BigDecimal calculateTotal(List<OrderItem> items) {\n42 +        BigDecimal total = BigDecimal.ZERO;\n43 +        for (OrderItem item : items) {\n44 +            BigDecimal itemTotal = item.getPrice().multiply(new BigDecimal(item.getQuantity()));\n45 +            total = total.add(itemTotal);\n46 +        }\n47 +        return total;\n48 +    }\n49 +\n50 +    public void processOrder(String orderId) {\n51 +        Order order = orderRepository.findById(orderId).orElse(null);\n52 +\n53 +        logger.info(\"Processing order {} for customer {}\", order.getId(), order.getCustomerId());\n54 +\n55 +        if (order.getStatus().equals(\"PENDING\")) {\n56 +            order.setStatus(\"PROCESSING\");\n57 +            orderRepository.save(order);\n58 +        }\n59 +    }\n60 +\n61 +    public String getOrderSummary(String orderId) {\n62 +        Order order = orderRepository.findById(orderId).orElse(null);\n63 +        Customer customer = customerRepository.findById(order.getCustomerId()).orElse(null);\n64 +\n65 +        StringBuilder summary = new StringBuilder();\n66 +        summary.append(\"Order: \").append(order.getId()).append(\"\\n\");\n67 +        summary.append(\"Customer: \").append(customer.getName()).append(\"\\n\");\n68 +        summary.append(\"Email: \").append(customer.getEmail()).append(\"\\n\");\n69 +        summary.append(\"Total: \").append(order.getTotal()).append(\"\\n\");\n70 +\n71 +        return summary.toString();\n72 +    }\n73 +\n74 +    public void applyDiscount(String orderId, String couponCode) {\n75 +        Order order = orderRepository.findById(orderId).orElse(null);\n76 +\n77 +        if (order != null && couponCode != null) {\n78 +            BigDecimal discount = calculateDiscount(couponCode, order.getTotal());\n79 +            order.setDiscount(discount);\n80 +            order.setTotal(order.getTotal().subtract(discount));\n81 +            orderRepository.save(order);\n82 +        }\n83 +    }\n84 +\n85 +    private BigDecimal calculateDiscount(String couponCode, BigDecimal total) {\n86 +        if (couponCode.startsWith(\"PERCENT\")) {\n87 +            int percent = Integer.parseInt(couponCode.substring(7));\n88 +            return total.multiply(new BigDecimal(percent)).divide(new BigDecimal(100));\n89 +        }\n90 +        return BigDecimal.ZERO;\n91 +    }\n92 +\n93 +    public boolean cancelOrder(String orderId) {\n94 +        Optional<Order> orderOpt = orderRepository.findById(orderId);\n95 +        if (orderOpt.isPresent()) {\n96 +            Order order = orderOpt.get();\n97 +            if (!\"SHIPPED\".equals(order.getStatus())) {\n98 +                order.setStatus(\"CANCELLED\");\n99 +                orderRepository.save(order);\n100 +                return true;\n101 +            }\n102 +        }\n103 +        return false;\n104 +    }\n105 +}\n106 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/OrderService.java\",\"relevantLinesStart\":28,\"relevantLinesEnd\":32},{\"relevantFile\":\"src/main/java/com/app/service/OrderService.java\",\"relevantLinesStart\":50,\"relevantLinesEnd\":52},{\"relevantFile\":\"src/main/java/com/app/service/OrderService.java\",\"relevantLinesStart\":60,\"relevantLinesEnd\":61}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"Customer customer = customerRepository.findById(customerId).orElse(null);\\n        \\n        Order order = new Order();\\n        order.setCustomerId(customerId);\\n        order.setCustomerEmail(customer.getEmail());\",\n    \"improvedCode\": \"Customer customer = customerRepository.findById(customerId)\\n            .orElseThrow(() -> new IllegalArgumentException(\\\"Customer not found: \\\" + customerId));\\n        \\n        Order order = new Order();\\n        order.setCustomerId(customerId);\\n        order.setCustomerEmail(customer.getEmail());\",\n    \"relevantFile\": \"src/main/java/com/app/service/OrderService.java\",\n    \"relevantLinesEnd\": 32,\n    \"suggestionContent\": \"In `createOrder`, `customerRepository.findById()` returns null via `orElse(null)`, then `customer.getEmail()` is called without null check. If customer doesn't exist, this throws NullPointerException.\",\n    \"oneSentenceSummary\": \"NullPointerException when customer not found - null.getEmail() called\",\n    \"relevantLinesStart\": 28\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"Order order = orderRepository.findById(orderId).orElse(null);\\n        \\n        logger.info(\\\"Processing order {} for customer {}\\\", order.getId(), order.getCustomerId());\",\n    \"improvedCode\": \"Order order = orderRepository.findById(orderId)\\n            .orElseThrow(() -> new IllegalArgumentException(\\\"Order not found: \\\" + orderId));\\n        \\n        logger.info(\\\"Processing order {} for customer {}\\\", order.getId(), order.getCustomerId());\",\n    \"relevantFile\": \"src/main/java/com/app/service/OrderService.java\",\n    \"relevantLinesEnd\": 52,\n    \"suggestionContent\": \"In `processOrder`, the order is retrieved with `orElse(null)` and immediately used without null check. If order doesn't exist, `order.getId()` throws NullPointerException.\",\n    \"oneSentenceSummary\": \"NullPointerException in processOrder when order not found\",\n    \"relevantLinesStart\": 50\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"Order order = orderRepository.findById(orderId).orElse(null);\\n        Customer customer = customerRepository.findById(order.getCustomerId()).orElse(null);\",\n    \"improvedCode\": \"Order order = orderRepository.findById(orderId)\\n            .orElseThrow(() -> new IllegalArgumentException(\\\"Order not found\\\"));\\n        Customer customer = customerRepository.findById(order.getCustomerId())\\n            .orElseThrow(() -> new IllegalArgumentException(\\\"Customer not found\\\"));\",\n    \"relevantFile\": \"src/main/java/com/app/service/OrderService.java\",\n    \"relevantLinesEnd\": 61,\n    \"suggestionContent\": \"In `getOrderSummary`, both order and customer can be null, but both are dereferenced without checks. The method chains `order.getCustomerId()` even when order might be null.\",\n    \"oneSentenceSummary\": \"Multiple NullPointerException risks - order and customer accessed without null checks\",\n    \"relevantLinesStart\": 60\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 60: src/main/java/com/app/service/CacheService.java",
    "vars": {
      "fileContent": "package com.app.service;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.*;\nimport java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\n\npublic class CacheService {\n    private static final Logger logger = LoggerFactory.getLogger(CacheService.class);\n\n    private final Map<String, byte[]> cache = new ConcurrentHashMap<>();\n    private final String cacheDirectory;\n\n    public CacheService(String cacheDirectory) {\n        this.cacheDirectory = cacheDirectory;\n    }\n\n    public void put(String key, Object value) {\n        try {\n            ByteArrayOutputStream bos = new ByteArrayOutputStream();\n            ObjectOutputStream oos = new ObjectOutputStream(bos);\n            oos.writeObject(value);\n            oos.close();\n\n            cache.put(key, bos.toByteArray());\n        } catch (IOException e) {\n            logger.error(\"Failed to serialize object for key {}\", key, e);\n        }\n    }\n\n    public Object get(String key) {\n        byte[] data = cache.get(key);\n        if (data == null) {\n            return null;\n        }\n\n        try {\n            ByteArrayInputStream bis = new ByteArrayInputStream(data);\n            ObjectInputStream ois = new ObjectInputStream(bis);\n            return ois.readObject();\n        } catch (Exception e) {\n            logger.error(\"Failed to deserialize object for key {}\", key, e);\n            return null;\n        }\n    }\n\n    public void saveToFile(String key) {\n        byte[] data = cache.get(key);\n        if (data == null) {\n            return;\n        }\n\n        try {\n            String filePath = cacheDirectory + \"/\" + key + \".cache\";\n            FileOutputStream fos = new FileOutputStream(filePath);\n            fos.write(data);\n            fos.close();\n        } catch (IOException e) {\n            logger.error(\"Failed to save cache to file\", e);\n        }\n    }\n\n    public Object loadFromFile(String key) {\n        String filePath = cacheDirectory + \"/\" + key + \".cache\";\n\n        try {\n            FileInputStream fis = new FileInputStream(filePath);\n            ObjectInputStream ois = new ObjectInputStream(fis);\n            Object obj = ois.readObject();\n            ois.close();\n\n            return obj;\n        } catch (Exception e) {\n            logger.error(\"Failed to load cache from file\", e);\n            return null;\n        }\n    }\n\n    public void importCache(byte[] serializedData) {\n        try {\n            ByteArrayInputStream bis = new ByteArrayInputStream(serializedData);\n            ObjectInputStream ois = new ObjectInputStream(bis);\n\n            @SuppressWarnings(\"unchecked\")\n            Map<String, byte[]> importedCache = (Map<String, byte[]>) ois.readObject();\n\n            cache.putAll(importedCache);\n            logger.info(\"Imported {} cache entries\", importedCache.size());\n        } catch (Exception e) {\n            logger.error(\"Failed to import cache\", e);\n        }\n    }\n\n    public byte[] exportCache() {\n        try {\n            ByteArrayOutputStream bos = new ByteArrayOutputStream();\n            ObjectOutputStream oos = new ObjectOutputStream(bos);\n            oos.writeObject(new HashMap<>(cache));\n            oos.close();\n\n            return bos.toByteArray();\n        } catch (IOException e) {\n            logger.error(\"Failed to export cache\", e);\n            return null;\n        }\n    }\n\n    public void clear() {\n        cache.clear();\n    }\n}\n",
      "patchWithLinesStr": "## file: 'src/main/java/com/app/service/CacheService.java'\n\n@@ -0,0 +1,114 @@\n__new hunk__\n1 +package com.app.service;\n2 +\n3 +import org.slf4j.Logger;\n4 +import org.slf4j.LoggerFactory;\n5 +\n6 +import java.io.*;\n7 +import java.util.*;\n8 +import java.util.concurrent.ConcurrentHashMap;\n9 +\n10 +public class CacheService {\n11 +    private static final Logger logger = LoggerFactory.getLogger(CacheService.class);\n12 +\n13 +    private final Map<String, byte[]> cache = new ConcurrentHashMap<>();\n14 +    private final String cacheDirectory;\n15 +\n16 +    public CacheService(String cacheDirectory) {\n17 +        this.cacheDirectory = cacheDirectory;\n18 +    }\n19 +\n20 +    public void put(String key, Object value) {\n21 +        try {\n22 +            ByteArrayOutputStream bos = new ByteArrayOutputStream();\n23 +            ObjectOutputStream oos = new ObjectOutputStream(bos);\n24 +            oos.writeObject(value);\n25 +            oos.close();\n26 +\n27 +            cache.put(key, bos.toByteArray());\n28 +        } catch (IOException e) {\n29 +            logger.error(\"Failed to serialize object for key {}\", key, e);\n30 +        }\n31 +    }\n32 +\n33 +    public Object get(String key) {\n34 +        byte[] data = cache.get(key);\n35 +        if (data == null) {\n36 +            return null;\n37 +        }\n38 +\n39 +        try {\n40 +            ByteArrayInputStream bis = new ByteArrayInputStream(data);\n41 +            ObjectInputStream ois = new ObjectInputStream(bis);\n42 +            return ois.readObject();\n43 +        } catch (Exception e) {\n44 +            logger.error(\"Failed to deserialize object for key {}\", key, e);\n45 +            return null;\n46 +        }\n47 +    }\n48 +\n49 +    public void saveToFile(String key) {\n50 +        byte[] data = cache.get(key);\n51 +        if (data == null) {\n52 +            return;\n53 +        }\n54 +\n55 +        try {\n56 +            String filePath = cacheDirectory + \"/\" + key + \".cache\";\n57 +            FileOutputStream fos = new FileOutputStream(filePath);\n58 +            fos.write(data);\n59 +            fos.close();\n60 +        } catch (IOException e) {\n61 +            logger.error(\"Failed to save cache to file\", e);\n62 +        }\n63 +    }\n64 +\n65 +    public Object loadFromFile(String key) {\n66 +        String filePath = cacheDirectory + \"/\" + key + \".cache\";\n67 +\n68 +        try {\n69 +            FileInputStream fis = new FileInputStream(filePath);\n70 +            ObjectInputStream ois = new ObjectInputStream(fis);\n71 +            Object obj = ois.readObject();\n72 +            ois.close();\n73 +\n74 +            return obj;\n75 +        } catch (Exception e) {\n76 +            logger.error(\"Failed to load cache from file\", e);\n77 +            return null;\n78 +        }\n79 +    }\n80 +\n81 +    public void importCache(byte[] serializedData) {\n82 +        try {\n83 +            ByteArrayInputStream bis = new ByteArrayInputStream(serializedData);\n84 +            ObjectInputStream ois = new ObjectInputStream(bis);\n85 +\n86 +            @SuppressWarnings(\"unchecked\")\n87 +            Map<String, byte[]> importedCache = (Map<String, byte[]>) ois.readObject();\n88 +\n89 +            cache.putAll(importedCache);\n90 +            logger.info(\"Imported {} cache entries\", importedCache.size());\n91 +        } catch (Exception e) {\n92 +            logger.error(\"Failed to import cache\", e);\n93 +        }\n94 +    }\n95 +\n96 +    public byte[] exportCache() {\n97 +        try {\n98 +            ByteArrayOutputStream bos = new ByteArrayOutputStream();\n99 +            ObjectOutputStream oos = new ObjectOutputStream(bos);\n100 +            oos.writeObject(new HashMap<>(cache));\n101 +            oos.close();\n102 +\n103 +            return bos.toByteArray();\n104 +        } catch (IOException e) {\n105 +            logger.error(\"Failed to export cache\", e);\n106 +            return null;\n107 +        }\n108 +    }\n109 +\n110 +    public void clear() {\n111 +        cache.clear();\n112 +    }\n113 +}\n114 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"src/main/java/com/app/service/CacheService.java\",\"relevantLinesStart\":67,\"relevantLinesEnd\":68},{\"relevantFile\":\"src/main/java/com/app/service/CacheService.java\",\"relevantLinesStart\":78,\"relevantLinesEnd\":81}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"ObjectInputStream ois = new ObjectInputStream(fis);\\n            Object obj = ois.readObject();\",\n    \"improvedCode\": \"// Use JSON serialization instead of Java serialization\\n// ObjectMapper mapper = new ObjectMapper();\\n// Object obj = mapper.readValue(fis, expectedClass);\",\n    \"relevantFile\": \"src/main/java/com/app/service/CacheService.java\",\n    \"relevantLinesEnd\": 68,\n    \"suggestionContent\": \"The `loadFromFile` and `importCache` methods use `ObjectInputStream` to deserialize data from files and external input. Java deserialization is inherently unsafe - malicious serialized data can execute arbitrary code during deserialization. An attacker can craft payloads using gadget chains (like Apache Commons Collections). Use JSON or other safe formats instead.\",\n    \"oneSentenceSummary\": \"Insecure deserialization - ObjectInputStream can execute arbitrary code\",\n    \"relevantLinesStart\": 67\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Java\",\n    \"existingCode\": \"public void importCache(byte[] serializedData) {\\n        try {\\n            ByteArrayInputStream bis = new ByteArrayInputStream(serializedData);\\n            ObjectInputStream ois = new ObjectInputStream(bis);\",\n    \"improvedCode\": \"// Never deserialize untrusted data with ObjectInputStream\\n// Use a whitelist-based ObjectInputFilter or switch to JSON\\npublic void importCache(String jsonData) {\\n    ObjectMapper mapper = new ObjectMapper();\\n    TypeReference<Map<String, byte[]>> typeRef = new TypeReference<>() {};\\n    Map<String, byte[]> importedCache = mapper.readValue(jsonData, typeRef);\",\n    \"relevantFile\": \"src/main/java/com/app/service/CacheService.java\",\n    \"relevantLinesEnd\": 81,\n    \"suggestionContent\": \"The `importCache` method deserializes external data passed as a byte array parameter. This is especially dangerous as the data likely comes from an untrusted source (network, user upload). Remote code execution is possible.\",\n    \"oneSentenceSummary\": \"Deserializing untrusted byte array enables remote code execution\",\n    \"relevantLinesStart\": 78\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 61: app/services/data_processor.rb",
    "vars": {
      "fileContent": "class DataProcessor\n  def initialize\n    @processors = []\n    @results = []\n  end\n\n  def register_processors(configs)\n    configs.each do |config|\n      @processors << lambda { |data| process_with_config(data, config) }\n    end\n  end\n\n  def build_validators(rules)\n    validators = []\n    rules.each do |rule|\n      validators << Proc.new { |value| validate_with_rule(value, rule) }\n    end\n    validators\n  end\n\n  def create_handlers(names)\n    handlers = {}\n    names.each do |name|\n      handlers[name] = -> { handle(name) }\n    end\n    handlers\n  end\n\n  def process_all(data_list)\n    data_list.each do |data|\n      @processors.each { |p| @results << p.call(data) }\n    end\n    @results\n  end\n\n  def async_process(items)\n    threads = []\n    items.each do |item|\n      threads << Thread.new { process_item(item) }\n    end\n    threads.map(&:value)\n  end\n\n  def filter_with_callback(items, &callback)\n    results = []\n    items.each do |item|\n      result = callback.call(item)\n      results << item if result\n    end\n    results\n  end\n\n  private\n\n  def process_with_config(data, config)\n    # Processing logic\n    { data: data, config: config[:name] }\n  end\n\n  def validate_with_rule(value, rule)\n    case rule[:type]\n    when :required then !value.nil? && !value.empty?\n    when :min_length then value.to_s.length >= rule[:value]\n    when :max_length then value.to_s.length <= rule[:value]\n    else true\n    end\n  end\n\n  def handle(name)\n    \"Handled: #{name}\"\n  end\n\n  def process_item(item)\n    # Item processing\n    item.to_s.upcase\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/data_processor.rb'\n\n@@ -0,0 +1,78 @@\n__new hunk__\n1 +class DataProcessor\n2 +  def initialize\n3 +    @processors = []\n4 +    @results = []\n5 +  end\n6 +\n7 +  def register_processors(configs)\n8 +    configs.each do |config|\n9 +      @processors << lambda { |data| process_with_config(data, config) }\n10 +    end\n11 +  end\n12 +\n13 +  def build_validators(rules)\n14 +    validators = []\n15 +    rules.each do |rule|\n16 +      validators << Proc.new { |value| validate_with_rule(value, rule) }\n17 +    end\n18 +    validators\n19 +  end\n20 +\n21 +  def create_handlers(names)\n22 +    handlers = {}\n23 +    names.each do |name|\n24 +      handlers[name] = -> { handle(name) }\n25 +    end\n26 +    handlers\n27 +  end\n28 +\n29 +  def process_all(data_list)\n30 +    data_list.each do |data|\n31 +      @processors.each { |p| @results << p.call(data) }\n32 +    end\n33 +    @results\n34 +  end\n35 +\n36 +  def async_process(items)\n37 +    threads = []\n38 +    items.each do |item|\n39 +      threads << Thread.new { process_item(item) }\n40 +    end\n41 +    threads.map(&:value)\n42 +  end\n43 +\n44 +  def filter_with_callback(items, &callback)\n45 +    results = []\n46 +    items.each do |item|\n47 +      result = callback.call(item)\n48 +      results << item if result\n49 +    end\n50 +    results\n51 +  end\n52 +\n53 +  private\n54 +\n55 +  def process_with_config(data, config)\n56 +    # Processing logic\n57 +    { data: data, config: config[:name] }\n58 +  end\n59 +\n60 +  def validate_with_rule(value, rule)\n61 +    case rule[:type]\n62 +    when :required then !value.nil? && !value.empty?\n63 +    when :min_length then value.to_s.length >= rule[:value]\n64 +    when :max_length then value.to_s.length <= rule[:value]\n65 +    else true\n66 +    end\n67 +  end\n68 +\n69 +  def handle(name)\n70 +    \"Handled: #{name}\"\n71 +  end\n72 +\n73 +  def process_item(item)\n74 +    # Item processing\n75 +    item.to_s.upcase\n76 +  end\n77 +end\n78 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/data_processor.rb\",\"relevantLinesStart\":8,\"relevantLinesEnd\":10}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"configs.each do |config|\\n      @processors << lambda { |data| process_with_config(data, config) }\\n    end\",\n    \"improvedCode\": \"configs.each do |config|\\n      config_copy = config.dup.freeze\\n      @processors << lambda { |data| process_with_config(data, config_copy) }\\n    end\",\n    \"relevantFile\": \"app/services/data_processor.rb\",\n    \"relevantLinesEnd\": 10,\n    \"suggestionContent\": \"The `register_processors` method captures `config` in a lambda inside a loop. However, unlike Python, Ruby's blocks capture variables by reference at closure creation time correctly. But there's still an issue: if configs is mutated after registration, the lambdas will use the mutated values. More importantly, this pattern creates a memory leak as each lambda holds a reference to the config objects.\",\n    \"oneSentenceSummary\": \"Lambda captures mutable config reference - changes after registration affect behavior\",\n    \"relevantLinesStart\": 8\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 62: app/services/pricing_calculator.rb",
    "vars": {
      "fileContent": "class PricingCalculator\n  TAX_RATE = 0.08\n  DISCOUNT_THRESHOLD = 100.0\n\n  def calculate_total(items)\n    subtotal = items.sum { |item| item[:price] * item[:quantity] }\n    tax = subtotal * TAX_RATE\n    subtotal + tax\n  end\n\n  def apply_discount(total, discount_percent)\n    discount = total * (discount_percent / 100.0)\n    total - discount\n  end\n\n  def verify_payment(expected, received)\n    expected == received\n  end\n\n  def is_zero_balance?(balance)\n    balance == 0.0\n  end\n\n  def split_bill(total, people_count)\n    per_person = total / people_count\n    remainder = total - (per_person * people_count)\n\n    shares = Array.new(people_count, per_person)\n    shares[-1] += remainder if remainder != 0.0\n\n    shares\n  end\n\n  def prices_match?(price1, price2)\n    price1 == price2\n  end\n\n  def calculate_change(paid, owed)\n    change = paid - owed\n    return 0.0 if change == 0.0\n    change\n  end\n\n  def eligible_for_discount?(subtotal)\n    subtotal == DISCOUNT_THRESHOLD || subtotal > DISCOUNT_THRESHOLD\n  end\n\n  def round_to_cents(amount)\n    (amount * 100).round / 100.0\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/pricing_calculator.rb'\n\n@@ -0,0 +1,52 @@\n__new hunk__\n1 +class PricingCalculator\n2 +  TAX_RATE = 0.08\n3 +  DISCOUNT_THRESHOLD = 100.0\n4 +\n5 +  def calculate_total(items)\n6 +    subtotal = items.sum { |item| item[:price] * item[:quantity] }\n7 +    tax = subtotal * TAX_RATE\n8 +    subtotal + tax\n9 +  end\n10 +\n11 +  def apply_discount(total, discount_percent)\n12 +    discount = total * (discount_percent / 100.0)\n13 +    total - discount\n14 +  end\n15 +\n16 +  def verify_payment(expected, received)\n17 +    expected == received\n18 +  end\n19 +\n20 +  def is_zero_balance?(balance)\n21 +    balance == 0.0\n22 +  end\n23 +\n24 +  def split_bill(total, people_count)\n25 +    per_person = total / people_count\n26 +    remainder = total - (per_person * people_count)\n27 +\n28 +    shares = Array.new(people_count, per_person)\n29 +    shares[-1] += remainder if remainder != 0.0\n30 +\n31 +    shares\n32 +  end\n33 +\n34 +  def prices_match?(price1, price2)\n35 +    price1 == price2\n36 +  end\n37 +\n38 +  def calculate_change(paid, owed)\n39 +    change = paid - owed\n40 +    return 0.0 if change == 0.0\n41 +    change\n42 +  end\n43 +\n44 +  def eligible_for_discount?(subtotal)\n45 +    subtotal == DISCOUNT_THRESHOLD || subtotal > DISCOUNT_THRESHOLD\n46 +  end\n47 +\n48 +  def round_to_cents(amount)\n49 +    (amount * 100).round / 100.0\n50 +  end\n51 +end\n52 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/pricing_calculator.rb\",\"relevantLinesStart\":16,\"relevantLinesEnd\":18},{\"relevantFile\":\"app/services/pricing_calculator.rb\",\"relevantLinesStart\":20,\"relevantLinesEnd\":22}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def verify_payment(expected, received)\\n    expected == received\\n  end\",\n    \"improvedCode\": \"def verify_payment(expected, received)\\n    (expected - received).abs < 0.001\\n  end\",\n    \"relevantFile\": \"app/services/pricing_calculator.rb\",\n    \"relevantLinesEnd\": 18,\n    \"suggestionContent\": \"The `verify_payment` method compares floating point numbers with `==`. Due to floating point representation, `0.1 + 0.2 != 0.3` in Ruby. Payment amounts like `100.10 + 50.20` may not equal `150.30` exactly. Use a threshold comparison or `BigDecimal` for financial calculations.\",\n    \"oneSentenceSummary\": \"Floating point == comparison fails due to precision errors\",\n    \"relevantLinesStart\": 16\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def is_zero_balance?(balance)\\n    balance == 0.0\\n  end\",\n    \"improvedCode\": \"def is_zero_balance?(balance)\\n    balance.abs < 0.001\\n  end\",\n    \"relevantFile\": \"app/services/pricing_calculator.rb\",\n    \"relevantLinesEnd\": 22,\n    \"suggestionContent\": \"The `is_zero_balance?` method compares with `0.0` using `==`. A balance calculated as `100.0 - 50.0 - 50.0` might be `1.4210854715202004e-14` instead of exactly `0.0`. This causes incorrect zero detection.\",\n    \"oneSentenceSummary\": \"Zero check fails for near-zero floating point values\",\n    \"relevantLinesStart\": 20\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 63: app/controllers/users_controller.rb",
    "vars": {
      "fileContent": "class UsersController < ApplicationController\n  before_action :authenticate_user!\n  before_action :set_user, only: [:show, :edit, :update, :destroy]\n\n  def index\n    @users = User.all\n  end\n\n  def show\n  end\n\n  def new\n    @user = User.new\n  end\n\n  def create\n    @user = User.new(params[:user])\n\n    if @user.save\n      redirect_to @user, notice: 'User created successfully.'\n    else\n      render :new\n    end\n  end\n\n  def edit\n  end\n\n  def update\n    if @user.update(params[:user])\n      redirect_to @user, notice: 'User updated successfully.'\n    else\n      render :edit\n    end\n  end\n\n  def destroy\n    @user.destroy\n    redirect_to users_path, notice: 'User deleted.'\n  end\n\n  def bulk_update\n    params[:users].each do |user_data|\n      user = User.find(user_data[:id])\n      user.update(user_data)\n    end\n    redirect_to users_path, notice: 'Users updated.'\n  end\n\n  def profile_update\n    current_user.update(params.permit(:name, :email, :avatar))\n    redirect_to profile_path\n  end\n\n  private\n\n  def set_user\n    @user = User.find(params[:id])\n  end\n\n  def user_params\n    params.require(:user).permit(:name, :email, :password, :password_confirmation)\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/controllers/users_controller.rb'\n\n@@ -0,0 +1,65 @@\n__new hunk__\n1 +class UsersController < ApplicationController\n2 +  before_action :authenticate_user!\n3 +  before_action :set_user, only: [:show, :edit, :update, :destroy]\n4 +\n5 +  def index\n6 +    @users = User.all\n7 +  end\n8 +\n9 +  def show\n10 +  end\n11 +\n12 +  def new\n13 +    @user = User.new\n14 +  end\n15 +\n16 +  def create\n17 +    @user = User.new(params[:user])\n18 +\n19 +    if @user.save\n20 +      redirect_to @user, notice: 'User created successfully.'\n21 +    else\n22 +      render :new\n23 +    end\n24 +  end\n25 +\n26 +  def edit\n27 +  end\n28 +\n29 +  def update\n30 +    if @user.update(params[:user])\n31 +      redirect_to @user, notice: 'User updated successfully.'\n32 +    else\n33 +      render :edit\n34 +    end\n35 +  end\n36 +\n37 +  def destroy\n38 +    @user.destroy\n39 +    redirect_to users_path, notice: 'User deleted.'\n40 +  end\n41 +\n42 +  def bulk_update\n43 +    params[:users].each do |user_data|\n44 +      user = User.find(user_data[:id])\n45 +      user.update(user_data)\n46 +    end\n47 +    redirect_to users_path, notice: 'Users updated.'\n48 +  end\n49 +\n50 +  def profile_update\n51 +    current_user.update(params.permit(:name, :email, :avatar))\n52 +    redirect_to profile_path\n53 +  end\n54 +\n55 +  private\n56 +\n57 +  def set_user\n58 +    @user = User.find(params[:id])\n59 +  end\n60 +\n61 +  def user_params\n62 +    params.require(:user).permit(:name, :email, :password, :password_confirmation)\n63 +  end\n64 +end\n65 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/controllers/users_controller.rb\",\"relevantLinesStart\":17,\"relevantLinesEnd\":17},{\"relevantFile\":\"app/controllers/users_controller.rb\",\"relevantLinesStart\":30,\"relevantLinesEnd\":30},{\"relevantFile\":\"app/controllers/users_controller.rb\",\"relevantLinesStart\":42,\"relevantLinesEnd\":45}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"@user = User.new(params[:user])\",\n    \"improvedCode\": \"@user = User.new(user_params)\",\n    \"relevantFile\": \"app/controllers/users_controller.rb\",\n    \"relevantLinesEnd\": 17,\n    \"suggestionContent\": \"The `create` method uses `params[:user]` directly without strong parameters, allowing mass assignment. An attacker can pass `user[admin]=true` or `user[role]=superadmin` to escalate privileges. Always use permitted parameters.\",\n    \"oneSentenceSummary\": \"Mass assignment vulnerability allows setting admin/role attributes\",\n    \"relevantLinesStart\": 17\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"if @user.update(params[:user])\",\n    \"improvedCode\": \"if @user.update(user_params)\",\n    \"relevantFile\": \"app/controllers/users_controller.rb\",\n    \"relevantLinesEnd\": 30,\n    \"suggestionContent\": \"The `update` method also uses `params[:user]` directly. Combined with `set_user` that finds by ID, an attacker can modify any user's attributes including sensitive fields like `admin`, `role`, or `password`.\",\n    \"oneSentenceSummary\": \"Mass assignment in update allows privilege escalation\",\n    \"relevantLinesStart\": 30\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"params[:users].each do |user_data|\\n      user = User.find(user_data[:id])\\n      user.update(user_data)\\n    end\",\n    \"improvedCode\": \"params[:users].each do |user_data|\\n      user = User.find(user_data[:id])\\n      permitted = user_data.permit(:name, :email)\\n      user.update(permitted)\\n    end\",\n    \"relevantFile\": \"app/controllers/users_controller.rb\",\n    \"relevantLinesEnd\": 45,\n    \"suggestionContent\": \"The `bulk_update` method iterates over user params without any permission checking. An attacker can update any user's attributes by passing arbitrary user IDs and data, including making themselves admin.\",\n    \"oneSentenceSummary\": \"Bulk update allows mass assignment on arbitrary users\",\n    \"relevantLinesStart\": 42\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 64: app/services/notification_service.rb",
    "vars": {
      "fileContent": "class NotificationService\n  def initialize(config = {})\n    @config = config\n    @notifications = []\n  end\n\n  def create_notification(user_id:, message:, metadata: {})\n    notification = {\n      id: SecureRandom.uuid,\n      user_id: user_id,\n      message: message,\n      metadata: metadata,\n      created_at: Time.current\n    }\n\n    metadata[:sent_at] = Time.current\n    @notifications << notification\n\n    Rails.logger.info(\"Created notification for user #{user_id}\")\n    notification\n  end\n\n  def bulk_notify(user_ids, message, tags: [])\n    user_ids.each do |user_id|\n      tags << \"bulk_#{user_id}\"\n      create_notification(\n        user_id: user_id,\n        message: message,\n        metadata: { tags: tags }\n      )\n    end\n  end\n\n  def get_notifications(user_id)\n    @notifications.select { |n| n[:user_id] == user_id }\n  end\n\n  def clear_notifications\n    @notifications.clear\n  end\n\n  def notification_count\n    @notifications.size\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/notification_service.rb'\n\n@@ -0,0 +1,46 @@\n__new hunk__\n1 +class NotificationService\n2 +  def initialize(config = {})\n3 +    @config = config\n4 +    @notifications = []\n5 +  end\n6 +\n7 +  def create_notification(user_id:, message:, metadata: {})\n8 +    notification = {\n9 +      id: SecureRandom.uuid,\n10 +      user_id: user_id,\n11 +      message: message,\n12 +      metadata: metadata,\n13 +      created_at: Time.current\n14 +    }\n15 +\n16 +    metadata[:sent_at] = Time.current\n17 +    @notifications << notification\n18 +\n19 +    Rails.logger.info(\"Created notification for user #{user_id}\")\n20 +    notification\n21 +  end\n22 +\n23 +  def bulk_notify(user_ids, message, tags: [])\n24 +    user_ids.each do |user_id|\n25 +      tags << \"bulk_#{user_id}\"\n26 +      create_notification(\n27 +        user_id: user_id,\n28 +        message: message,\n29 +        metadata: { tags: tags }\n30 +      )\n31 +    end\n32 +  end\n33 +\n34 +  def get_notifications(user_id)\n35 +    @notifications.select { |n| n[:user_id] == user_id }\n36 +  end\n37 +\n38 +  def clear_notifications\n39 +    @notifications.clear\n40 +  end\n41 +\n42 +  def notification_count\n43 +    @notifications.size\n44 +  end\n45 +end\n46 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/notification_service.rb\",\"relevantLinesStart\":7,\"relevantLinesEnd\":7},{\"relevantFile\":\"app/services/notification_service.rb\",\"relevantLinesStart\":23,\"relevantLinesEnd\":25}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def create_notification(user_id:, message:, metadata: {})\",\n    \"improvedCode\": \"def create_notification(user_id:, message:, metadata: nil)\\n    metadata ||= {}\",\n    \"relevantFile\": \"app/services/notification_service.rb\",\n    \"relevantLinesEnd\": 7,\n    \"suggestionContent\": \"The `create_notification` method has a mutable default argument `metadata: {}`. In Ruby, default argument values are evaluated once when the method is defined, not on each call. All calls without metadata will share the same hash object. When `metadata[:sent_at] = Time.current` is executed, it modifies this shared hash, affecting all notifications.\",\n    \"oneSentenceSummary\": \"Mutable default argument causes shared state between method calls\",\n    \"relevantLinesStart\": 7\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def bulk_notify(user_ids, message, tags: [])\\n    user_ids.each do |user_id|\\n      tags << \\\"bulk_#{user_id}\\\"\",\n    \"improvedCode\": \"def bulk_notify(user_ids, message, tags: nil)\\n    tags = (tags || []).dup\\n    user_ids.each do |user_id|\\n      tags << \\\"bulk_#{user_id}\\\"\",\n    \"relevantFile\": \"app/services/notification_service.rb\",\n    \"relevantLinesEnd\": 25,\n    \"suggestionContent\": \"The `bulk_notify` method has `tags: []` as a default argument. The `tags << \\\"bulk_#{user_id}\\\"` modifies this shared array. After one bulk operation, subsequent calls will have all previous tags accumulated.\",\n    \"oneSentenceSummary\": \"Mutable default array accumulates values across calls\",\n    \"relevantLinesStart\": 23\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 65: app/services/config_loader.rb",
    "vars": {
      "fileContent": "require 'yaml'\nrequire 'erb'\n\nclass ConfigLoader\n  def initialize(config_dir)\n    @config_dir = config_dir\n    @cache = {}\n  end\n\n  def load_config(filename)\n    return @cache[filename] if @cache[filename]\n\n    filepath = File.join(@config_dir, filename)\n    raise \"Config file not found: #{filepath}\" unless File.exist?(filepath)\n\n    content = File.read(filepath)\n    config = YAML.load(content)\n\n    @cache[filename] = config\n    config\n  end\n\n  def load_config_with_erb(filename)\n    filepath = File.join(@config_dir, filename)\n    content = File.read(filepath)\n    processed = ERB.new(content).result\n    YAML.load(processed)\n  end\n\n  def load_from_string(yaml_string)\n    YAML.load(yaml_string)\n  end\n\n  def load_all_configs\n    configs = {}\n    Dir.glob(File.join(@config_dir, '*.yml')).each do |filepath|\n      name = File.basename(filepath, '.yml')\n      configs[name] = YAML.load(File.read(filepath))\n    end\n    configs\n  end\n\n  def merge_configs(*filenames)\n    result = {}\n    filenames.each do |filename|\n      config = load_config(filename)\n      result = deep_merge(result, config)\n    end\n    result\n  end\n\n  def reload_config(filename)\n    @cache.delete(filename)\n    load_config(filename)\n  end\n\n  private\n\n  def deep_merge(hash1, hash2)\n    hash1.merge(hash2) do |_key, old_val, new_val|\n      if old_val.is_a?(Hash) && new_val.is_a?(Hash)\n        deep_merge(old_val, new_val)\n      else\n        new_val\n      end\n    end\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/config_loader.rb'\n\n@@ -0,0 +1,69 @@\n__new hunk__\n1 +require 'yaml'\n2 +require 'erb'\n3 +\n4 +class ConfigLoader\n5 +  def initialize(config_dir)\n6 +    @config_dir = config_dir\n7 +    @cache = {}\n8 +  end\n9 +\n10 +  def load_config(filename)\n11 +    return @cache[filename] if @cache[filename]\n12 +\n13 +    filepath = File.join(@config_dir, filename)\n14 +    raise \"Config file not found: #{filepath}\" unless File.exist?(filepath)\n15 +\n16 +    content = File.read(filepath)\n17 +    config = YAML.load(content)\n18 +\n19 +    @cache[filename] = config\n20 +    config\n21 +  end\n22 +\n23 +  def load_config_with_erb(filename)\n24 +    filepath = File.join(@config_dir, filename)\n25 +    content = File.read(filepath)\n26 +    processed = ERB.new(content).result\n27 +    YAML.load(processed)\n28 +  end\n29 +\n30 +  def load_from_string(yaml_string)\n31 +    YAML.load(yaml_string)\n32 +  end\n33 +\n34 +  def load_all_configs\n35 +    configs = {}\n36 +    Dir.glob(File.join(@config_dir, '*.yml')).each do |filepath|\n37 +      name = File.basename(filepath, '.yml')\n38 +      configs[name] = YAML.load(File.read(filepath))\n39 +    end\n40 +    configs\n41 +  end\n42 +\n43 +  def merge_configs(*filenames)\n44 +    result = {}\n45 +    filenames.each do |filename|\n46 +      config = load_config(filename)\n47 +      result = deep_merge(result, config)\n48 +    end\n49 +    result\n50 +  end\n51 +\n52 +  def reload_config(filename)\n53 +    @cache.delete(filename)\n54 +    load_config(filename)\n55 +  end\n56 +\n57 +  private\n58 +\n59 +  def deep_merge(hash1, hash2)\n60 +    hash1.merge(hash2) do |_key, old_val, new_val|\n61 +      if old_val.is_a?(Hash) && new_val.is_a?(Hash)\n62 +        deep_merge(old_val, new_val)\n63 +      else\n64 +        new_val\n65 +      end\n66 +    end\n67 +  end\n68 +end\n69 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/config_loader.rb\",\"relevantLinesStart\":17,\"relevantLinesEnd\":17}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"config = YAML.load(content)\",\n    \"improvedCode\": \"config = YAML.safe_load(content, permitted_classes: [Symbol, Date, Time])\",\n    \"relevantFile\": \"app/services/config_loader.rb\",\n    \"relevantLinesEnd\": 17,\n    \"suggestionContent\": \"Multiple methods use `YAML.load` which is unsafe in Ruby. It can deserialize arbitrary Ruby objects, allowing remote code execution. A malicious YAML file with `!ruby/object:Gem::Installer` can execute system commands. Use `YAML.safe_load` instead, which only allows basic types.\",\n    \"oneSentenceSummary\": \"YAML.load allows arbitrary code execution via malicious YAML files\",\n    \"relevantLinesStart\": 17\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 66: app/services/cache_service.rb",
    "vars": {
      "fileContent": "class CacheService\n  def initialize\n    @store = {}\n    @stats = { hits: 0, misses: 0 }\n  end\n\n  def get(key)\n    if @store.key?(key)\n      @stats[:hits] += 1\n      @store[key]\n    else\n      @stats[:misses] += 1\n      nil\n    end\n  end\n\n  def set(key, value, ttl: nil)\n    @store[key] = {\n      value: value,\n      expires_at: ttl ? Time.current + ttl : nil\n    }\n  end\n\n  def fetch(key, &block)\n    return get(key) if exists?(key)\n\n    value = block.call\n    set(key, value)\n    value\n  end\n\n  def exists?(key)\n    @store.key?(key)\n  end\n\n  def delete(key)\n    @store.delete(key)\n  end\n\n  def process_options(options)\n    ttl = options['ttl'] || options[:ttl] || 3600\n    namespace = options['namespace'] || options[:namespace] || 'default'\n    compress = options['compress'] || options[:compress] || false\n\n    { ttl: ttl, namespace: namespace, compress: compress }\n  end\n\n  def get_from_params(params)\n    key = params['key']\n    namespace = params[:namespace]\n\n    full_key = \"#{namespace}:#{key}\"\n    get(full_key)\n  end\n\n  def stats\n    @stats.dup\n  end\n\n  def clear\n    @store.clear\n    @stats = { hits: 0, misses: 0 }\n  end\n\n  def import_data(data)\n    data.each do |key, value|\n      @store[key.to_s] = value\n    end\n  end\n\n  def export_data\n    @store.transform_keys(&:to_s)\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/cache_service.rb'\n\n@@ -0,0 +1,75 @@\n__new hunk__\n1 +class CacheService\n2 +  def initialize\n3 +    @store = {}\n4 +    @stats = { hits: 0, misses: 0 }\n5 +  end\n6 +\n7 +  def get(key)\n8 +    if @store.key?(key)\n9 +      @stats[:hits] += 1\n10 +      @store[key]\n11 +    else\n12 +      @stats[:misses] += 1\n13 +      nil\n14 +    end\n15 +  end\n16 +\n17 +  def set(key, value, ttl: nil)\n18 +    @store[key] = {\n19 +      value: value,\n20 +      expires_at: ttl ? Time.current + ttl : nil\n21 +    }\n22 +  end\n23 +\n24 +  def fetch(key, &block)\n25 +    return get(key) if exists?(key)\n26 +\n27 +    value = block.call\n28 +    set(key, value)\n29 +    value\n30 +  end\n31 +\n32 +  def exists?(key)\n33 +    @store.key?(key)\n34 +  end\n35 +\n36 +  def delete(key)\n37 +    @store.delete(key)\n38 +  end\n39 +\n40 +  def process_options(options)\n41 +    ttl = options['ttl'] || options[:ttl] || 3600\n42 +    namespace = options['namespace'] || options[:namespace] || 'default'\n43 +    compress = options['compress'] || options[:compress] || false\n44 +\n45 +    { ttl: ttl, namespace: namespace, compress: compress }\n46 +  end\n47 +\n48 +  def get_from_params(params)\n49 +    key = params['key']\n50 +    namespace = params[:namespace]\n51 +\n52 +    full_key = \"#{namespace}:#{key}\"\n53 +    get(full_key)\n54 +  end\n55 +\n56 +  def stats\n57 +    @stats.dup\n58 +  end\n59 +\n60 +  def clear\n61 +    @store.clear\n62 +    @stats = { hits: 0, misses: 0 }\n63 +  end\n64 +\n65 +  def import_data(data)\n66 +    data.each do |key, value|\n67 +      @store[key.to_s] = value\n68 +    end\n69 +  end\n70 +\n71 +  def export_data\n72 +    @store.transform_keys(&:to_s)\n73 +  end\n74 +end\n75 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/cache_service.rb\",\"relevantLinesStart\":40,\"relevantLinesEnd\":42},{\"relevantFile\":\"app/services/cache_service.rb\",\"relevantLinesStart\":47,\"relevantLinesEnd\":48}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"ttl = options['ttl'] || options[:ttl] || 3600\\n    namespace = options['namespace'] || options[:namespace] || 'default'\\n    compress = options['compress'] || options[:compress] || false\",\n    \"improvedCode\": \"options = options.with_indifferent_access\\n    ttl = options.fetch(:ttl, 3600)\\n    namespace = options.fetch(:namespace, 'default')\\n    compress = options.fetch(:compress, false)\",\n    \"relevantFile\": \"app/services/cache_service.rb\",\n    \"relevantLinesEnd\": 42,\n    \"suggestionContent\": \"The `process_options` method tries to handle both string and symbol keys with `options['ttl'] || options[:ttl]`. However, if `options['ttl']` is `false` or `0`, the `||` will skip it and check `:ttl`. This causes incorrect behavior when falsy values are valid. Also, this pattern is error-prone and verbose. Use `Hash#fetch` or `HashWithIndifferentAccess`.\",\n    \"oneSentenceSummary\": \"String/symbol key handling with || fails for falsy values like false or 0\",\n    \"relevantLinesStart\": 40\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"key = params['key']\\n    namespace = params[:namespace]\",\n    \"improvedCode\": \"params = params.with_indifferent_access\\n    key = params[:key]\\n    namespace = params[:namespace]\",\n    \"relevantFile\": \"app/services/cache_service.rb\",\n    \"relevantLinesEnd\": 48,\n    \"suggestionContent\": \"The `get_from_params` method accesses `params['key']` (string) and `params[:namespace]` (symbol) inconsistently. If params uses symbol keys, `params['key']` returns nil. This causes `full_key` to be `\\\"namespace:\\\"` without the actual key.\",\n    \"oneSentenceSummary\": \"Inconsistent string/symbol key access causes nil values\",\n    \"relevantLinesStart\": 47\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 67: app/services/file_processor.rb",
    "vars": {
      "fileContent": "class FileProcessor\n  def initialize(base_path)\n    @base_path = base_path\n  end\n\n  def read_file(filename)\n    path = File.join(@base_path, filename)\n    file = File.open(path, 'r')\n    content = file.read\n    file.close\n    content\n  end\n\n  def write_file(filename, content)\n    path = File.join(@base_path, filename)\n    file = File.open(path, 'w')\n    file.write(content)\n    file.close\n  end\n\n  def process_csv(filename)\n    path = File.join(@base_path, filename)\n    file = File.open(path, 'r')\n\n    results = []\n    file.each_line do |line|\n      fields = line.strip.split(',')\n      results << process_row(fields)\n    end\n\n    file.close\n    results\n  end\n\n  def copy_file(source, destination)\n    source_path = File.join(@base_path, source)\n    dest_path = File.join(@base_path, destination)\n\n    source_file = File.open(source_path, 'rb')\n    dest_file = File.open(dest_path, 'wb')\n\n    while (chunk = source_file.read(8192))\n      dest_file.write(chunk)\n    end\n\n    source_file.close\n    dest_file.close\n  end\n\n  def read_safe(filename)\n    path = File.join(@base_path, filename)\n    File.read(path)\n  end\n\n  def write_safe(filename, content)\n    path = File.join(@base_path, filename)\n    File.write(path, content)\n  end\n\n  private\n\n  def process_row(fields)\n    { id: fields[0], name: fields[1], value: fields[2] }\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/file_processor.rb'\n\n@@ -0,0 +1,66 @@\n__new hunk__\n1 +class FileProcessor\n2 +  def initialize(base_path)\n3 +    @base_path = base_path\n4 +  end\n5 +\n6 +  def read_file(filename)\n7 +    path = File.join(@base_path, filename)\n8 +    file = File.open(path, 'r')\n9 +    content = file.read\n10 +    file.close\n11 +    content\n12 +  end\n13 +\n14 +  def write_file(filename, content)\n15 +    path = File.join(@base_path, filename)\n16 +    file = File.open(path, 'w')\n17 +    file.write(content)\n18 +    file.close\n19 +  end\n20 +\n21 +  def process_csv(filename)\n22 +    path = File.join(@base_path, filename)\n23 +    file = File.open(path, 'r')\n24 +\n25 +    results = []\n26 +    file.each_line do |line|\n27 +      fields = line.strip.split(',')\n28 +      results << process_row(fields)\n29 +    end\n30 +\n31 +    file.close\n32 +    results\n33 +  end\n34 +\n35 +  def copy_file(source, destination)\n36 +    source_path = File.join(@base_path, source)\n37 +    dest_path = File.join(@base_path, destination)\n38 +\n39 +    source_file = File.open(source_path, 'rb')\n40 +    dest_file = File.open(dest_path, 'wb')\n41 +\n42 +    while (chunk = source_file.read(8192))\n43 +      dest_file.write(chunk)\n44 +    end\n45 +\n46 +    source_file.close\n47 +    dest_file.close\n48 +  end\n49 +\n50 +  def read_safe(filename)\n51 +    path = File.join(@base_path, filename)\n52 +    File.read(path)\n53 +  end\n54 +\n55 +  def write_safe(filename, content)\n56 +    path = File.join(@base_path, filename)\n57 +    File.write(path, content)\n58 +  end\n59 +\n60 +  private\n61 +\n62 +  def process_row(fields)\n63 +    { id: fields[0], name: fields[1], value: fields[2] }\n64 +  end\n65 +end\n66 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/file_processor.rb\",\"relevantLinesStart\":6,\"relevantLinesEnd\":12},{\"relevantFile\":\"app/services/file_processor.rb\",\"relevantLinesStart\":37,\"relevantLinesEnd\":45}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def read_file(filename)\\n    path = File.join(@base_path, filename)\\n    file = File.open(path, 'r')\\n    content = file.read\\n    file.close\\n    content\\n  end\",\n    \"improvedCode\": \"def read_file(filename)\\n    path = File.join(@base_path, filename)\\n    File.open(path, 'r') do |file|\\n      file.read\\n    end\\n  end\",\n    \"relevantFile\": \"app/services/file_processor.rb\",\n    \"relevantLinesEnd\": 12,\n    \"suggestionContent\": \"The `read_file` method opens a file but if `file.read` raises an exception, `file.close` is never called, causing a file descriptor leak. Use block form of `File.open` which automatically closes the file, or use `ensure`.\",\n    \"oneSentenceSummary\": \"File descriptor leak if exception occurs before close\",\n    \"relevantLinesStart\": 6\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"source_file = File.open(source_path, 'rb')\\n    dest_file = File.open(dest_path, 'wb')\\n\\n    while (chunk = source_file.read(8192))\\n      dest_file.write(chunk)\\n    end\\n\\n    source_file.close\\n    dest_file.close\",\n    \"improvedCode\": \"File.open(source_path, 'rb') do |source_file|\\n      File.open(dest_path, 'wb') do |dest_file|\\n        while (chunk = source_file.read(8192))\\n          dest_file.write(chunk)\\n        end\\n      end\\n    end\",\n    \"relevantFile\": \"app/services/file_processor.rb\",\n    \"relevantLinesEnd\": 45,\n    \"suggestionContent\": \"The `copy_file` method opens two files but if an error occurs during copying, neither file is closed. This leaks two file descriptors per failed copy operation.\",\n    \"oneSentenceSummary\": \"Two file descriptors leaked if copy operation fails\",\n    \"relevantLinesStart\": 37\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 68: app/services/counter_service.rb",
    "vars": {
      "fileContent": "class CounterService\n  @@instance = nil\n\n  def self.instance\n    @@instance ||= new\n  end\n\n  def initialize\n    @counters = {}\n    @total = 0\n  end\n\n  def increment(name, amount = 1)\n    @counters[name] ||= 0\n    @counters[name] += amount\n    @total += amount\n  end\n\n  def decrement(name, amount = 1)\n    @counters[name] ||= 0\n    @counters[name] -= amount\n    @total -= amount\n  end\n\n  def get(name)\n    @counters[name] || 0\n  end\n\n  def total\n    @total\n  end\n\n  def check_and_increment(name, threshold)\n    current = @counters[name] || 0\n    if current < threshold\n      @counters[name] = current + 1\n      @total += 1\n      true\n    else\n      false\n    end\n  end\n\n  def reset(name)\n    old_value = @counters[name] || 0\n    @counters[name] = 0\n    @total -= old_value\n    old_value\n  end\n\n  def all_counters\n    @counters.dup\n  end\n\n  def reset_all\n    @counters.clear\n    @total = 0\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/counter_service.rb'\n\n@@ -0,0 +1,60 @@\n__new hunk__\n1 +class CounterService\n2 +  @@instance = nil\n3 +\n4 +  def self.instance\n5 +    @@instance ||= new\n6 +  end\n7 +\n8 +  def initialize\n9 +    @counters = {}\n10 +    @total = 0\n11 +  end\n12 +\n13 +  def increment(name, amount = 1)\n14 +    @counters[name] ||= 0\n15 +    @counters[name] += amount\n16 +    @total += amount\n17 +  end\n18 +\n19 +  def decrement(name, amount = 1)\n20 +    @counters[name] ||= 0\n21 +    @counters[name] -= amount\n22 +    @total -= amount\n23 +  end\n24 +\n25 +  def get(name)\n26 +    @counters[name] || 0\n27 +  end\n28 +\n29 +  def total\n30 +    @total\n31 +  end\n32 +\n33 +  def check_and_increment(name, threshold)\n34 +    current = @counters[name] || 0\n35 +    if current < threshold\n36 +      @counters[name] = current + 1\n37 +      @total += 1\n38 +      true\n39 +    else\n40 +      false\n41 +    end\n42 +  end\n43 +\n44 +  def reset(name)\n45 +    old_value = @counters[name] || 0\n46 +    @counters[name] = 0\n47 +    @total -= old_value\n48 +    old_value\n49 +  end\n50 +\n51 +  def all_counters\n52 +    @counters.dup\n53 +  end\n54 +\n55 +  def reset_all\n56 +    @counters.clear\n57 +    @total = 0\n58 +  end\n59 +end\n60 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/counter_service.rb\",\"relevantLinesStart\":4,\"relevantLinesEnd\":6},{\"relevantFile\":\"app/services/counter_service.rb\",\"relevantLinesStart\":13,\"relevantLinesEnd\":17},{\"relevantFile\":\"app/services/counter_service.rb\",\"relevantLinesStart\":33,\"relevantLinesEnd\":36}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def self.instance\\n    @@instance ||= new\\n  end\",\n    \"improvedCode\": \"require 'singleton'\\n\\nclass CounterService\\n  include Singleton\",\n    \"relevantFile\": \"app/services/counter_service.rb\",\n    \"relevantLinesEnd\": 6,\n    \"suggestionContent\": \"The singleton implementation `@@instance ||= new` is not thread-safe. Multiple threads can see `@@instance` as nil simultaneously and each create their own instance. Use `Mutex` or Ruby's built-in `Singleton` module.\",\n    \"oneSentenceSummary\": \"Non-thread-safe singleton - race condition creates multiple instances\",\n    \"relevantLinesStart\": 4\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def increment(name, amount = 1)\\n    @counters[name] ||= 0\\n    @counters[name] += amount\\n    @total += amount\\n  end\",\n    \"improvedCode\": \"def increment(name, amount = 1)\\n    @mutex.synchronize do\\n      @counters[name] ||= 0\\n      @counters[name] += amount\\n      @total += amount\\n    end\\n  end\",\n    \"relevantFile\": \"app/services/counter_service.rb\",\n    \"relevantLinesEnd\": 17,\n    \"suggestionContent\": \"The `increment` method has a race condition. The `@counters[name] += amount` is not atomic - it reads, adds, then writes. Two threads can read the same value, add their amounts, and write, losing one increment. Use `Mutex` or `Concurrent::AtomicFixnum`.\",\n    \"oneSentenceSummary\": \"Race condition in counter increment - concurrent updates lose counts\",\n    \"relevantLinesStart\": 13\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def check_and_increment(name, threshold)\\n    current = @counters[name] || 0\\n    if current < threshold\\n      @counters[name] = current + 1\",\n    \"improvedCode\": \"def check_and_increment(name, threshold)\\n    @mutex.synchronize do\\n      current = @counters[name] || 0\\n      if current < threshold\\n        @counters[name] = current + 1\",\n    \"relevantFile\": \"app/services/counter_service.rb\",\n    \"relevantLinesEnd\": 36,\n    \"suggestionContent\": \"The `check_and_increment` method has a TOCTOU (time-of-check-time-of-use) race condition. Between checking `current < threshold` and incrementing, another thread can increment past the threshold.\",\n    \"oneSentenceSummary\": \"TOCTOU race condition allows exceeding threshold\",\n    \"relevantLinesStart\": 33\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 69: app/services/text_processor.rb",
    "vars": {
      "fileContent": "class TextProcessor\n  def initialize\n    @encoding = 'UTF-8'\n  end\n\n  def read_file(path)\n    File.read(path)\n  end\n\n  def process_user_input(input)\n    input.downcase.strip\n  end\n\n  def extract_characters(text, count)\n    text[0, count]\n  end\n\n  def count_characters(text)\n    text.length\n  end\n\n  def truncate(text, max_length)\n    return text if text.length <= max_length\n    text[0, max_length] + '...'\n  end\n\n  def search_in_file(path, term)\n    content = File.read(path)\n    content.include?(term)\n  end\n\n  def parse_csv_line(line)\n    line.split(',').map(&:strip)\n  end\n\n  def normalize_whitespace(text)\n    text.gsub(/\\s+/, ' ').strip\n  end\n\n  def safe_read(path)\n    File.read(path, encoding: 'UTF-8')\n  end\n\n  def combine_strings(*strings)\n    result = ''\n    strings.each { |s| result += s }\n    result\n  end\n\n  def build_report(items)\n    report = ''\n    items.each_with_index do |item, index|\n      report += \"#{index + 1}. #{item}\\n\"\n    end\n    report\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/text_processor.rb'\n\n@@ -0,0 +1,58 @@\n__new hunk__\n1 +class TextProcessor\n2 +  def initialize\n3 +    @encoding = 'UTF-8'\n4 +  end\n5 +\n6 +  def read_file(path)\n7 +    File.read(path)\n8 +  end\n9 +\n10 +  def process_user_input(input)\n11 +    input.downcase.strip\n12 +  end\n13 +\n14 +  def extract_characters(text, count)\n15 +    text[0, count]\n16 +  end\n17 +\n18 +  def count_characters(text)\n19 +    text.length\n20 +  end\n21 +\n22 +  def truncate(text, max_length)\n23 +    return text if text.length <= max_length\n24 +    text[0, max_length] + '...'\n25 +  end\n26 +\n27 +  def search_in_file(path, term)\n28 +    content = File.read(path)\n29 +    content.include?(term)\n30 +  end\n31 +\n32 +  def parse_csv_line(line)\n33 +    line.split(',').map(&:strip)\n34 +  end\n35 +\n36 +  def normalize_whitespace(text)\n37 +    text.gsub(/\\s+/, ' ').strip\n38 +  end\n39 +\n40 +  def safe_read(path)\n41 +    File.read(path, encoding: 'UTF-8')\n42 +  end\n43 +\n44 +  def combine_strings(*strings)\n45 +    result = ''\n46 +    strings.each { |s| result += s }\n47 +    result\n48 +  end\n49 +\n50 +  def build_report(items)\n51 +    report = ''\n52 +    items.each_with_index do |item, index|\n53 +      report += \"#{index + 1}. #{item}\\n\"\n54 +    end\n55 +    report\n56 +  end\n57 +end\n58 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/text_processor.rb\",\"relevantLinesStart\":6,\"relevantLinesEnd\":8},{\"relevantFile\":\"app/services/text_processor.rb\",\"relevantLinesStart\":14,\"relevantLinesEnd\":16},{\"relevantFile\":\"app/services/text_processor.rb\",\"relevantLinesStart\":35,\"relevantLinesEnd\":39}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def read_file(path)\\n    File.read(path)\\n  end\",\n    \"improvedCode\": \"def read_file(path)\\n    File.read(path, encoding: 'UTF-8')\\n  end\",\n    \"relevantFile\": \"app/services/text_processor.rb\",\n    \"relevantLinesEnd\": 8,\n    \"suggestionContent\": \"The `read_file` method uses `File.read` without specifying encoding. If the file contains UTF-8 characters but the system default is ASCII-8BIT, string operations will fail with `Encoding::CompatibilityError`. Always specify encoding explicitly.\",\n    \"oneSentenceSummary\": \"File.read without encoding causes encoding errors on non-ASCII content\",\n    \"relevantLinesStart\": 6\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def extract_characters(text, count)\\n    text[0, count]\\n  end\",\n    \"improvedCode\": \"def extract_characters(text, count)\\n    text.chars.first(count).join\\n  end\",\n    \"relevantFile\": \"app/services/text_processor.rb\",\n    \"relevantLinesEnd\": 16,\n    \"suggestionContent\": \"The `extract_characters` and `truncate` methods use `String#length` and `String#[]` which count bytes, not characters in some Ruby versions and encodings. For multi-byte UTF-8 characters like emojis, this can split a character mid-byte, corrupting the string. Use `String#chars` for character-safe operations.\",\n    \"oneSentenceSummary\": \"String slicing may split multi-byte UTF-8 characters\",\n    \"relevantLinesStart\": 14\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def combine_strings(*strings)\\n    result = ''\\n    strings.each { |s| result += s }\\n    result\\n  end\",\n    \"improvedCode\": \"def combine_strings(*strings)\\n    result = ''\\n    strings.each { |s| result << s }\\n    result\\n  end\",\n    \"relevantFile\": \"app/services/text_processor.rb\",\n    \"relevantLinesEnd\": 39,\n    \"suggestionContent\": \"The `combine_strings` and `build_report` methods use `+=` for string concatenation in a loop. In Ruby, strings are mutable but `+=` creates a new string each time, causing O(nÂ²) performance. Use `<<` or `String#concat` for efficient appending.\",\n    \"oneSentenceSummary\": \"String += in loop creates O(nÂ²) performance - use << instead\",\n    \"relevantLinesStart\": 35\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 70: app/services/base_handler.rb",
    "vars": {
      "fileContent": "class BaseHandler\n  def initialize(config)\n    @config = config\n    @logger = Rails.logger\n  end\n\n  def handle(request)\n    validate(request)\n    process(request)\n    log_completion(request)\n  end\n\n  def validate(request)\n    raise 'Invalid request' if request.nil?\n  end\n\n  def process(request)\n    raise NotImplementedError, 'Subclass must implement'\n  end\n\n  private\n\n  def log_completion(request)\n    @logger.info(\"Handled request: #{request[:id]}\")\n  end\n\n  def internal_helper\n    # Some helper logic\n  end\nend\n\nclass OrderHandler < BaseHandler\n  def initialize(config, payment_gateway)\n    @payment_gateway = payment_gateway\n    super(config)\n  end\n\n  def handle(request)\n    pre_process(request)\n    result = process(request)\n    post_process(result)\n  end\n\n  def process(request)\n    @payment_gateway.charge(request[:amount])\n  end\n\n  def validate(request)\n    raise 'Amount required' unless request[:amount]\n  end\n\n  private\n\n  def pre_process(request)\n    @logger.info(\"Starting order: #{request[:id]}\")\n  end\n\n  def post_process(result)\n    log_completion(result)\n  end\nend\n\nclass RefundHandler < BaseHandler\n  def process(request)\n    @payment_gateway.refund(request[:transaction_id], request[:amount])\n  end\n\n  def validate(request)\n    super\n    raise 'Transaction ID required' unless request[:transaction_id]\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/base_handler.rb'\n\n@@ -0,0 +1,73 @@\n__new hunk__\n1 +class BaseHandler\n2 +  def initialize(config)\n3 +    @config = config\n4 +    @logger = Rails.logger\n5 +  end\n6 +\n7 +  def handle(request)\n8 +    validate(request)\n9 +    process(request)\n10 +    log_completion(request)\n11 +  end\n12 +\n13 +  def validate(request)\n14 +    raise 'Invalid request' if request.nil?\n15 +  end\n16 +\n17 +  def process(request)\n18 +    raise NotImplementedError, 'Subclass must implement'\n19 +  end\n20 +\n21 +  private\n22 +\n23 +  def log_completion(request)\n24 +    @logger.info(\"Handled request: #{request[:id]}\")\n25 +  end\n26 +\n27 +  def internal_helper\n28 +    # Some helper logic\n29 +  end\n30 +end\n31 +\n32 +class OrderHandler < BaseHandler\n33 +  def initialize(config, payment_gateway)\n34 +    @payment_gateway = payment_gateway\n35 +    super(config)\n36 +  end\n37 +\n38 +  def handle(request)\n39 +    pre_process(request)\n40 +    result = process(request)\n41 +    post_process(result)\n42 +  end\n43 +\n44 +  def process(request)\n45 +    @payment_gateway.charge(request[:amount])\n46 +  end\n47 +\n48 +  def validate(request)\n49 +    raise 'Amount required' unless request[:amount]\n50 +  end\n51 +\n52 +  private\n53 +\n54 +  def pre_process(request)\n55 +    @logger.info(\"Starting order: #{request[:id]}\")\n56 +  end\n57 +\n58 +  def post_process(result)\n59 +    log_completion(result)\n60 +  end\n61 +end\n62 +\n63 +class RefundHandler < BaseHandler\n64 +  def process(request)\n65 +    @payment_gateway.refund(request[:transaction_id], request[:amount])\n66 +  end\n67 +\n68 +  def validate(request)\n69 +    super\n70 +    raise 'Transaction ID required' unless request[:transaction_id]\n71 +  end\n72 +end\n73 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/base_handler.rb\",\"relevantLinesStart\":37,\"relevantLinesEnd\":41},{\"relevantFile\":\"app/services/base_handler.rb\",\"relevantLinesStart\":47,\"relevantLinesEnd\":49},{\"relevantFile\":\"app/services/base_handler.rb\",\"relevantLinesStart\":61,\"relevantLinesEnd\":64}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def handle(request)\\n    pre_process(request)\\n    result = process(request)\\n    post_process(result)\\n  end\",\n    \"improvedCode\": \"def handle(request)\\n    validate(request)\\n    pre_process(request)\\n    result = process(request)\\n    post_process(result)\\n  end\",\n    \"relevantFile\": \"app/services/base_handler.rb\",\n    \"relevantLinesEnd\": 41,\n    \"suggestionContent\": \"The `OrderHandler#handle` method overrides `BaseHandler#handle` but doesn't call `super` or the parent's `validate` method. This skips the nil check from `BaseHandler#validate`, allowing invalid requests through. The parent's `log_completion` is also skipped.\",\n    \"oneSentenceSummary\": \"Overridden handle skips parent validation - allows nil requests\",\n    \"relevantLinesStart\": 37\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def validate(request)\\n    raise 'Amount required' unless request[:amount]\\n  end\",\n    \"improvedCode\": \"def validate(request)\\n    super\\n    raise 'Amount required' unless request[:amount]\\n  end\",\n    \"relevantFile\": \"app/services/base_handler.rb\",\n    \"relevantLinesEnd\": 49,\n    \"suggestionContent\": \"The `OrderHandler#validate` method overrides `BaseHandler#validate` without calling `super`. This loses the nil check from the parent class. Compare with `RefundHandler#validate` which correctly calls `super` first.\",\n    \"oneSentenceSummary\": \"Override without super skips parent validation logic\",\n    \"relevantLinesStart\": 47\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"class RefundHandler < BaseHandler\\n  def process(request)\\n    @payment_gateway.refund(request[:transaction_id], request[:amount])\\n  end\",\n    \"improvedCode\": \"class RefundHandler < BaseHandler\\n  def initialize(config, payment_gateway)\\n    super(config)\\n    @payment_gateway = payment_gateway\\n  end\\n\\n  def process(request)\\n    @payment_gateway.refund(request[:transaction_id], request[:amount])\\n  end\",\n    \"relevantFile\": \"app/services/base_handler.rb\",\n    \"relevantLinesEnd\": 64,\n    \"suggestionContent\": \"The `RefundHandler` class references `@payment_gateway` in `process` but never initializes it. The `initialize` method is not overridden, so `@payment_gateway` is `nil`. This will raise `NoMethodError: undefined method 'refund' for nil:NilClass`.\",\n    \"oneSentenceSummary\": \"Uninitialized instance variable @payment_gateway causes NoMethodError\",\n    \"relevantLinesStart\": 61\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 71: app/services/session_store.rb",
    "vars": {
      "fileContent": "require 'base64'\n\nclass SessionStore\n  def initialize(redis_client)\n    @redis = redis_client\n    @namespace = 'sessions'\n  end\n\n  def store(session_id, data)\n    serialized = Marshal.dump(data)\n    encoded = Base64.strict_encode64(serialized)\n    @redis.set(key_for(session_id), encoded)\n  end\n\n  def retrieve(session_id)\n    encoded = @redis.get(key_for(session_id))\n    return nil unless encoded\n\n    serialized = Base64.strict_decode64(encoded)\n    Marshal.load(serialized)\n  end\n\n  def delete(session_id)\n    @redis.del(key_for(session_id))\n  end\n\n  def import_session(encoded_data)\n    serialized = Base64.strict_decode64(encoded_data)\n    Marshal.load(serialized)\n  end\n\n  def restore_from_cookie(cookie_value)\n    return nil if cookie_value.nil? || cookie_value.empty?\n\n    decoded = Base64.strict_decode64(cookie_value)\n    Marshal.load(decoded)\n  end\n\n  def export_session(session_id)\n    encoded = @redis.get(key_for(session_id))\n    encoded\n  end\n\n  private\n\n  def key_for(session_id)\n    \"#{@namespace}:#{session_id}\"\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/session_store.rb'\n\n@@ -0,0 +1,50 @@\n__new hunk__\n1 +require 'base64'\n2 +\n3 +class SessionStore\n4 +  def initialize(redis_client)\n5 +    @redis = redis_client\n6 +    @namespace = 'sessions'\n7 +  end\n8 +\n9 +  def store(session_id, data)\n10 +    serialized = Marshal.dump(data)\n11 +    encoded = Base64.strict_encode64(serialized)\n12 +    @redis.set(key_for(session_id), encoded)\n13 +  end\n14 +\n15 +  def retrieve(session_id)\n16 +    encoded = @redis.get(key_for(session_id))\n17 +    return nil unless encoded\n18 +\n19 +    serialized = Base64.strict_decode64(encoded)\n20 +    Marshal.load(serialized)\n21 +  end\n22 +\n23 +  def delete(session_id)\n24 +    @redis.del(key_for(session_id))\n25 +  end\n26 +\n27 +  def import_session(encoded_data)\n28 +    serialized = Base64.strict_decode64(encoded_data)\n29 +    Marshal.load(serialized)\n30 +  end\n31 +\n32 +  def restore_from_cookie(cookie_value)\n33 +    return nil if cookie_value.nil? || cookie_value.empty?\n34 +\n35 +    decoded = Base64.strict_decode64(cookie_value)\n36 +    Marshal.load(decoded)\n37 +  end\n38 +\n39 +  def export_session(session_id)\n40 +    encoded = @redis.get(key_for(session_id))\n41 +    encoded\n42 +  end\n43 +\n44 +  private\n45 +\n46 +  def key_for(session_id)\n47 +    \"#{@namespace}:#{session_id}\"\n48 +  end\n49 +end\n50 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/session_store.rb\",\"relevantLinesStart\":32,\"relevantLinesEnd\":37}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def restore_from_cookie(cookie_value)\\n    return nil if cookie_value.nil? || cookie_value.empty?\\n\\n    decoded = Base64.strict_decode64(cookie_value)\\n    Marshal.load(decoded)\\n  end\",\n    \"improvedCode\": \"def restore_from_cookie(cookie_value)\\n    return nil if cookie_value.nil? || cookie_value.empty?\\n\\n    decoded = Base64.strict_decode64(cookie_value)\\n    JSON.parse(decoded, symbolize_names: true)\\n  end\",\n    \"relevantFile\": \"app/services/session_store.rb\",\n    \"relevantLinesEnd\": 37,\n    \"suggestionContent\": \"Multiple methods use `Marshal.load` to deserialize data, including data from cookies and external sources (`import_session`, `restore_from_cookie`). Marshal can deserialize arbitrary Ruby objects, allowing remote code execution. An attacker can craft a malicious payload that executes code when deserialized. Use JSON or `MessagePack` for untrusted data.\",\n    \"oneSentenceSummary\": \"Marshal.load on untrusted data allows arbitrary code execution\",\n    \"relevantLinesStart\": 32\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 72: app/validators/input_validator.rb",
    "vars": {
      "fileContent": "class InputValidator\n  EMAIL_REGEX = /^([a-zA-Z0-9_\\-\\.]+)+@(([a-zA-Z0-9\\-])+\\.)+([a-zA-Z]{2,})+$/\n  URL_REGEX = /^(https?:\\/\\/)?([\\w\\-]+\\.)+[\\w\\-]+(\\/[\\w\\-\\.~]*)*\\/?$/\n  SLUG_REGEX = /^[a-z0-9]+(-[a-z0-9]+)*$/\n\n  def validate_email(email)\n    return false if email.nil? || email.empty?\n    email.match?(EMAIL_REGEX)\n  end\n\n  def validate_url(url)\n    return false if url.nil? || url.empty?\n    url.match?(URL_REGEX)\n  end\n\n  def validate_slug(slug)\n    return false if slug.nil? || slug.empty?\n    slug.match?(SLUG_REGEX)\n  end\n\n  def extract_domain(email)\n    match = email.match(/@(.+)$/)\n    match[1] if match\n  end\n\n  def validate_phone(phone)\n    phone =~ /^\\+?[0-9]{10,14}$/\n  end\n\n  def validate_input(input, pattern_string)\n    regex = Regexp.new(pattern_string)\n    input.match?(regex)\n  end\n\n  def sanitize_for_regex(input)\n    input.gsub(/[^a-zA-Z0-9]/, '')\n  end\n\n  def find_matches(text, pattern)\n    regex = /#{pattern}/\n    text.scan(regex)\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/validators/input_validator.rb'\n\n@@ -0,0 +1,44 @@\n__new hunk__\n1 +class InputValidator\n2 +  EMAIL_REGEX = /^([a-zA-Z0-9_\\-\\.]+)+@(([a-zA-Z0-9\\-])+\\.)+([a-zA-Z]{2,})+$/\n3 +  URL_REGEX = /^(https?:\\/\\/)?([\\w\\-]+\\.)+[\\w\\-]+(\\/[\\w\\-\\.~]*)*\\/?$/\n4 +  SLUG_REGEX = /^[a-z0-9]+(-[a-z0-9]+)*$/\n5 +\n6 +  def validate_email(email)\n7 +    return false if email.nil? || email.empty?\n8 +    email.match?(EMAIL_REGEX)\n9 +  end\n10 +\n11 +  def validate_url(url)\n12 +    return false if url.nil? || url.empty?\n13 +    url.match?(URL_REGEX)\n14 +  end\n15 +\n16 +  def validate_slug(slug)\n17 +    return false if slug.nil? || slug.empty?\n18 +    slug.match?(SLUG_REGEX)\n19 +  end\n20 +\n21 +  def extract_domain(email)\n22 +    match = email.match(/@(.+)$/)\n23 +    match[1] if match\n24 +  end\n25 +\n26 +  def validate_phone(phone)\n27 +    phone =~ /^\\+?[0-9]{10,14}$/\n28 +  end\n29 +\n30 +  def validate_input(input, pattern_string)\n31 +    regex = Regexp.new(pattern_string)\n32 +    input.match?(regex)\n33 +  end\n34 +\n35 +  def sanitize_for_regex(input)\n36 +    input.gsub(/[^a-zA-Z0-9]/, '')\n37 +  end\n38 +\n39 +  def find_matches(text, pattern)\n40 +    regex = /#{pattern}/\n41 +    text.scan(regex)\n42 +  end\n43 +end\n44 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/validators/input_validator.rb\",\"relevantLinesStart\":2,\"relevantLinesEnd\":2},{\"relevantFile\":\"app/validators/input_validator.rb\",\"relevantLinesStart\":40,\"relevantLinesEnd\":43}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"EMAIL_REGEX = /^([a-zA-Z0-9_\\\\\\\\-\\\\\\\\.]+)+@(([a-zA-Z0-9\\\\\\\\-])+\\\\\\\\.)+([a-zA-Z]{2,})+$/\",\n    \"improvedCode\": \"EMAIL_REGEX = /^[a-zA-Z0-9_\\\\\\\\-\\\\\\\\.]+@[a-zA-Z0-9\\\\\\\\-]+(\\\\\\\\.[a-zA-Z0-9\\\\\\\\-]+)*\\\\\\\\.[a-zA-Z]{2,}$/\",\n    \"relevantFile\": \"app/validators/input_validator.rb\",\n    \"relevantLinesEnd\": 2,\n    \"suggestionContent\": \"The `EMAIL_REGEX` has nested quantifiers `([a-zA-Z0-9_\\\\-\\\\.]+)+` which causes catastrophic backtracking (ReDoS). A malicious input like 'aaaaaaaaaaaaaaaaaaaaa@' can cause the regex engine to hang for minutes, enabling denial-of-service attacks.\",\n    \"oneSentenceSummary\": \"ReDoS vulnerability - nested quantifiers cause exponential backtracking\",\n    \"relevantLinesStart\": 2\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def find_matches(text, pattern)\\n    regex = /\\\\#{pattern}/\\n    text.scan(regex)\\n  end\",\n    \"improvedCode\": \"def find_matches(text, pattern)\\n    regex = /\\\\#{Regexp.escape(pattern)}/\\n    text.scan(regex)\\n  end\",\n    \"relevantFile\": \"app/validators/input_validator.rb\",\n    \"relevantLinesEnd\": 43,\n    \"suggestionContent\": \"The `find_matches` method interpolates user input directly into a regex pattern. An attacker can inject regex metacharacters or cause ReDoS with patterns like `(a+)+$`. Use `Regexp.escape` to sanitize the input.\",\n    \"oneSentenceSummary\": \"Regex injection via unescaped user input enables ReDoS attacks\",\n    \"relevantLinesStart\": 40\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 73: app/services/report_generator.rb",
    "vars": {
      "fileContent": "class ReportGenerator\n  def generate_user_report\n    users = User.all\n    users.map do |user|\n      {\n        name: user.name,\n        email: user.email,\n        orders_count: user.orders.count,\n        total_spent: user.orders.sum(:total),\n        last_order: user.orders.last&.created_at\n      }\n    end\n  end\n\n  def generate_order_report\n    orders = Order.where(status: 'completed')\n    orders.map do |order|\n      {\n        id: order.id,\n        user_name: order.user.name,\n        user_email: order.user.email,\n        items: order.line_items.map { |li| li.product.name },\n        total: order.total\n      }\n    end\n  end\n\n  def list_posts_with_comments\n    posts = Post.recent\n    posts.map do |post|\n      {\n        title: post.title,\n        author: post.author.name,\n        comments_count: post.comments.count,\n        recent_comments: post.comments.limit(5).map do |comment|\n          { body: comment.body, author: comment.user.name }\n        end\n      }\n    end\n  end\n\n  def calculate_department_stats\n    departments = Department.all\n    departments.map do |dept|\n      employees = dept.employees\n      {\n        name: dept.name,\n        employee_count: employees.count,\n        total_salary: employees.sum(:salary),\n        avg_tenure: employees.average(:years_employed),\n        managers: employees.where(role: 'manager').pluck(:name)\n      }\n    end\n  end\n\n  def efficient_user_report\n    users = User.includes(:orders).all\n    users.map do |user|\n      {\n        name: user.name,\n        orders_count: user.orders.size\n      }\n    end\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/report_generator.rb'\n\n@@ -0,0 +1,66 @@\n__new hunk__\n1 +class ReportGenerator\n2 +  def generate_user_report\n3 +    users = User.all\n4 +    users.map do |user|\n5 +      {\n6 +        name: user.name,\n7 +        email: user.email,\n8 +        orders_count: user.orders.count,\n9 +        total_spent: user.orders.sum(:total),\n10 +        last_order: user.orders.last&.created_at\n11 +      }\n12 +    end\n13 +  end\n14 +\n15 +  def generate_order_report\n16 +    orders = Order.where(status: 'completed')\n17 +    orders.map do |order|\n18 +      {\n19 +        id: order.id,\n20 +        user_name: order.user.name,\n21 +        user_email: order.user.email,\n22 +        items: order.line_items.map { |li| li.product.name },\n23 +        total: order.total\n24 +      }\n25 +    end\n26 +  end\n27 +\n28 +  def list_posts_with_comments\n29 +    posts = Post.recent\n30 +    posts.map do |post|\n31 +      {\n32 +        title: post.title,\n33 +        author: post.author.name,\n34 +        comments_count: post.comments.count,\n35 +        recent_comments: post.comments.limit(5).map do |comment|\n36 +          { body: comment.body, author: comment.user.name }\n37 +        end\n38 +      }\n39 +    end\n40 +  end\n41 +\n42 +  def calculate_department_stats\n43 +    departments = Department.all\n44 +    departments.map do |dept|\n45 +      employees = dept.employees\n46 +      {\n47 +        name: dept.name,\n48 +        employee_count: employees.count,\n49 +        total_salary: employees.sum(:salary),\n50 +        avg_tenure: employees.average(:years_employed),\n51 +        managers: employees.where(role: 'manager').pluck(:name)\n52 +      }\n53 +    end\n54 +  end\n55 +\n56 +  def efficient_user_report\n57 +    users = User.includes(:orders).all\n58 +    users.map do |user|\n59 +      {\n60 +        name: user.name,\n61 +        orders_count: user.orders.size\n62 +      }\n63 +    end\n64 +  end\n65 +end\n66 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/report_generator.rb\",\"relevantLinesStart\":3,\"relevantLinesEnd\":8},{\"relevantFile\":\"app/services/report_generator.rb\",\"relevantLinesStart\":15,\"relevantLinesEnd\":21}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"users = User.all\\n    users.map do |user|\\n      {\\n        name: user.name,\\n        email: user.email,\\n        orders_count: user.orders.count,\",\n    \"improvedCode\": \"users = User.left_joins(:orders)\\n              .select('users.*, COUNT(orders.id) as orders_count, SUM(orders.total) as total_spent')\\n              .group('users.id')\\n    users.map do |user|\\n      {\\n        name: user.name,\\n        email: user.email,\\n        orders_count: user.orders_count,\",\n    \"relevantFile\": \"app/services/report_generator.rb\",\n    \"relevantLinesEnd\": 8,\n    \"suggestionContent\": \"The `generate_user_report` method has an N+1 query problem. For each user, it makes 3 separate queries: `orders.count`, `orders.sum`, and `orders.last`. With 100 users, this results in 301 queries instead of 2. Use `includes` or aggregate in a single query.\",\n    \"oneSentenceSummary\": \"N+1 query - 3 queries per user for orders data\",\n    \"relevantLinesStart\": 3\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"orders = Order.where(status: 'completed')\\n    orders.map do |order|\\n      {\\n        id: order.id,\\n        user_name: order.user.name,\\n        user_email: order.user.email,\\n        items: order.line_items.map { |li| li.product.name },\",\n    \"improvedCode\": \"orders = Order.where(status: 'completed')\\n              .includes(:user, line_items: :product)\\n    orders.map do |order|\\n      {\\n        id: order.id,\\n        user_name: order.user.name,\\n        user_email: order.user.email,\\n        items: order.line_items.map { |li| li.product.name },\",\n    \"relevantFile\": \"app/services/report_generator.rb\",\n    \"relevantLinesEnd\": 21,\n    \"suggestionContent\": \"The `generate_order_report` method has multiple N+1 issues: `order.user` (N queries), `order.line_items` (N queries), and `li.product` (N*M queries for each line item). This can result in thousands of queries for a moderate dataset.\",\n    \"oneSentenceSummary\": \"Triple N+1 query - user, line_items, and products all queried separately\",\n    \"relevantLinesStart\": 15\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 74: app/controllers/downloads_controller.rb",
    "vars": {
      "fileContent": "class DownloadsController < ApplicationController\n  DOWNLOADS_DIR = Rails.root.join('public', 'downloads')\n\n  def show\n    filename = params[:filename]\n    filepath = File.join(DOWNLOADS_DIR, filename)\n\n    if File.exist?(filepath)\n      send_file filepath, disposition: 'attachment'\n    else\n      render plain: 'File not found', status: :not_found\n    end\n  end\n\n  def preview\n    filename = params[:filename]\n    filepath = \"#{DOWNLOADS_DIR}/#{filename}\"\n\n    render plain: File.read(filepath)\n  end\n\n  def delete\n    filename = params[:filename]\n    filepath = File.join(DOWNLOADS_DIR, filename)\n\n    File.delete(filepath) if File.exist?(filepath)\n    redirect_to downloads_path, notice: 'File deleted'\n  end\n\n  def upload\n    uploaded_file = params[:file]\n    filename = params[:filename] || uploaded_file.original_filename\n    filepath = File.join(DOWNLOADS_DIR, filename)\n\n    File.open(filepath, 'wb') do |file|\n      file.write(uploaded_file.read)\n    end\n\n    redirect_to downloads_path, notice: 'File uploaded'\n  end\n\n  def list\n    @files = Dir.glob(File.join(DOWNLOADS_DIR, '*')).map do |f|\n      File.basename(f)\n    end\n  end\n\n  def safe_download\n    filename = File.basename(params[:filename])\n    filepath = DOWNLOADS_DIR.join(filename)\n\n    if filepath.to_s.start_with?(DOWNLOADS_DIR.to_s) && File.exist?(filepath)\n      send_file filepath\n    else\n      head :not_found\n    end\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/controllers/downloads_controller.rb'\n\n@@ -0,0 +1,59 @@\n__new hunk__\n1 +class DownloadsController < ApplicationController\n2 +  DOWNLOADS_DIR = Rails.root.join('public', 'downloads')\n3 +\n4 +  def show\n5 +    filename = params[:filename]\n6 +    filepath = File.join(DOWNLOADS_DIR, filename)\n7 +\n8 +    if File.exist?(filepath)\n9 +      send_file filepath, disposition: 'attachment'\n10 +    else\n11 +      render plain: 'File not found', status: :not_found\n12 +    end\n13 +  end\n14 +\n15 +  def preview\n16 +    filename = params[:filename]\n17 +    filepath = \"#{DOWNLOADS_DIR}/#{filename}\"\n18 +\n19 +    render plain: File.read(filepath)\n20 +  end\n21 +\n22 +  def delete\n23 +    filename = params[:filename]\n24 +    filepath = File.join(DOWNLOADS_DIR, filename)\n25 +\n26 +    File.delete(filepath) if File.exist?(filepath)\n27 +    redirect_to downloads_path, notice: 'File deleted'\n28 +  end\n29 +\n30 +  def upload\n31 +    uploaded_file = params[:file]\n32 +    filename = params[:filename] || uploaded_file.original_filename\n33 +    filepath = File.join(DOWNLOADS_DIR, filename)\n34 +\n35 +    File.open(filepath, 'wb') do |file|\n36 +      file.write(uploaded_file.read)\n37 +    end\n38 +\n39 +    redirect_to downloads_path, notice: 'File uploaded'\n40 +  end\n41 +\n42 +  def list\n43 +    @files = Dir.glob(File.join(DOWNLOADS_DIR, '*')).map do |f|\n44 +      File.basename(f)\n45 +    end\n46 +  end\n47 +\n48 +  def safe_download\n49 +    filename = File.basename(params[:filename])\n50 +    filepath = DOWNLOADS_DIR.join(filename)\n51 +\n52 +    if filepath.to_s.start_with?(DOWNLOADS_DIR.to_s) && File.exist?(filepath)\n53 +      send_file filepath\n54 +    else\n55 +      head :not_found\n56 +    end\n57 +  end\n58 +end\n59 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/controllers/downloads_controller.rb\",\"relevantLinesStart\":5,\"relevantLinesEnd\":9},{\"relevantFile\":\"app/controllers/downloads_controller.rb\",\"relevantLinesStart\":23,\"relevantLinesEnd\":25}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"filename = params[:filename]\\n    filepath = File.join(DOWNLOADS_DIR, filename)\\n\\n    if File.exist?(filepath)\\n      send_file filepath\",\n    \"improvedCode\": \"filename = params[:filename]\\n    filepath = File.expand_path(File.join(DOWNLOADS_DIR, filename))\\n\\n    unless filepath.start_with?(DOWNLOADS_DIR.to_s)\\n      return head :forbidden\\n    end\\n\\n    if File.exist?(filepath)\\n      send_file filepath\",\n    \"relevantFile\": \"app/controllers/downloads_controller.rb\",\n    \"relevantLinesEnd\": 9,\n    \"suggestionContent\": \"The `show` method is vulnerable to path traversal. An attacker can request `filename=../../../etc/passwd` to read any file on the system. `File.join` doesn't sanitize `..` sequences. Validate that the resolved path is within the allowed directory.\",\n    \"oneSentenceSummary\": \"Path traversal allows reading arbitrary system files\",\n    \"relevantLinesStart\": 5\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"filepath = File.join(DOWNLOADS_DIR, filename)\\n\\n    File.delete(filepath) if File.exist?(filepath)\",\n    \"improvedCode\": \"filepath = File.expand_path(File.join(DOWNLOADS_DIR, filename))\\n    return head :forbidden unless filepath.start_with?(DOWNLOADS_DIR.to_s)\\n\\n    File.delete(filepath) if File.exist?(filepath)\",\n    \"relevantFile\": \"app/controllers/downloads_controller.rb\",\n    \"relevantLinesEnd\": 25,\n    \"suggestionContent\": \"The `delete` method has the same path traversal vulnerability, allowing deletion of arbitrary files. An attacker can delete critical system or application files.\",\n    \"oneSentenceSummary\": \"Path traversal allows deleting arbitrary system files\",\n    \"relevantLinesStart\": 23\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 75: app/repositories/user_repository.rb",
    "vars": {
      "fileContent": "class UserRepository\n  def initialize(connection)\n    @connection = connection\n  end\n\n  def find_by_id(id)\n    result = @connection.execute(\"SELECT * FROM users WHERE id = $1\", [id])\n    result.first\n  end\n\n  def find_by_email(email)\n    query = \"SELECT * FROM users WHERE email = '#{email}'\"\n    result = @connection.execute(query)\n    result.first\n  end\n\n  def find_by_username(username)\n    query = \"SELECT * FROM users WHERE username = '#{username}'\"\n    result = @connection.execute(query)\n    result.first\n  end\n\n  def search_users(term, sort_by: 'created_at')\n    query = \"SELECT * FROM users WHERE name LIKE '%#{term}%' ORDER BY #{sort_by}\"\n    @connection.execute(query)\n  end\n\n  def authenticate(username, password)\n    query = \"SELECT * FROM users WHERE username = '#{username}' AND password_hash = '#{password}'\"\n    result = @connection.execute(query)\n    result.first\n  end\n\n  def delete_by_status(status)\n    query = \"DELETE FROM users WHERE status = '#{status}'\"\n    @connection.execute(query)\n  end\n\n  def update_role(user_id, role)\n    @connection.execute(\n      \"UPDATE users SET role = $1 WHERE id = $2\",\n      [role, user_id]\n    )\n  end\n\n  def count_by_role(role)\n    result = @connection.execute(\n      \"SELECT COUNT(*) FROM users WHERE role = $1\",\n      [role]\n    )\n    result.first['count'].to_i\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/repositories/user_repository.rb'\n\n@@ -0,0 +1,54 @@\n__new hunk__\n1 +class UserRepository\n2 +  def initialize(connection)\n3 +    @connection = connection\n4 +  end\n5 +\n6 +  def find_by_id(id)\n7 +    result = @connection.execute(\"SELECT * FROM users WHERE id = $1\", [id])\n8 +    result.first\n9 +  end\n10 +\n11 +  def find_by_email(email)\n12 +    query = \"SELECT * FROM users WHERE email = '#{email}'\"\n13 +    result = @connection.execute(query)\n14 +    result.first\n15 +  end\n16 +\n17 +  def find_by_username(username)\n18 +    query = \"SELECT * FROM users WHERE username = '#{username}'\"\n19 +    result = @connection.execute(query)\n20 +    result.first\n21 +  end\n22 +\n23 +  def search_users(term, sort_by: 'created_at')\n24 +    query = \"SELECT * FROM users WHERE name LIKE '%#{term}%' ORDER BY #{sort_by}\"\n25 +    @connection.execute(query)\n26 +  end\n27 +\n28 +  def authenticate(username, password)\n29 +    query = \"SELECT * FROM users WHERE username = '#{username}' AND password_hash = '#{password}'\"\n30 +    result = @connection.execute(query)\n31 +    result.first\n32 +  end\n33 +\n34 +  def delete_by_status(status)\n35 +    query = \"DELETE FROM users WHERE status = '#{status}'\"\n36 +    @connection.execute(query)\n37 +  end\n38 +\n39 +  def update_role(user_id, role)\n40 +    @connection.execute(\n41 +      \"UPDATE users SET role = $1 WHERE id = $2\",\n42 +      [role, user_id]\n43 +    )\n44 +  end\n45 +\n46 +  def count_by_role(role)\n47 +    result = @connection.execute(\n48 +      \"SELECT COUNT(*) FROM users WHERE role = $1\",\n49 +      [role]\n50 +    )\n51 +    result.first['count'].to_i\n52 +  end\n53 +end\n54 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/repositories/user_repository.rb\",\"relevantLinesStart\":12,\"relevantLinesEnd\":12},{\"relevantFile\":\"app/repositories/user_repository.rb\",\"relevantLinesStart\":24,\"relevantLinesEnd\":24},{\"relevantFile\":\"app/repositories/user_repository.rb\",\"relevantLinesStart\":28,\"relevantLinesEnd\":28}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"query = \\\"SELECT * FROM users WHERE email = '\\\\#{email}'\\\"\",\n    \"improvedCode\": \"result = @connection.execute(\\\"SELECT * FROM users WHERE email = $1\\\", [email])\",\n    \"relevantFile\": \"app/repositories/user_repository.rb\",\n    \"relevantLinesEnd\": 12,\n    \"suggestionContent\": \"The `find_by_email` method uses string interpolation to build SQL query. An attacker can input `' OR '1'='1` to retrieve all users or `'; DROP TABLE users; --` to delete data. Use parameterized queries with placeholders.\",\n    \"oneSentenceSummary\": \"SQL injection via string interpolation in email lookup\",\n    \"relevantLinesStart\": 12\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"query = \\\"SELECT * FROM users WHERE name LIKE '%\\\\#{term}%' ORDER BY \\\\#{sort_by}\\\"\",\n    \"improvedCode\": \"allowed_sorts = %w[created_at name email]\\nraise ArgumentError unless allowed_sorts.include?(sort_by)\\nquery = \\\"SELECT * FROM users WHERE name LIKE $1 ORDER BY \\\\#{sort_by}\\\"\\n@connection.execute(query, [\\\"%\\\\#{term}%\\\"])\",\n    \"relevantFile\": \"app/repositories/user_repository.rb\",\n    \"relevantLinesEnd\": 24,\n    \"suggestionContent\": \"The `search_users` method has two SQL injection vulnerabilities: `term` and `sort_by` are both interpolated. The `sort_by` parameter is particularly dangerous as ORDER BY cannot be parameterized and needs allowlist validation.\",\n    \"oneSentenceSummary\": \"SQL injection in search - both term and sort_by are injectable\",\n    \"relevantLinesStart\": 24\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"query = \\\"SELECT * FROM users WHERE username = '\\\\#{username}' AND password_hash = '\\\\#{password}'\\\"\",\n    \"improvedCode\": \"result = @connection.execute(\\n  \\\"SELECT * FROM users WHERE username = $1 AND password_hash = $2\\\",\\n  [username, password]\\n)\",\n    \"relevantFile\": \"app/repositories/user_repository.rb\",\n    \"relevantLinesEnd\": 28,\n    \"suggestionContent\": \"The `authenticate` method interpolates both username and password into SQL, enabling authentication bypass. An attacker can login as any user with `admin' --` as username.\",\n    \"oneSentenceSummary\": \"SQL injection in authentication allows login bypass\",\n    \"relevantLinesStart\": 28\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 76: app/services/scheduler_service.rb",
    "vars": {
      "fileContent": "class SchedulerService\n  def initialize\n    @scheduled_tasks = []\n  end\n\n  def schedule_at(task, datetime_string)\n    scheduled_time = Time.parse(datetime_string)\n    @scheduled_tasks << { task: task, time: scheduled_time }\n  end\n\n  def schedule_for_tomorrow(task)\n    tomorrow = Date.today + 1\n    scheduled_time = Time.new(tomorrow.year, tomorrow.month, tomorrow.day, 9, 0, 0)\n    @scheduled_tasks << { task: task, time: scheduled_time }\n  end\n\n  def is_past_due?(scheduled_time)\n    scheduled_time < Time.now\n  end\n\n  def tasks_for_today\n    today = Date.today\n    @scheduled_tasks.select do |task|\n      task[:time].to_date == today\n    end\n  end\n\n  def calculate_duration(start_time, end_time)\n    (end_time - start_time) / 3600.0 # hours\n  end\n\n  def next_weekday(from_date = Date.today)\n    date = from_date + 1\n    date += 1 while date.saturday? || date.sunday?\n    date\n  end\n\n  def format_time(time)\n    time.strftime('%Y-%m-%d %H:%M:%S')\n  end\n\n  def parse_user_time(time_string, user_timezone)\n    Time.parse(time_string)\n  end\n\n  def utc_to_local(utc_time, timezone)\n    utc_time + timezone_offset(timezone)\n  end\n\n  private\n\n  def timezone_offset(timezone)\n    # Simplified offset calculation\n    offsets = { 'EST' => -5, 'PST' => -8, 'UTC' => 0 }\n    (offsets[timezone] || 0) * 3600\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/scheduler_service.rb'\n\n@@ -0,0 +1,58 @@\n__new hunk__\n1 +class SchedulerService\n2 +  def initialize\n3 +    @scheduled_tasks = []\n4 +  end\n5 +\n6 +  def schedule_at(task, datetime_string)\n7 +    scheduled_time = Time.parse(datetime_string)\n8 +    @scheduled_tasks << { task: task, time: scheduled_time }\n9 +  end\n10 +\n11 +  def schedule_for_tomorrow(task)\n12 +    tomorrow = Date.today + 1\n13 +    scheduled_time = Time.new(tomorrow.year, tomorrow.month, tomorrow.day, 9, 0, 0)\n14 +    @scheduled_tasks << { task: task, time: scheduled_time }\n15 +  end\n16 +\n17 +  def is_past_due?(scheduled_time)\n18 +    scheduled_time < Time.now\n19 +  end\n20 +\n21 +  def tasks_for_today\n22 +    today = Date.today\n23 +    @scheduled_tasks.select do |task|\n24 +      task[:time].to_date == today\n25 +    end\n26 +  end\n27 +\n28 +  def calculate_duration(start_time, end_time)\n29 +    (end_time - start_time) / 3600.0 # hours\n30 +  end\n31 +\n32 +  def next_weekday(from_date = Date.today)\n33 +    date = from_date + 1\n34 +    date += 1 while date.saturday? || date.sunday?\n35 +    date\n36 +  end\n37 +\n38 +  def format_time(time)\n39 +    time.strftime('%Y-%m-%d %H:%M:%S')\n40 +  end\n41 +\n42 +  def parse_user_time(time_string, user_timezone)\n43 +    Time.parse(time_string)\n44 +  end\n45 +\n46 +  def utc_to_local(utc_time, timezone)\n47 +    utc_time + timezone_offset(timezone)\n48 +  end\n49 +\n50 +  private\n51 +\n52 +  def timezone_offset(timezone)\n53 +    # Simplified offset calculation\n54 +    offsets = { 'EST' => -5, 'PST' => -8, 'UTC' => 0 }\n55 +    (offsets[timezone] || 0) * 3600\n56 +  end\n57 +end\n58 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/scheduler_service.rb\",\"relevantLinesStart\":7,\"relevantLinesEnd\":7},{\"relevantFile\":\"app/services/scheduler_service.rb\",\"relevantLinesStart\":16,\"relevantLinesEnd\":18},{\"relevantFile\":\"app/services/scheduler_service.rb\",\"relevantLinesStart\":40,\"relevantLinesEnd\":42}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"scheduled_time = Time.parse(datetime_string)\",\n    \"improvedCode\": \"scheduled_time = Time.zone.parse(datetime_string)\",\n    \"relevantFile\": \"app/services/scheduler_service.rb\",\n    \"relevantLinesEnd\": 7,\n    \"suggestionContent\": \"The `schedule_at` method uses `Time.parse` which parses in the local timezone without explicit zone handling. If the server timezone differs from user timezone, tasks will be scheduled at wrong times. Use `Time.zone.parse` in Rails or explicitly handle timezones.\",\n    \"oneSentenceSummary\": \"Time.parse ignores timezone - schedules tasks at wrong times\",\n    \"relevantLinesStart\": 7\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def is_past_due?(scheduled_time)\\n    scheduled_time < Time.now\\n  end\",\n    \"improvedCode\": \"def is_past_due?(scheduled_time)\\n    scheduled_time < Time.current  # Rails timezone-aware\\n  end\",\n    \"relevantFile\": \"app/services/scheduler_service.rb\",\n    \"relevantLinesEnd\": 18,\n    \"suggestionContent\": \"The `is_past_due?` method compares times but mixes `Time.now` (local time) with potentially UTC times. If `scheduled_time` is in UTC and `Time.now` is in local time, comparisons will be incorrect by the timezone offset.\",\n    \"oneSentenceSummary\": \"Comparing times without timezone awareness gives wrong results\",\n    \"relevantLinesStart\": 16\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def parse_user_time(time_string, user_timezone)\\n    Time.parse(time_string)\\n  end\",\n    \"improvedCode\": \"def parse_user_time(time_string, user_timezone)\\n    Time.use_zone(user_timezone) { Time.zone.parse(time_string) }\\n  end\",\n    \"relevantFile\": \"app/services/scheduler_service.rb\",\n    \"relevantLinesEnd\": 42,\n    \"suggestionContent\": \"The `parse_user_time` method ignores the `user_timezone` parameter entirely and parses in local time. User times will be interpreted in server timezone instead of user's timezone.\",\n    \"oneSentenceSummary\": \"User timezone parameter ignored - times parsed in server timezone\",\n    \"relevantLinesStart\": 40\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 77: app/services/payment_processor.rb",
    "vars": {
      "fileContent": "class PaymentProcessor\n  class PaymentError < StandardError; end\n  class InsufficientFundsError < PaymentError; end\n  class InvalidCardError < PaymentError; end\n\n  def initialize(gateway)\n    @gateway = gateway\n    @logger = Rails.logger\n  end\n\n  def process_payment(amount, card_details)\n    validate_card(card_details)\n\n    begin\n      result = @gateway.charge(amount, card_details)\n      @logger.info(\"Payment processed: #{amount}\")\n      result\n    rescue\n      @logger.error(\"Payment failed\")\n      nil\n    end\n  end\n\n  def refund(transaction_id, amount)\n    begin\n      @gateway.refund(transaction_id, amount)\n    rescue => e\n      @logger.error(\"Refund failed: #{e.message}\")\n      raise\n    end\n  end\n\n  def batch_process(payments)\n    results = []\n    payments.each do |payment|\n      begin\n        result = process_payment(payment[:amount], payment[:card])\n        results << { status: 'success', result: result }\n      rescue Exception => e\n        results << { status: 'failed', error: e.message }\n      end\n    end\n    results\n  end\n\n  def validate_card(card_details)\n    raise InvalidCardError, \"Card number required\" if card_details[:number].nil?\n    raise InvalidCardError, \"Invalid card number\" unless valid_card_number?(card_details[:number])\n  end\n\n  def check_balance(account_id)\n    begin\n      @gateway.get_balance(account_id)\n    rescue\n      0\n    end\n  end\n\n  private\n\n  def valid_card_number?(number)\n    number.to_s.length >= 13 && number.to_s.length <= 19\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/payment_processor.rb'\n\n@@ -0,0 +1,65 @@\n__new hunk__\n1 +class PaymentProcessor\n2 +  class PaymentError < StandardError; end\n3 +  class InsufficientFundsError < PaymentError; end\n4 +  class InvalidCardError < PaymentError; end\n5 +\n6 +  def initialize(gateway)\n7 +    @gateway = gateway\n8 +    @logger = Rails.logger\n9 +  end\n10 +\n11 +  def process_payment(amount, card_details)\n12 +    validate_card(card_details)\n13 +\n14 +    begin\n15 +      result = @gateway.charge(amount, card_details)\n16 +      @logger.info(\"Payment processed: #{amount}\")\n17 +      result\n18 +    rescue\n19 +      @logger.error(\"Payment failed\")\n20 +      nil\n21 +    end\n22 +  end\n23 +\n24 +  def refund(transaction_id, amount)\n25 +    begin\n26 +      @gateway.refund(transaction_id, amount)\n27 +    rescue => e\n28 +      @logger.error(\"Refund failed: #{e.message}\")\n29 +      raise\n30 +    end\n31 +  end\n32 +\n33 +  def batch_process(payments)\n34 +    results = []\n35 +    payments.each do |payment|\n36 +      begin\n37 +        result = process_payment(payment[:amount], payment[:card])\n38 +        results << { status: 'success', result: result }\n39 +      rescue Exception => e\n40 +        results << { status: 'failed', error: e.message }\n41 +      end\n42 +    end\n43 +    results\n44 +  end\n45 +\n46 +  def validate_card(card_details)\n47 +    raise InvalidCardError, \"Card number required\" if card_details[:number].nil?\n48 +    raise InvalidCardError, \"Invalid card number\" unless valid_card_number?(card_details[:number])\n49 +  end\n50 +\n51 +  def check_balance(account_id)\n52 +    begin\n53 +      @gateway.get_balance(account_id)\n54 +    rescue\n55 +      0\n56 +    end\n57 +  end\n58 +\n59 +  private\n60 +\n61 +  def valid_card_number?(number)\n62 +    number.to_s.length >= 13 && number.to_s.length <= 19\n63 +  end\n64 +end\n65 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/payment_processor.rb\",\"relevantLinesStart\":18,\"relevantLinesEnd\":20},{\"relevantFile\":\"app/services/payment_processor.rb\",\"relevantLinesStart\":39,\"relevantLinesEnd\":40},{\"relevantFile\":\"app/services/payment_processor.rb\",\"relevantLinesStart\":53,\"relevantLinesEnd\":54}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"rescue\\n      @logger.error(\\\"Payment failed\\\")\\n      nil\",\n    \"improvedCode\": \"rescue PaymentError => e\\n      @logger.error(\\\"Payment failed: \\\\#{e.message}\\\")\\n      raise\",\n    \"relevantFile\": \"app/services/payment_processor.rb\",\n    \"relevantLinesEnd\": 20,\n    \"suggestionContent\": \"The `process_payment` method uses bare `rescue` without specifying an exception type. This catches `StandardError` by default but the intention is unclear, and it silently returns nil, hiding all errors. Always specify the exception type and handle appropriately.\",\n    \"oneSentenceSummary\": \"Bare rescue catches all StandardErrors and silently returns nil\",\n    \"relevantLinesStart\": 18\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"rescue Exception => e\\n        results << { status: 'failed', error: e.message }\",\n    \"improvedCode\": \"rescue StandardError => e\\n        results << { status: 'failed', error: e.message }\",\n    \"relevantFile\": \"app/services/payment_processor.rb\",\n    \"relevantLinesEnd\": 40,\n    \"suggestionContent\": \"The `batch_process` method rescues `Exception` which is too broad - it catches system exceptions like `SignalException`, `NoMemoryError`, and `SystemExit`. This prevents graceful shutdown and can hide critical errors. Rescue `StandardError` instead.\",\n    \"oneSentenceSummary\": \"Rescuing Exception catches system signals and prevents graceful shutdown\",\n    \"relevantLinesStart\": 39\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"rescue\\n      0\",\n    \"improvedCode\": \"rescue StandardError => e\\n      @logger.error(\\\"Balance check failed: \\\\#{e.message}\\\")\\n      raise\",\n    \"relevantFile\": \"app/services/payment_processor.rb\",\n    \"relevantLinesEnd\": 54,\n    \"suggestionContent\": \"The `check_balance` method has bare `rescue` that returns 0 on any error. This silently hides connection errors, authentication failures, and other issues. Returning 0 for a failed balance check could lead to incorrect business decisions.\",\n    \"oneSentenceSummary\": \"Bare rescue returns 0 hiding connection and auth errors\",\n    \"relevantLinesStart\": 53\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 78: app/services/data_pipeline.rb",
    "vars": {
      "fileContent": "class DataPipeline\n  def initialize(data_source)\n    @data_source = data_source\n  end\n\n  def process_records\n    records = @data_source.each\n    processed = records.map { |r| transform(r) }\n    processed.select { |r| r[:valid] }\n  end\n\n  def filter_large_dataset\n    @data_source.lazy.select { |r| r[:active] }\n  end\n\n  def get_first_valid(records)\n    filtered = records.lazy.select { |r| valid?(r) }\n    filtered.first\n  end\n\n  def process_in_batches(records, batch_size: 100)\n    batches = records.each_slice(batch_size)\n\n    batches.map do |batch|\n      process_batch(batch)\n    end\n  end\n\n  def chain_operations(records)\n    result = records.lazy\n      .map { |r| enrich(r) }\n      .select { |r| r[:score] > 50 }\n      .take(10)\n\n    result\n  end\n\n  def count_matches(records)\n    records.lazy\n      .select { |r| r[:type] == 'premium' }\n      .count\n  end\n\n  def to_hash_map(records)\n    records.lazy\n      .map { |r| [r[:id], r] }\n      .to_h\n  end\n\n  def force_evaluation(records)\n    records.lazy\n      .map { |r| expensive_transform(r) }\n      .to_a\n  end\n\n  private\n\n  def transform(record)\n    record.merge(transformed: true, valid: record[:data].present?)\n  end\n\n  def valid?(record)\n    record[:status] == 'active' && record[:data].present?\n  end\n\n  def process_batch(batch)\n    batch.map { |r| transform(r) }\n  end\n\n  def enrich(record)\n    record.merge(score: calculate_score(record))\n  end\n\n  def calculate_score(record)\n    record[:value].to_i * 10\n  end\n\n  def expensive_transform(record)\n    sleep(0.01) # Simulate expensive operation\n    record.merge(processed: true)\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/data_pipeline.rb'\n\n@@ -0,0 +1,83 @@\n__new hunk__\n1 +class DataPipeline\n2 +  def initialize(data_source)\n3 +    @data_source = data_source\n4 +  end\n5 +\n6 +  def process_records\n7 +    records = @data_source.each\n8 +    processed = records.map { |r| transform(r) }\n9 +    processed.select { |r| r[:valid] }\n10 +  end\n11 +\n12 +  def filter_large_dataset\n13 +    @data_source.lazy.select { |r| r[:active] }\n14 +  end\n15 +\n16 +  def get_first_valid(records)\n17 +    filtered = records.lazy.select { |r| valid?(r) }\n18 +    filtered.first\n19 +  end\n20 +\n21 +  def process_in_batches(records, batch_size: 100)\n22 +    batches = records.each_slice(batch_size)\n23 +\n24 +    batches.map do |batch|\n25 +      process_batch(batch)\n26 +    end\n27 +  end\n28 +\n29 +  def chain_operations(records)\n30 +    result = records.lazy\n31 +      .map { |r| enrich(r) }\n32 +      .select { |r| r[:score] > 50 }\n33 +      .take(10)\n34 +\n35 +    result\n36 +  end\n37 +\n38 +  def count_matches(records)\n39 +    records.lazy\n40 +      .select { |r| r[:type] == 'premium' }\n41 +      .count\n42 +  end\n43 +\n44 +  def to_hash_map(records)\n45 +    records.lazy\n46 +      .map { |r| [r[:id], r] }\n47 +      .to_h\n48 +  end\n49 +\n50 +  def force_evaluation(records)\n51 +    records.lazy\n52 +      .map { |r| expensive_transform(r) }\n53 +      .to_a\n54 +  end\n55 +\n56 +  private\n57 +\n58 +  def transform(record)\n59 +    record.merge(transformed: true, valid: record[:data].present?)\n60 +  end\n61 +\n62 +  def valid?(record)\n63 +    record[:status] == 'active' && record[:data].present?\n64 +  end\n65 +\n66 +  def process_batch(batch)\n67 +    batch.map { |r| transform(r) }\n68 +  end\n69 +\n70 +  def enrich(record)\n71 +    record.merge(score: calculate_score(record))\n72 +  end\n73 +\n74 +  def calculate_score(record)\n75 +    record[:value].to_i * 10\n76 +  end\n77 +\n78 +  def expensive_transform(record)\n79 +    sleep(0.01) # Simulate expensive operation\n80 +    record.merge(processed: true)\n81 +  end\n82 +end\n83 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/data_pipeline.rb\",\"relevantLinesStart\":12,\"relevantLinesEnd\":14},{\"relevantFile\":\"app/services/data_pipeline.rb\",\"relevantLinesStart\":28,\"relevantLinesEnd\":34},{\"relevantFile\":\"app/services/data_pipeline.rb\",\"relevantLinesStart\":36,\"relevantLinesEnd\":40}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def filter_large_dataset\\n    @data_source.lazy.select { |r| r[:active] }\\n  end\",\n    \"improvedCode\": \"def filter_large_dataset\\n    @data_source.lazy.select { |r| r[:active] }.to_a\\n  end\\n  # Or document: # @return [Enumerator::Lazy] lazy enumerator, caller must force evaluation\",\n    \"relevantFile\": \"app/services/data_pipeline.rb\",\n    \"relevantLinesEnd\": 14,\n    \"suggestionContent\": \"The `filter_large_dataset` method returns a lazy enumerator without forcing evaluation. The caller receives an unevaluated lazy enumerator, and if `@data_source` is a database cursor or file handle that gets closed, iterating will fail. Either force with `.to_a` or document that it returns a lazy enumerator.\",\n    \"oneSentenceSummary\": \"Lazy enumerator returned without evaluation - data source may close\",\n    \"relevantLinesStart\": 12\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"result = records.lazy\\n      .map { |r| enrich(r) }\\n      .select { |r| r[:score] > 50 }\\n      .take(10)\\n\\n    result\\n  end\",\n    \"improvedCode\": \"result = records.lazy\\n      .map { |r| enrich(r) }\\n      .select { |r| r[:score] > 50 }\\n      .take(10)\\n      .to_a  # Force evaluation\\n\\n    result\\n  end\",\n    \"relevantFile\": \"app/services/data_pipeline.rb\",\n    \"relevantLinesEnd\": 34,\n    \"suggestionContent\": \"The `chain_operations` method returns an unevaluated lazy enumerator. The `take(10)` doesn't force evaluation - it returns another lazy enumerator. If the result is used multiple times, each use re-executes the entire chain from the beginning.\",\n    \"oneSentenceSummary\": \"Lazy chain returns unevaluated - recomputes on each access\",\n    \"relevantLinesStart\": 28\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def count_matches(records)\\n    records.lazy\\n      .select { |r| r[:type] == 'premium' }\\n      .count\\n  end\",\n    \"improvedCode\": \"def count_matches(records)\\n    records.count { |r| r[:type] == 'premium' }\\n  end\",\n    \"relevantFile\": \"app/services/data_pipeline.rb\",\n    \"relevantLinesEnd\": 40,\n    \"suggestionContent\": \"The `count_matches` method calls `.count` on a lazy enumerator. While this works, it forces full iteration and defeats the purpose of lazy evaluation. If the intent was lazy, use `.size` with caution or reconsider the approach. If eager count is intended, don't use `.lazy`.\",\n    \"oneSentenceSummary\": \"Lazy enumeration with count is inefficient - forces full iteration anyway\",\n    \"relevantLinesStart\": 36\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 79: app/services/dynamic_executor.rb",
    "vars": {
      "fileContent": "class DynamicExecutor\n  ALLOWED_METHODS = %w[process transform validate].freeze\n\n  def initialize(context = {})\n    @context = context\n  end\n\n  def execute_expression(expression)\n    eval(expression)\n  end\n\n  def execute_with_binding(expression, local_vars = {})\n    b = binding\n    local_vars.each do |name, value|\n      b.local_variable_set(name, value)\n    end\n    eval(expression, b)\n  end\n\n  def call_method(object, method_name, *args)\n    object.send(method_name, *args)\n  end\n\n  def call_method_safe(object, method_name, *args)\n    if ALLOWED_METHODS.include?(method_name.to_s)\n      object.send(method_name, *args)\n    else\n      raise \"Method not allowed: #{method_name}\"\n    end\n  end\n\n  def process_template(template, data)\n    result = template.dup\n    data.each do |key, value|\n      result.gsub!(\"\\#{#{key} }\", value.to_s)\n    end\n    eval(%Q{\"#{result}\"})\n  end\n\n  def build_query(params)\n    conditions = params.map do |key, value|\n      \"#{key} = '#{value}'\"\n    end\n    conditions.join(' AND ')\n  end\n\n  def instantiate_class(class_name, *args)\n    klass = Object.const_get(class_name)\n    klass.new(*args)\n  end\n\n  def execute_callback(callback_name, *args)\n    method(callback_name).call(*args)\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/dynamic_executor.rb'\n\n@@ -0,0 +1,56 @@\n__new hunk__\n1 +class DynamicExecutor\n2 +  ALLOWED_METHODS = %w[process transform validate].freeze\n3 +\n4 +  def initialize(context = {})\n5 +    @context = context\n6 +  end\n7 +\n8 +  def execute_expression(expression)\n9 +    eval(expression)\n10 +  end\n11 +\n12 +  def execute_with_binding(expression, local_vars = {})\n13 +    b = binding\n14 +    local_vars.each do |name, value|\n15 +      b.local_variable_set(name, value)\n16 +    end\n17 +    eval(expression, b)\n18 +  end\n19 +\n20 +  def call_method(object, method_name, *args)\n21 +    object.send(method_name, *args)\n22 +  end\n23 +\n24 +  def call_method_safe(object, method_name, *args)\n25 +    if ALLOWED_METHODS.include?(method_name.to_s)\n26 +      object.send(method_name, *args)\n27 +    else\n28 +      raise \"Method not allowed: #{method_name}\"\n29 +    end\n30 +  end\n31 +\n32 +  def process_template(template, data)\n33 +    result = template.dup\n34 +    data.each do |key, value|\n35 +      result.gsub!(\"\\#{#{key} }\", value.to_s)\n36 +    end\n37 +    eval(%Q{\"#{result}\"})\n38 +  end\n39 +\n40 +  def build_query(params)\n41 +    conditions = params.map do |key, value|\n42 +      \"#{key} = '#{value}'\"\n43 +    end\n44 +    conditions.join(' AND ')\n45 +  end\n46 +\n47 +  def instantiate_class(class_name, *args)\n48 +    klass = Object.const_get(class_name)\n49 +    klass.new(*args)\n50 +  end\n51 +\n52 +  def execute_callback(callback_name, *args)\n53 +    method(callback_name).call(*args)\n54 +  end\n55 +end\n56 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/dynamic_executor.rb\",\"relevantLinesStart\":8,\"relevantLinesEnd\":10},{\"relevantFile\":\"app/services/dynamic_executor.rb\",\"relevantLinesStart\":20,\"relevantLinesEnd\":22},{\"relevantFile\":\"app/services/dynamic_executor.rb\",\"relevantLinesStart\":46,\"relevantLinesEnd\":49}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def execute_expression(expression)\\n    eval(expression)\\n  end\",\n    \"improvedCode\": \"# Remove this method entirely - eval on user input is never safe\\n  # Use a proper expression parser or DSL instead\",\n    \"relevantFile\": \"app/services/dynamic_executor.rb\",\n    \"relevantLinesEnd\": 10,\n    \"suggestionContent\": \"The `execute_expression` method uses `eval` on arbitrary input. An attacker can execute any Ruby code, including `system('rm -rf /')` or accessing sensitive data. Never use `eval` on user input.\",\n    \"oneSentenceSummary\": \"eval on user input allows arbitrary code execution\",\n    \"relevantLinesStart\": 8\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def call_method(object, method_name, *args)\\n    object.send(method_name, *args)\\n  end\",\n    \"improvedCode\": \"def call_method(object, method_name, *args)\\n    raise \\\"Method not allowed\\\" unless ALLOWED_METHODS.include?(method_name.to_s)\\n    object.public_send(method_name, *args)\\n  end\",\n    \"relevantFile\": \"app/services/dynamic_executor.rb\",\n    \"relevantLinesEnd\": 22,\n    \"suggestionContent\": \"The `call_method` method uses `send` which can call any method including private methods and dangerous ones like `instance_eval`, `system`, or `exit`. Use `public_send` and validate against an allowlist.\",\n    \"oneSentenceSummary\": \"send can call private methods and dangerous system methods\",\n    \"relevantLinesStart\": 20\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"def instantiate_class(class_name, *args)\\n    klass = Object.const_get(class_name)\\n    klass.new(*args)\\n  end\",\n    \"improvedCode\": \"ALLOWED_CLASSES = %w[User Order Product].freeze\\n\\n  def instantiate_class(class_name, *args)\\n    raise \\\"Class not allowed\\\" unless ALLOWED_CLASSES.include?(class_name)\\n    klass = Object.const_get(class_name)\\n    klass.new(*args)\\n  end\",\n    \"relevantFile\": \"app/services/dynamic_executor.rb\",\n    \"relevantLinesEnd\": 49,\n    \"suggestionContent\": \"The `instantiate_class` method uses `Object.const_get` with user input, allowing instantiation of any class. An attacker can instantiate `File`, `Dir`, or other dangerous classes to access the filesystem.\",\n    \"oneSentenceSummary\": \"const_get allows instantiating arbitrary classes for filesystem access\",\n    \"relevantLinesStart\": 46\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  },
  {
    "description": "Example 80: app/services/task_manager.rb",
    "vars": {
      "fileContent": "class TaskManager\n  def initialize\n    @tasks = []\n    @completed = []\n  end\n\n  def add_task(task)\n    @tasks << task\n  end\n\n  def remove_completed_tasks\n    @tasks.each do |task|\n      if task[:status] == 'completed'\n        @tasks.delete(task)\n        @completed << task\n      end\n    end\n  end\n\n  def process_and_remove\n    @tasks.each do |task|\n      result = process_task(task)\n      if result[:success]\n        @tasks.delete(task)\n      end\n    end\n  end\n\n  def filter_by_priority(min_priority)\n    @tasks.each do |task|\n      @tasks.delete(task) if task[:priority] < min_priority\n    end\n  end\n\n  def cleanup_old_tasks(max_age)\n    cutoff = Time.current - max_age\n    @tasks.each_with_index do |task, index|\n      if task[:created_at] < cutoff\n        @tasks.delete_at(index)\n      end\n    end\n  end\n\n  def get_pending_tasks\n    @tasks.select { |t| t[:status] == 'pending' }\n  end\n\n  def mark_complete(task_id)\n    task = @tasks.find { |t| t[:id] == task_id }\n    task[:status] = 'completed' if task\n  end\n\n  def safe_cleanup\n    @tasks.reject! { |task| task[:status] == 'completed' }\n  end\n\n  private\n\n  def process_task(task)\n    # Processing logic\n    { success: rand > 0.5 }\n  end\nend\n",
      "patchWithLinesStr": "## file: 'app/services/task_manager.rb'\n\n@@ -0,0 +1,64 @@\n__new hunk__\n1 +class TaskManager\n2 +  def initialize\n3 +    @tasks = []\n4 +    @completed = []\n5 +  end\n6 +\n7 +  def add_task(task)\n8 +    @tasks << task\n9 +  end\n10 +\n11 +  def remove_completed_tasks\n12 +    @tasks.each do |task|\n13 +      if task[:status] == 'completed'\n14 +        @tasks.delete(task)\n15 +        @completed << task\n16 +      end\n17 +    end\n18 +  end\n19 +\n20 +  def process_and_remove\n21 +    @tasks.each do |task|\n22 +      result = process_task(task)\n23 +      if result[:success]\n24 +        @tasks.delete(task)\n25 +      end\n26 +    end\n27 +  end\n28 +\n29 +  def filter_by_priority(min_priority)\n30 +    @tasks.each do |task|\n31 +      @tasks.delete(task) if task[:priority] < min_priority\n32 +    end\n33 +  end\n34 +\n35 +  def cleanup_old_tasks(max_age)\n36 +    cutoff = Time.current - max_age\n37 +    @tasks.each_with_index do |task, index|\n38 +      if task[:created_at] < cutoff\n39 +        @tasks.delete_at(index)\n40 +      end\n41 +    end\n42 +  end\n43 +\n44 +  def get_pending_tasks\n45 +    @tasks.select { |t| t[:status] == 'pending' }\n46 +  end\n47 +\n48 +  def mark_complete(task_id)\n49 +    task = @tasks.find { |t| t[:id] == task_id }\n50 +    task[:status] = 'completed' if task\n51 +  end\n52 +\n53 +  def safe_cleanup\n54 +    @tasks.reject! { |task| task[:status] == 'completed' }\n55 +  end\n56 +\n57 +  private\n58 +\n59 +  def process_task(task)\n60 +    # Processing logic\n61 +    { success: rand > 0.5 }\n62 +  end\n63 +end\n64 +\n__old hunk__\n",
      "prSummary": "",
      "referenceBugs": "[{\"relevantFile\":\"app/services/task_manager.rb\",\"relevantLinesStart\":12,\"relevantLinesEnd\":17},{\"relevantFile\":\"app/services/task_manager.rb\",\"relevantLinesStart\":35,\"relevantLinesEnd\":39}]",
      "referenceCodeSuggestions": "[\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"@tasks.each do |task|\\n      if task[:status] == 'completed'\\n        @tasks.delete(task)\\n        @completed << task\\n      end\\n    end\",\n    \"improvedCode\": \"completed_tasks, @tasks = @tasks.partition { |task| task[:status] == 'completed' }\\n    @completed.concat(completed_tasks)\",\n    \"relevantFile\": \"app/services/task_manager.rb\",\n    \"relevantLinesEnd\": 17,\n    \"suggestionContent\": \"The `remove_completed_tasks` method modifies `@tasks` array while iterating over it with `each`. In Ruby, this causes elements to be skipped because indices shift after deletion. For example, if tasks[0] is deleted, tasks[1] becomes tasks[0], but the iterator moves to index 1, skipping the element.\",\n    \"oneSentenceSummary\": \"Array modification during each iteration skips elements\",\n    \"relevantLinesStart\": 12\n  },\n  {\n    \"label\": \"bug\",\n    \"language\": \"Ruby\",\n    \"existingCode\": \"@tasks.each_with_index do |task, index|\\n      if task[:created_at] < cutoff\\n        @tasks.delete_at(index)\\n      end\\n    end\",\n    \"improvedCode\": \"@tasks.reject! { |task| task[:created_at] < cutoff }\",\n    \"relevantFile\": \"app/services/task_manager.rb\",\n    \"relevantLinesEnd\": 39,\n    \"suggestionContent\": \"The `cleanup_old_tasks` method uses `delete_at(index)` while iterating with `each_with_index`. After deleting at index 0, all subsequent indices are off by one, causing elements to be skipped or wrong elements to be deleted.\",\n    \"oneSentenceSummary\": \"delete_at during each_with_index corrupts iteration indices\",\n    \"relevantLinesStart\": 35\n  }\n]"
    },
    "assert": [
      {
        "type": "javascript",
        "value": "file://parse-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://judge-assertion.js"
      },
      {
        "type": "javascript",
        "value": "file://line-accuracy-assertion.js"
      }
    ]
  }
]